{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/processed_chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"efficient_net_b1\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 0\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "# norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Pneumonia dataset metrics\n",
    "norm_arr=([0.4810, 0.4810, 0.4810], [0.2373, 0.2373, 0.2373])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = (input_size, input_size), \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/129], Loss: 0.6076, Accuracy: 25.00%\n",
      "train Loss: 1.0594 Acc: 0.5409\n",
      "val Loss: 0.9740 Acc: 0.5564\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/129], Loss: 0.6659, Accuracy: 23.00%\n",
      "train Loss: 0.7548 Acc: 0.6569\n",
      "val Loss: 0.7971 Acc: 0.6237\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/129], Loss: 0.6183, Accuracy: 24.00%\n",
      "train Loss: 0.7210 Acc: 0.6695\n",
      "val Loss: 1.9396 Acc: 0.4778\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/129], Loss: 0.5550, Accuracy: 24.00%\n",
      "train Loss: 0.6729 Acc: 0.6941\n",
      "val Loss: 0.5595 Acc: 0.7457\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/129], Loss: 0.4653, Accuracy: 26.00%\n",
      "train Loss: 0.6308 Acc: 0.7028\n",
      "val Loss: 1.1772 Acc: 0.5348\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/129], Loss: 0.6980, Accuracy: 21.00%\n",
      "train Loss: 0.6003 Acc: 0.7349\n",
      "val Loss: 0.6952 Acc: 0.6876\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/129], Loss: 0.5071, Accuracy: 24.00%\n",
      "train Loss: 0.5759 Acc: 0.7502\n",
      "val Loss: 0.6938 Acc: 0.6636\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/129], Loss: 0.5838, Accuracy: 22.00%\n",
      "train Loss: 0.5648 Acc: 0.7456\n",
      "val Loss: 0.5480 Acc: 0.7537\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/129], Loss: 0.5154, Accuracy: 23.00%\n",
      "train Loss: 0.5578 Acc: 0.7617\n",
      "val Loss: 0.9673 Acc: 0.5941\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/129], Loss: 0.5042, Accuracy: 23.00%\n",
      "train Loss: 0.5370 Acc: 0.7721\n",
      "val Loss: 0.7638 Acc: 0.6807\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/129], Loss: 0.4517, Accuracy: 26.00%\n",
      "train Loss: 0.5252 Acc: 0.7714\n",
      "val Loss: 0.5199 Acc: 0.7594\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/129], Loss: 0.7294, Accuracy: 21.00%\n",
      "train Loss: 0.5120 Acc: 0.7765\n",
      "val Loss: 0.5614 Acc: 0.7081\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/129], Loss: 0.3923, Accuracy: 28.00%\n",
      "train Loss: 0.5063 Acc: 0.7867\n",
      "val Loss: 0.6873 Acc: 0.7298\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/129], Loss: 0.4114, Accuracy: 26.00%\n",
      "train Loss: 0.5008 Acc: 0.7943\n",
      "val Loss: 0.7206 Acc: 0.5918\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/129], Loss: 0.3742, Accuracy: 28.00%\n",
      "train Loss: 0.4899 Acc: 0.7964\n",
      "val Loss: 0.5339 Acc: 0.7491\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/129], Loss: 0.5966, Accuracy: 24.00%\n",
      "train Loss: 0.4810 Acc: 0.7984\n",
      "val Loss: 1.3560 Acc: 0.4208\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/129], Loss: 0.7313, Accuracy: 19.00%\n",
      "train Loss: 0.4791 Acc: 0.8008\n",
      "val Loss: 0.4886 Acc: 0.7719\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/129], Loss: 0.4266, Accuracy: 25.00%\n",
      "train Loss: 0.4701 Acc: 0.7977\n",
      "val Loss: 0.7918 Acc: 0.6420\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/129], Loss: 0.4503, Accuracy: 27.00%\n",
      "train Loss: 0.4888 Acc: 0.7947\n",
      "val Loss: 1.2170 Acc: 0.5097\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/129], Loss: 0.4091, Accuracy: 25.00%\n",
      "train Loss: 0.4552 Acc: 0.8118\n",
      "val Loss: 0.6952 Acc: 0.6990\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/129], Loss: 0.4848, Accuracy: 26.00%\n",
      "train Loss: 0.4670 Acc: 0.8050\n",
      "val Loss: 0.4486 Acc: 0.8062\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/129], Loss: 0.3477, Accuracy: 27.00%\n",
      "train Loss: 0.4511 Acc: 0.8159\n",
      "val Loss: 0.4677 Acc: 0.8016\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/129], Loss: 0.4736, Accuracy: 24.00%\n",
      "train Loss: 0.4499 Acc: 0.8101\n",
      "val Loss: 0.4596 Acc: 0.8039\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/129], Loss: 0.3334, Accuracy: 27.00%\n",
      "train Loss: 0.4504 Acc: 0.8137\n",
      "val Loss: 0.4552 Acc: 0.8119\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/129], Loss: 0.4863, Accuracy: 25.00%\n",
      "train Loss: 0.4279 Acc: 0.8196\n",
      "val Loss: 0.4829 Acc: 0.7834\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/129], Loss: 0.3902, Accuracy: 28.00%\n",
      "train Loss: 0.4360 Acc: 0.8234\n",
      "val Loss: 0.5066 Acc: 0.7811\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/129], Loss: 0.3484, Accuracy: 29.00%\n",
      "train Loss: 0.4186 Acc: 0.8249\n",
      "val Loss: 0.4730 Acc: 0.7936\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/129], Loss: 0.2423, Accuracy: 30.00%\n",
      "train Loss: 0.4217 Acc: 0.8251\n",
      "val Loss: 0.6312 Acc: 0.7366\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/129], Loss: 0.4061, Accuracy: 30.00%\n",
      "train Loss: 0.4234 Acc: 0.8147\n",
      "val Loss: 0.5222 Acc: 0.7948\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/129], Loss: 0.4682, Accuracy: 26.00%\n",
      "train Loss: 0.4190 Acc: 0.8188\n",
      "val Loss: 0.6891 Acc: 0.6933\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/129], Loss: 0.4541, Accuracy: 26.00%\n",
      "train Loss: 0.4060 Acc: 0.8276\n",
      "val Loss: 0.5021 Acc: 0.7993\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/129], Loss: 0.4549, Accuracy: 25.00%\n",
      "train Loss: 0.4023 Acc: 0.8288\n",
      "val Loss: 0.6217 Acc: 0.7092\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/129], Loss: 0.4505, Accuracy: 23.00%\n",
      "train Loss: 0.4048 Acc: 0.8254\n",
      "val Loss: 0.7504 Acc: 0.7035\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/129], Loss: 0.3888, Accuracy: 25.00%\n",
      "train Loss: 0.3878 Acc: 0.8351\n",
      "val Loss: 0.5245 Acc: 0.7662\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/129], Loss: 0.5554, Accuracy: 23.00%\n",
      "train Loss: 0.3789 Acc: 0.8393\n",
      "val Loss: 0.8833 Acc: 0.6910\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/129], Loss: 0.4582, Accuracy: 24.00%\n",
      "train Loss: 0.3879 Acc: 0.8366\n",
      "val Loss: 0.5387 Acc: 0.7731\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/129], Loss: 0.3453, Accuracy: 30.00%\n",
      "train Loss: 0.3796 Acc: 0.8422\n",
      "val Loss: 0.5131 Acc: 0.7697\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/129], Loss: 0.4174, Accuracy: 25.00%\n",
      "train Loss: 0.3697 Acc: 0.8414\n",
      "val Loss: 0.5156 Acc: 0.7662\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/129], Loss: 0.3356, Accuracy: 27.00%\n",
      "train Loss: 0.3736 Acc: 0.8385\n",
      "val Loss: 0.5306 Acc: 0.7822\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/129], Loss: 0.3530, Accuracy: 28.00%\n",
      "train Loss: 0.3692 Acc: 0.8422\n",
      "val Loss: 0.4696 Acc: 0.8005\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/129], Loss: 0.3691, Accuracy: 24.00%\n",
      "train Loss: 0.3596 Acc: 0.8458\n",
      "val Loss: 0.5131 Acc: 0.7936\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/129], Loss: 0.3292, Accuracy: 27.00%\n",
      "train Loss: 0.3383 Acc: 0.8558\n",
      "val Loss: 0.5245 Acc: 0.7913\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/129], Loss: 0.5647, Accuracy: 22.00%\n",
      "train Loss: 0.3289 Acc: 0.8614\n",
      "val Loss: 0.4712 Acc: 0.8164\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/129], Loss: 0.2295, Accuracy: 28.00%\n",
      "train Loss: 0.3288 Acc: 0.8546\n",
      "val Loss: 0.4723 Acc: 0.8324\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/129], Loss: 0.5064, Accuracy: 25.00%\n",
      "train Loss: 0.3268 Acc: 0.8616\n",
      "val Loss: 0.5568 Acc: 0.7526\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/129], Loss: 0.3498, Accuracy: 26.00%\n",
      "train Loss: 0.3148 Acc: 0.8645\n",
      "val Loss: 0.5969 Acc: 0.7674\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/129], Loss: 0.2931, Accuracy: 28.00%\n",
      "train Loss: 0.3098 Acc: 0.8677\n",
      "val Loss: 0.6274 Acc: 0.7024\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/129], Loss: 0.2750, Accuracy: 28.00%\n",
      "train Loss: 0.2869 Acc: 0.8755\n",
      "val Loss: 0.5177 Acc: 0.8130\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/129], Loss: 0.5009, Accuracy: 25.00%\n",
      "train Loss: 0.2927 Acc: 0.8731\n",
      "val Loss: 0.5650 Acc: 0.7571\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/129], Loss: 0.3043, Accuracy: 28.00%\n",
      "train Loss: 0.2837 Acc: 0.8813\n",
      "val Loss: 0.5813 Acc: 0.7537\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/129], Loss: 0.1815, Accuracy: 30.00%\n",
      "train Loss: 0.2618 Acc: 0.8918\n",
      "val Loss: 0.6213 Acc: 0.7891\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/129], Loss: 0.2736, Accuracy: 29.00%\n",
      "train Loss: 0.2530 Acc: 0.8918\n",
      "val Loss: 0.5796 Acc: 0.7959\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/129], Loss: 0.2749, Accuracy: 29.00%\n",
      "train Loss: 0.2453 Acc: 0.9027\n",
      "val Loss: 0.6019 Acc: 0.7503\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/129], Loss: 0.2550, Accuracy: 26.00%\n",
      "train Loss: 0.2385 Acc: 0.9020\n",
      "val Loss: 0.9080 Acc: 0.6271\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/129], Loss: 0.8063, Accuracy: 21.00%\n",
      "train Loss: 0.2303 Acc: 0.9086\n",
      "val Loss: 0.5827 Acc: 0.7822\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/129], Loss: 0.1784, Accuracy: 30.00%\n",
      "train Loss: 0.2170 Acc: 0.9125\n",
      "val Loss: 0.6676 Acc: 0.7879\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/129], Loss: 0.1614, Accuracy: 29.00%\n",
      "train Loss: 0.2023 Acc: 0.9132\n",
      "val Loss: 0.7021 Acc: 0.7708\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/129], Loss: 0.0788, Accuracy: 32.00%\n",
      "train Loss: 0.1834 Acc: 0.9256\n",
      "val Loss: 0.7464 Acc: 0.7594\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/129], Loss: 0.1217, Accuracy: 31.00%\n",
      "train Loss: 0.1683 Acc: 0.9307\n",
      "val Loss: 0.7987 Acc: 0.7868\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/129], Loss: 0.0742, Accuracy: 31.00%\n",
      "train Loss: 0.1671 Acc: 0.9358\n",
      "val Loss: 0.9893 Acc: 0.7754\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/129], Loss: 0.1582, Accuracy: 31.00%\n",
      "train Loss: 0.1550 Acc: 0.9404\n",
      "val Loss: 0.7722 Acc: 0.8016\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/129], Loss: 0.2915, Accuracy: 30.00%\n",
      "train Loss: 0.1342 Acc: 0.9492\n",
      "val Loss: 0.9360 Acc: 0.8039\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/129], Loss: 0.0206, Accuracy: 32.00%\n",
      "train Loss: 0.1285 Acc: 0.9499\n",
      "val Loss: 0.8178 Acc: 0.7651\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/129], Loss: 0.2139, Accuracy: 28.00%\n",
      "train Loss: 0.1095 Acc: 0.9570\n",
      "val Loss: 1.0149 Acc: 0.7605\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/129], Loss: 0.0872, Accuracy: 30.00%\n",
      "train Loss: 0.0952 Acc: 0.9623\n",
      "val Loss: 0.9276 Acc: 0.7913\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/129], Loss: 0.1502, Accuracy: 30.00%\n",
      "train Loss: 0.1101 Acc: 0.9589\n",
      "val Loss: 0.9101 Acc: 0.8073\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/129], Loss: 0.3639, Accuracy: 28.00%\n",
      "train Loss: 0.0954 Acc: 0.9674\n",
      "val Loss: 0.9936 Acc: 0.7970\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/129], Loss: 0.0114, Accuracy: 32.00%\n",
      "train Loss: 0.0590 Acc: 0.9767\n",
      "val Loss: 1.1571 Acc: 0.7948\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/129], Loss: 0.0065, Accuracy: 32.00%\n",
      "train Loss: 0.0688 Acc: 0.9742\n",
      "val Loss: 1.0575 Acc: 0.7719\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/129], Loss: 0.1715, Accuracy: 29.00%\n",
      "train Loss: 0.0803 Acc: 0.9689\n",
      "val Loss: 1.0144 Acc: 0.7571\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/129], Loss: 0.0045, Accuracy: 32.00%\n",
      "train Loss: 0.0574 Acc: 0.9776\n",
      "val Loss: 1.1352 Acc: 0.8073\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/129], Loss: 0.1897, Accuracy: 30.00%\n",
      "train Loss: 0.0608 Acc: 0.9786\n",
      "val Loss: 1.0995 Acc: 0.7856\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/129], Loss: 0.1002, Accuracy: 31.00%\n",
      "train Loss: 0.0561 Acc: 0.9815\n",
      "val Loss: 1.0932 Acc: 0.7754\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/129], Loss: 0.0029, Accuracy: 32.00%\n",
      "train Loss: 0.0477 Acc: 0.9844\n",
      "val Loss: 1.1520 Acc: 0.7936\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/129], Loss: 0.0395, Accuracy: 31.00%\n",
      "train Loss: 0.0346 Acc: 0.9861\n",
      "val Loss: 1.1956 Acc: 0.7913\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/129], Loss: 0.0032, Accuracy: 32.00%\n",
      "train Loss: 0.0397 Acc: 0.9866\n",
      "val Loss: 1.3188 Acc: 0.7936\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/129], Loss: 0.0098, Accuracy: 32.00%\n",
      "train Loss: 0.0321 Acc: 0.9883\n",
      "val Loss: 1.2817 Acc: 0.7777\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/129], Loss: 0.0142, Accuracy: 32.00%\n",
      "train Loss: 0.0373 Acc: 0.9869\n",
      "val Loss: 1.2388 Acc: 0.7788\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/129], Loss: 0.0056, Accuracy: 32.00%\n",
      "train Loss: 0.0473 Acc: 0.9839\n",
      "val Loss: 1.2657 Acc: 0.7925\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/129], Loss: 0.0478, Accuracy: 32.00%\n",
      "train Loss: 0.0262 Acc: 0.9910\n",
      "val Loss: 1.2788 Acc: 0.7891\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/129], Loss: 0.0560, Accuracy: 31.00%\n",
      "train Loss: 0.0265 Acc: 0.9910\n",
      "val Loss: 1.2680 Acc: 0.7845\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/129], Loss: 0.0060, Accuracy: 32.00%\n",
      "train Loss: 0.0225 Acc: 0.9934\n",
      "val Loss: 1.3348 Acc: 0.7902\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/129], Loss: 0.1477, Accuracy: 31.00%\n",
      "train Loss: 0.0193 Acc: 0.9942\n",
      "val Loss: 1.4677 Acc: 0.7913\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/129], Loss: 0.0181, Accuracy: 32.00%\n",
      "train Loss: 0.0202 Acc: 0.9939\n",
      "val Loss: 1.3473 Acc: 0.7868\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/129], Loss: 0.0025, Accuracy: 32.00%\n",
      "train Loss: 0.0254 Acc: 0.9908\n",
      "val Loss: 1.4332 Acc: 0.8016\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/129], Loss: 0.0482, Accuracy: 31.00%\n",
      "train Loss: 0.0189 Acc: 0.9932\n",
      "val Loss: 1.4642 Acc: 0.8027\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/129], Loss: 0.0251, Accuracy: 31.00%\n",
      "train Loss: 0.0131 Acc: 0.9954\n",
      "val Loss: 1.5069 Acc: 0.7970\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/129], Loss: 0.0980, Accuracy: 31.00%\n",
      "train Loss: 0.0202 Acc: 0.9929\n",
      "val Loss: 1.4070 Acc: 0.7902\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/129], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0165 Acc: 0.9946\n",
      "val Loss: 1.5101 Acc: 0.7879\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/129], Loss: 0.0353, Accuracy: 32.00%\n",
      "train Loss: 0.0184 Acc: 0.9949\n",
      "val Loss: 1.4968 Acc: 0.7936\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/129], Loss: 0.0567, Accuracy: 31.00%\n",
      "train Loss: 0.0221 Acc: 0.9937\n",
      "val Loss: 1.4913 Acc: 0.7879\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/129], Loss: 0.0016, Accuracy: 32.00%\n",
      "train Loss: 0.0140 Acc: 0.9949\n",
      "val Loss: 1.5279 Acc: 0.7879\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/129], Loss: 0.0027, Accuracy: 32.00%\n",
      "train Loss: 0.0125 Acc: 0.9973\n",
      "val Loss: 1.5253 Acc: 0.7891\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/129], Loss: 0.0009, Accuracy: 32.00%\n",
      "train Loss: 0.0184 Acc: 0.9934\n",
      "val Loss: 1.4580 Acc: 0.7891\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/129], Loss: 0.0005, Accuracy: 32.00%\n",
      "train Loss: 0.0131 Acc: 0.9959\n",
      "val Loss: 1.6012 Acc: 0.7913\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/129], Loss: 0.0047, Accuracy: 32.00%\n",
      "train Loss: 0.0115 Acc: 0.9961\n",
      "val Loss: 1.5520 Acc: 0.7913\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/129], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0081 Acc: 0.9976\n",
      "val Loss: 1.5636 Acc: 0.7948\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/129], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0108 Acc: 0.9961\n",
      "val Loss: 1.6541 Acc: 0.7868\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/129], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0083 Acc: 0.9968\n",
      "val Loss: 1.6273 Acc: 0.7856\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/129], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0071 Acc: 0.9981\n",
      "val Loss: 1.5743 Acc: 0.7834\n",
      "\n",
      "Training complete in 183m 26s\n",
      "Best val Acc: 0.832383\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, \n",
    "                                                           eta_min=lr_end, last_epoch=-1)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.798175598631699\n",
      "f1: 0.7683671126087986\n",
      "cm: [[232   2   2]\n",
      " [ 12 373  32]\n",
      " [  9 120  95]]\n",
      "outputs: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 0 1 1 1 2 1\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 2 1 2 2 2 1 1 1\n",
      " 1 1 1 2 2 1 1 1 1 1 2 1 2 2 2 1 0 2 2 1 1 2 2 2 1 1 1 2 2 2 2 1 1 1 1 2 2\n",
      " 2 2 2 2 2 1 1 0 2 2 1 1 2 0 2 0 1 1 2 2 1 2 2 2 1 0 2 1 1 1 2 2 1 1 1 1 1\n",
      " 1 1 2 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 2 2 2 2 2 2 2 2\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 2 2 1 2 2 2 1\n",
      " 2 0 0 1 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1 2 1 1 1\n",
      " 1 2 1 2 1 2 2 2 2 2 2 2 1 2 0 2 1 2 2 2 0 1 1 1 1 2]\n",
      "targets: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
