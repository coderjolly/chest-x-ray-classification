{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/covid_pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"resnet34\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Covid Pneumonia dataset metrics\n",
    "norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/188], Loss: 0.5734, Accuracy: 22.00%\n",
      "train Loss: 0.8808 Acc: 0.5782\n",
      "val Loss: 0.6815 Acc: 0.6954\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/188], Loss: 0.6913, Accuracy: 22.00%\n",
      "train Loss: 0.6563 Acc: 0.6868\n",
      "val Loss: 0.7121 Acc: 0.6566\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/188], Loss: 0.4870, Accuracy: 25.00%\n",
      "train Loss: 0.5631 Acc: 0.7478\n",
      "val Loss: 0.5693 Acc: 0.7413\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/188], Loss: 0.5994, Accuracy: 20.00%\n",
      "train Loss: 0.4959 Acc: 0.7788\n",
      "val Loss: 0.5050 Acc: 0.7700\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/188], Loss: 0.6709, Accuracy: 23.00%\n",
      "train Loss: 0.4642 Acc: 0.7909\n",
      "val Loss: 0.4836 Acc: 0.7832\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/188], Loss: 0.4151, Accuracy: 28.00%\n",
      "train Loss: 0.4318 Acc: 0.8039\n",
      "val Loss: 0.4206 Acc: 0.8166\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/188], Loss: 0.4470, Accuracy: 27.00%\n",
      "train Loss: 0.4017 Acc: 0.8293\n",
      "val Loss: 0.5529 Acc: 0.7436\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/188], Loss: 0.3774, Accuracy: 27.00%\n",
      "train Loss: 0.3857 Acc: 0.8319\n",
      "val Loss: 0.3677 Acc: 0.8407\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/188], Loss: 0.2703, Accuracy: 26.00%\n",
      "train Loss: 0.3664 Acc: 0.8467\n",
      "val Loss: 0.4004 Acc: 0.8260\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/188], Loss: 0.5947, Accuracy: 21.00%\n",
      "train Loss: 0.3336 Acc: 0.8571\n",
      "val Loss: 0.4276 Acc: 0.8182\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/188], Loss: 0.2436, Accuracy: 29.00%\n",
      "train Loss: 0.3103 Acc: 0.8731\n",
      "val Loss: 0.3815 Acc: 0.8531\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/188], Loss: 0.2476, Accuracy: 29.00%\n",
      "train Loss: 0.2937 Acc: 0.8831\n",
      "val Loss: 0.3309 Acc: 0.8733\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/188], Loss: 0.1722, Accuracy: 30.00%\n",
      "train Loss: 0.2839 Acc: 0.8884\n",
      "val Loss: 0.4286 Acc: 0.8384\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/188], Loss: 0.1534, Accuracy: 31.00%\n",
      "train Loss: 0.2713 Acc: 0.8911\n",
      "val Loss: 0.3792 Acc: 0.8399\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/188], Loss: 0.3655, Accuracy: 29.00%\n",
      "train Loss: 0.2496 Acc: 0.9050\n",
      "val Loss: 0.4187 Acc: 0.8399\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/188], Loss: 0.1131, Accuracy: 30.00%\n",
      "train Loss: 0.2190 Acc: 0.9164\n",
      "val Loss: 0.3071 Acc: 0.8796\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/188], Loss: 0.2183, Accuracy: 30.00%\n",
      "train Loss: 0.2025 Acc: 0.9235\n",
      "val Loss: 0.2503 Acc: 0.8974\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/188], Loss: 0.1181, Accuracy: 31.00%\n",
      "train Loss: 0.1876 Acc: 0.9290\n",
      "val Loss: 0.9508 Acc: 0.7234\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/188], Loss: 0.1688, Accuracy: 28.00%\n",
      "train Loss: 0.1808 Acc: 0.9314\n",
      "val Loss: 0.2802 Acc: 0.8881\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/188], Loss: 0.1495, Accuracy: 31.00%\n",
      "train Loss: 0.1565 Acc: 0.9384\n",
      "val Loss: 5.5440 Acc: 0.5330\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/188], Loss: 0.2010, Accuracy: 29.00%\n",
      "train Loss: 0.1475 Acc: 0.9420\n",
      "val Loss: 0.3965 Acc: 0.8671\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/188], Loss: 0.0501, Accuracy: 31.00%\n",
      "train Loss: 0.1535 Acc: 0.9410\n",
      "val Loss: 0.1937 Acc: 0.9308\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/188], Loss: 0.0164, Accuracy: 32.00%\n",
      "train Loss: 0.1126 Acc: 0.9575\n",
      "val Loss: 0.2334 Acc: 0.9169\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/188], Loss: 0.1175, Accuracy: 31.00%\n",
      "train Loss: 0.1198 Acc: 0.9527\n",
      "val Loss: 0.4617 Acc: 0.8586\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/188], Loss: 0.0688, Accuracy: 31.00%\n",
      "train Loss: 0.1026 Acc: 0.9619\n",
      "val Loss: 0.1975 Acc: 0.9316\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/188], Loss: 0.0882, Accuracy: 31.00%\n",
      "train Loss: 0.0877 Acc: 0.9668\n",
      "val Loss: 0.2372 Acc: 0.9153\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/188], Loss: 0.0603, Accuracy: 31.00%\n",
      "train Loss: 0.0839 Acc: 0.9673\n",
      "val Loss: 0.2361 Acc: 0.9231\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/188], Loss: 0.0093, Accuracy: 32.00%\n",
      "train Loss: 0.0872 Acc: 0.9702\n",
      "val Loss: 0.2391 Acc: 0.9184\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/188], Loss: 0.0889, Accuracy: 30.00%\n",
      "train Loss: 0.0729 Acc: 0.9740\n",
      "val Loss: 0.4389 Acc: 0.8850\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/188], Loss: 0.0041, Accuracy: 32.00%\n",
      "train Loss: 0.0702 Acc: 0.9723\n",
      "val Loss: 0.3020 Acc: 0.9005\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/188], Loss: 0.0168, Accuracy: 32.00%\n",
      "train Loss: 0.0700 Acc: 0.9762\n",
      "val Loss: 0.2051 Acc: 0.9270\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/188], Loss: 0.0287, Accuracy: 32.00%\n",
      "train Loss: 0.0463 Acc: 0.9838\n",
      "val Loss: 0.2578 Acc: 0.9246\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/188], Loss: 0.0190, Accuracy: 32.00%\n",
      "train Loss: 0.0521 Acc: 0.9805\n",
      "val Loss: 0.2180 Acc: 0.9371\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/188], Loss: 0.0163, Accuracy: 32.00%\n",
      "train Loss: 0.0398 Acc: 0.9860\n",
      "val Loss: 0.6323 Acc: 0.8656\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/188], Loss: 0.0213, Accuracy: 32.00%\n",
      "train Loss: 0.0468 Acc: 0.9840\n",
      "val Loss: 0.1994 Acc: 0.9355\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/188], Loss: 0.0151, Accuracy: 32.00%\n",
      "train Loss: 0.0489 Acc: 0.9810\n",
      "val Loss: 0.2497 Acc: 0.9262\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/188], Loss: 0.1491, Accuracy: 30.00%\n",
      "train Loss: 0.0256 Acc: 0.9908\n",
      "val Loss: 0.3189 Acc: 0.9223\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/188], Loss: 0.0173, Accuracy: 32.00%\n",
      "train Loss: 0.0430 Acc: 0.9837\n",
      "val Loss: 0.2472 Acc: 0.9355\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/188], Loss: 0.0248, Accuracy: 31.00%\n",
      "train Loss: 0.0194 Acc: 0.9938\n",
      "val Loss: 0.2981 Acc: 0.9285\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/188], Loss: 0.0023, Accuracy: 32.00%\n",
      "train Loss: 0.0447 Acc: 0.9835\n",
      "val Loss: 0.2416 Acc: 0.9324\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/188], Loss: 0.0031, Accuracy: 32.00%\n",
      "train Loss: 0.0257 Acc: 0.9907\n",
      "val Loss: 0.2878 Acc: 0.9332\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/188], Loss: 0.0013, Accuracy: 32.00%\n",
      "train Loss: 0.0301 Acc: 0.9895\n",
      "val Loss: 0.4169 Acc: 0.8858\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/188], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0253 Acc: 0.9913\n",
      "val Loss: 0.3028 Acc: 0.9184\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/188], Loss: 0.0055, Accuracy: 32.00%\n",
      "train Loss: 0.0227 Acc: 0.9935\n",
      "val Loss: 0.2758 Acc: 0.9332\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/188], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0088 Acc: 0.9967\n",
      "val Loss: 0.3355 Acc: 0.9262\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/188], Loss: 0.0023, Accuracy: 32.00%\n",
      "train Loss: 0.0152 Acc: 0.9947\n",
      "val Loss: 0.9181 Acc: 0.8438\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/188], Loss: 0.0071, Accuracy: 32.00%\n",
      "train Loss: 0.0255 Acc: 0.9920\n",
      "val Loss: 0.2579 Acc: 0.9402\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/188], Loss: 0.0175, Accuracy: 32.00%\n",
      "train Loss: 0.0134 Acc: 0.9945\n",
      "val Loss: 0.2529 Acc: 0.9472\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/188], Loss: 0.0057, Accuracy: 32.00%\n",
      "train Loss: 0.0071 Acc: 0.9978\n",
      "val Loss: 0.4230 Acc: 0.9308\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/188], Loss: 0.0021, Accuracy: 32.00%\n",
      "train Loss: 0.0254 Acc: 0.9922\n",
      "val Loss: 0.3299 Acc: 0.9270\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/188], Loss: 0.0030, Accuracy: 32.00%\n",
      "train Loss: 0.0167 Acc: 0.9937\n",
      "val Loss: 0.3038 Acc: 0.9301\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/188], Loss: 0.0027, Accuracy: 32.00%\n",
      "train Loss: 0.0122 Acc: 0.9957\n",
      "val Loss: 0.3360 Acc: 0.9246\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/188], Loss: 0.0009, Accuracy: 32.00%\n",
      "train Loss: 0.0106 Acc: 0.9962\n",
      "val Loss: 0.3850 Acc: 0.9301\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/188], Loss: 0.0024, Accuracy: 32.00%\n",
      "train Loss: 0.0077 Acc: 0.9973\n",
      "val Loss: 0.4179 Acc: 0.9122\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/188], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0210 Acc: 0.9928\n",
      "val Loss: 0.2898 Acc: 0.9371\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/188], Loss: 0.0337, Accuracy: 31.00%\n",
      "train Loss: 0.0106 Acc: 0.9963\n",
      "val Loss: 0.3371 Acc: 0.9378\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/188], Loss: 0.0069, Accuracy: 32.00%\n",
      "train Loss: 0.0048 Acc: 0.9987\n",
      "val Loss: 0.2990 Acc: 0.9340\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/188], Loss: 0.0006, Accuracy: 32.00%\n",
      "train Loss: 0.0090 Acc: 0.9962\n",
      "val Loss: 0.2867 Acc: 0.9394\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/188], Loss: 0.0593, Accuracy: 31.00%\n",
      "train Loss: 0.0148 Acc: 0.9948\n",
      "val Loss: 0.2768 Acc: 0.9402\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0025 Acc: 0.9993\n",
      "val Loss: 0.3190 Acc: 0.9347\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/188], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0031 Acc: 0.9990\n",
      "val Loss: 0.3303 Acc: 0.9417\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/188], Loss: 0.0011, Accuracy: 32.00%\n",
      "train Loss: 0.0102 Acc: 0.9960\n",
      "val Loss: 0.3648 Acc: 0.9371\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/188], Loss: 0.0179, Accuracy: 32.00%\n",
      "train Loss: 0.0036 Acc: 0.9985\n",
      "val Loss: 0.2540 Acc: 0.9433\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "val Loss: 0.2718 Acc: 0.9441\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "val Loss: 0.2813 Acc: 0.9464\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/188], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 0.2875 Acc: 0.9464\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/188], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0070 Acc: 0.9973\n",
      "val Loss: 0.3298 Acc: 0.9371\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/188], Loss: 0.0010, Accuracy: 32.00%\n",
      "train Loss: 0.0116 Acc: 0.9950\n",
      "val Loss: 0.3642 Acc: 0.9363\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/188], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0075 Acc: 0.9968\n",
      "val Loss: 0.3548 Acc: 0.9417\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0028 Acc: 0.9987\n",
      "val Loss: 0.3233 Acc: 0.9402\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0034 Acc: 0.9985\n",
      "val Loss: 0.3688 Acc: 0.9402\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0019 Acc: 0.9995\n",
      "val Loss: 0.3209 Acc: 0.9433\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0023 Acc: 0.9992\n",
      "val Loss: 0.3267 Acc: 0.9448\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0020 Acc: 0.9992\n",
      "val Loss: 0.3412 Acc: 0.9433\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.3397 Acc: 0.9441\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/188], Loss: 0.0029, Accuracy: 32.00%\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "val Loss: 0.3487 Acc: 0.9448\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0010 Acc: 0.9995\n",
      "val Loss: 0.4369 Acc: 0.9324\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/188], Loss: 0.0046, Accuracy: 32.00%\n",
      "train Loss: 0.0026 Acc: 0.9988\n",
      "val Loss: 0.3779 Acc: 0.9394\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 0.3447 Acc: 0.9409\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 0.3581 Acc: 0.9386\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/188], Loss: 0.0012, Accuracy: 32.00%\n",
      "train Loss: 0.0016 Acc: 0.9997\n",
      "val Loss: 0.3297 Acc: 0.9464\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0030 Acc: 0.9988\n",
      "val Loss: 0.3524 Acc: 0.9448\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0013 Acc: 0.9995\n",
      "val Loss: 0.3141 Acc: 0.9472\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/188], Loss: 0.0013, Accuracy: 32.00%\n",
      "train Loss: 0.0013 Acc: 0.9995\n",
      "val Loss: 0.3358 Acc: 0.9472\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.3248 Acc: 0.9495\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/188], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0006 Acc: 0.9998\n",
      "val Loss: 0.3282 Acc: 0.9487\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/188], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0009 Acc: 0.9995\n",
      "val Loss: 0.3108 Acc: 0.9456\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0009 Acc: 0.9998\n",
      "val Loss: 0.3473 Acc: 0.9448\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 0.3198 Acc: 0.9518\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.3341 Acc: 0.9495\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/188], Loss: 0.0009, Accuracy: 32.00%\n",
      "train Loss: 0.0004 Acc: 0.9998\n",
      "val Loss: 0.3161 Acc: 0.9472\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0007 Acc: 0.9998\n",
      "val Loss: 0.3617 Acc: 0.9479\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 0.3132 Acc: 0.9495\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 0.3366 Acc: 0.9495\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/188], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.3174 Acc: 0.9487\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/188], Loss: 0.0013, Accuracy: 32.00%\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.3262 Acc: 0.9518\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/188], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.3338 Acc: 0.9526\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.3224 Acc: 0.9542\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/188], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.3312 Acc: 0.9448\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/188], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.3290 Acc: 0.9479\n",
      "\n",
      "Training complete in 83m 42s\n",
      "Best val Acc: 0.954157\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end, last_epoch=-1)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'covid_pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9541569541569541\n",
      "f1: 0.959575957081532\n",
      "cm: [[525  17   0]\n",
      " [ 34 506   3]\n",
      " [  2   3 197]]\n",
      "outputs: [0 0 0 ... 2 2 2]\n",
      "targets: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
