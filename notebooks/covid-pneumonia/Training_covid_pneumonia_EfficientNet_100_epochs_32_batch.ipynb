{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/covid_pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"efficient_net_b1\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Covid Pneumonia dataset metrics\n",
    "norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/332], Loss: 1.0870, Accuracy: 22.00%\n",
      "Epoch [1/100], Step [200/332], Loss: 1.1927, Accuracy: 18.00%\n",
      "Epoch [1/100], Step [300/332], Loss: 0.7181, Accuracy: 24.00%\n",
      "train Loss: 0.8639 Acc: 0.6689\n",
      "val Loss: 0.7129 Acc: 0.6907\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/332], Loss: 0.6335, Accuracy: 27.00%\n",
      "Epoch [2/100], Step [200/332], Loss: 0.5915, Accuracy: 22.00%\n",
      "Epoch [2/100], Step [300/332], Loss: 0.6411, Accuracy: 24.00%\n",
      "train Loss: 0.6131 Acc: 0.7365\n",
      "val Loss: 0.5703 Acc: 0.7338\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/332], Loss: 0.5000, Accuracy: 25.00%\n",
      "Epoch [3/100], Step [200/332], Loss: 0.4492, Accuracy: 26.00%\n",
      "Epoch [3/100], Step [300/332], Loss: 0.2925, Accuracy: 28.00%\n",
      "train Loss: 0.4721 Acc: 0.7975\n",
      "val Loss: 0.4699 Acc: 0.8007\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/332], Loss: 0.4910, Accuracy: 26.00%\n",
      "Epoch [4/100], Step [200/332], Loss: 0.5538, Accuracy: 26.00%\n",
      "Epoch [4/100], Step [300/332], Loss: 0.4383, Accuracy: 23.00%\n",
      "train Loss: 0.4208 Acc: 0.8262\n",
      "val Loss: 0.4058 Acc: 0.8451\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/332], Loss: 0.3029, Accuracy: 27.00%\n",
      "Epoch [5/100], Step [200/332], Loss: 0.5642, Accuracy: 26.00%\n",
      "Epoch [5/100], Step [300/332], Loss: 0.6339, Accuracy: 26.00%\n",
      "train Loss: 0.3567 Acc: 0.8557\n",
      "val Loss: 0.3057 Acc: 0.8803\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/332], Loss: 0.1559, Accuracy: 30.00%\n",
      "Epoch [6/100], Step [200/332], Loss: 0.2998, Accuracy: 30.00%\n",
      "Epoch [6/100], Step [300/332], Loss: 0.3538, Accuracy: 29.00%\n",
      "train Loss: 0.2900 Acc: 0.8832\n",
      "val Loss: 0.3285 Acc: 0.8623\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/332], Loss: 0.2623, Accuracy: 27.00%\n",
      "Epoch [7/100], Step [200/332], Loss: 0.3002, Accuracy: 30.00%\n",
      "Epoch [7/100], Step [300/332], Loss: 0.1421, Accuracy: 30.00%\n",
      "train Loss: 0.2330 Acc: 0.9111\n",
      "val Loss: 0.1881 Acc: 0.9300\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/332], Loss: 0.1176, Accuracy: 32.00%\n",
      "Epoch [8/100], Step [200/332], Loss: 0.1357, Accuracy: 29.00%\n",
      "Epoch [8/100], Step [300/332], Loss: 0.1122, Accuracy: 31.00%\n",
      "train Loss: 0.1893 Acc: 0.9285\n",
      "val Loss: 0.1605 Acc: 0.9371\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/332], Loss: 0.1484, Accuracy: 30.00%\n",
      "Epoch [9/100], Step [200/332], Loss: 0.0659, Accuracy: 31.00%\n",
      "Epoch [9/100], Step [300/332], Loss: 0.2179, Accuracy: 30.00%\n",
      "train Loss: 0.1575 Acc: 0.9430\n",
      "val Loss: 0.1282 Acc: 0.9542\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/332], Loss: 0.2198, Accuracy: 29.00%\n",
      "Epoch [10/100], Step [200/332], Loss: 0.2288, Accuracy: 30.00%\n",
      "Epoch [10/100], Step [300/332], Loss: 0.0478, Accuracy: 32.00%\n",
      "train Loss: 0.1280 Acc: 0.9517\n",
      "val Loss: 0.1033 Acc: 0.9644\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/332], Loss: 0.2495, Accuracy: 28.00%\n",
      "Epoch [11/100], Step [200/332], Loss: 0.4264, Accuracy: 25.00%\n",
      "Epoch [11/100], Step [300/332], Loss: 0.0589, Accuracy: 32.00%\n",
      "train Loss: 0.3292 Acc: 0.8699\n",
      "val Loss: 0.4101 Acc: 0.8553\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/332], Loss: 0.1346, Accuracy: 31.00%\n",
      "Epoch [12/100], Step [200/332], Loss: 0.2445, Accuracy: 27.00%\n",
      "Epoch [12/100], Step [300/332], Loss: 0.1412, Accuracy: 30.00%\n",
      "train Loss: 0.2532 Acc: 0.9075\n",
      "val Loss: 0.2437 Acc: 0.9015\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/332], Loss: 0.4127, Accuracy: 24.00%\n",
      "Epoch [13/100], Step [200/332], Loss: 0.0810, Accuracy: 32.00%\n",
      "Epoch [13/100], Step [300/332], Loss: 0.3311, Accuracy: 28.00%\n",
      "train Loss: 0.2285 Acc: 0.9135\n",
      "val Loss: 0.3358 Acc: 0.8825\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/332], Loss: 0.1866, Accuracy: 30.00%\n",
      "Epoch [14/100], Step [200/332], Loss: 0.3057, Accuracy: 28.00%\n",
      "Epoch [14/100], Step [300/332], Loss: 0.1822, Accuracy: 30.00%\n",
      "train Loss: 0.1959 Acc: 0.9280\n",
      "val Loss: 0.1763 Acc: 0.9358\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/332], Loss: 0.3042, Accuracy: 29.00%\n",
      "Epoch [15/100], Step [200/332], Loss: 0.1796, Accuracy: 29.00%\n",
      "Epoch [15/100], Step [300/332], Loss: 0.2148, Accuracy: 30.00%\n",
      "train Loss: 0.1519 Acc: 0.9454\n",
      "val Loss: 0.1400 Acc: 0.9512\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/332], Loss: 0.0948, Accuracy: 31.00%\n",
      "Epoch [16/100], Step [200/332], Loss: 0.1990, Accuracy: 29.00%\n",
      "Epoch [16/100], Step [300/332], Loss: 0.0679, Accuracy: 31.00%\n",
      "train Loss: 0.1286 Acc: 0.9533\n",
      "val Loss: 0.1553 Acc: 0.9415\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/332], Loss: 0.0782, Accuracy: 31.00%\n",
      "Epoch [17/100], Step [200/332], Loss: 0.0523, Accuracy: 32.00%\n",
      "Epoch [17/100], Step [300/332], Loss: 0.0745, Accuracy: 31.00%\n",
      "train Loss: 0.0995 Acc: 0.9639\n",
      "val Loss: 0.0792 Acc: 0.9723\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/332], Loss: 0.0486, Accuracy: 31.00%\n",
      "Epoch [18/100], Step [200/332], Loss: 0.1621, Accuracy: 30.00%\n",
      "Epoch [18/100], Step [300/332], Loss: 0.1910, Accuracy: 31.00%\n",
      "train Loss: 0.0848 Acc: 0.9699\n",
      "val Loss: 0.0883 Acc: 0.9666\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/332], Loss: 0.0653, Accuracy: 31.00%\n",
      "Epoch [19/100], Step [200/332], Loss: 0.0126, Accuracy: 32.00%\n",
      "Epoch [19/100], Step [300/332], Loss: 0.0124, Accuracy: 32.00%\n",
      "train Loss: 0.0643 Acc: 0.9761\n",
      "val Loss: 0.0746 Acc: 0.9780\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/332], Loss: 0.0025, Accuracy: 32.00%\n",
      "Epoch [20/100], Step [200/332], Loss: 0.0275, Accuracy: 32.00%\n",
      "Epoch [20/100], Step [300/332], Loss: 0.2061, Accuracy: 29.00%\n",
      "train Loss: 0.0572 Acc: 0.9803\n",
      "val Loss: 0.0688 Acc: 0.9798\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/332], Loss: 0.0914, Accuracy: 31.00%\n",
      "Epoch [21/100], Step [200/332], Loss: 0.2035, Accuracy: 30.00%\n",
      "Epoch [21/100], Step [300/332], Loss: 0.0326, Accuracy: 32.00%\n",
      "train Loss: 0.2119 Acc: 0.9207\n",
      "val Loss: 0.1647 Acc: 0.9410\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/332], Loss: 0.0454, Accuracy: 32.00%\n",
      "Epoch [22/100], Step [200/332], Loss: 0.1315, Accuracy: 30.00%\n",
      "Epoch [22/100], Step [300/332], Loss: 0.1397, Accuracy: 31.00%\n",
      "train Loss: 0.1593 Acc: 0.9432\n",
      "val Loss: 0.1235 Acc: 0.9525\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/332], Loss: 0.0721, Accuracy: 32.00%\n",
      "Epoch [23/100], Step [200/332], Loss: 0.0246, Accuracy: 32.00%\n",
      "Epoch [23/100], Step [300/332], Loss: 0.2196, Accuracy: 30.00%\n",
      "train Loss: 0.1367 Acc: 0.9506\n",
      "val Loss: 0.1543 Acc: 0.9437\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/332], Loss: 0.0193, Accuracy: 32.00%\n",
      "Epoch [24/100], Step [200/332], Loss: 0.0534, Accuracy: 32.00%\n",
      "Epoch [24/100], Step [300/332], Loss: 0.1164, Accuracy: 31.00%\n",
      "train Loss: 0.1146 Acc: 0.9577\n",
      "val Loss: 0.1158 Acc: 0.9582\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/332], Loss: 0.0614, Accuracy: 32.00%\n",
      "Epoch [25/100], Step [200/332], Loss: 0.0442, Accuracy: 31.00%\n",
      "Epoch [25/100], Step [300/332], Loss: 0.0374, Accuracy: 32.00%\n",
      "train Loss: 0.1002 Acc: 0.9658\n",
      "val Loss: 0.1150 Acc: 0.9551\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/332], Loss: 0.2322, Accuracy: 30.00%\n",
      "Epoch [26/100], Step [200/332], Loss: 0.0222, Accuracy: 32.00%\n",
      "Epoch [26/100], Step [300/332], Loss: 0.0326, Accuracy: 32.00%\n",
      "train Loss: 0.0779 Acc: 0.9713\n",
      "val Loss: 0.0635 Acc: 0.9767\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/332], Loss: 0.0137, Accuracy: 32.00%\n",
      "Epoch [27/100], Step [200/332], Loss: 0.0659, Accuracy: 31.00%\n",
      "Epoch [27/100], Step [300/332], Loss: 0.2408, Accuracy: 30.00%\n",
      "train Loss: 0.0652 Acc: 0.9783\n",
      "val Loss: 0.1279 Acc: 0.9551\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/332], Loss: 0.0216, Accuracy: 32.00%\n",
      "Epoch [28/100], Step [200/332], Loss: 0.0076, Accuracy: 32.00%\n",
      "Epoch [28/100], Step [300/332], Loss: 0.1122, Accuracy: 30.00%\n",
      "train Loss: 0.0478 Acc: 0.9831\n",
      "val Loss: 0.0741 Acc: 0.9736\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/332], Loss: 0.0201, Accuracy: 32.00%\n",
      "Epoch [29/100], Step [200/332], Loss: 0.0483, Accuracy: 31.00%\n",
      "Epoch [29/100], Step [300/332], Loss: 0.0253, Accuracy: 31.00%\n",
      "train Loss: 0.0411 Acc: 0.9867\n",
      "val Loss: 0.0589 Acc: 0.9762\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/332], Loss: 0.0226, Accuracy: 32.00%\n",
      "Epoch [30/100], Step [200/332], Loss: 0.0045, Accuracy: 32.00%\n",
      "Epoch [30/100], Step [300/332], Loss: 0.0695, Accuracy: 31.00%\n",
      "train Loss: 0.0288 Acc: 0.9906\n",
      "val Loss: 0.0530 Acc: 0.9798\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/332], Loss: 0.3522, Accuracy: 25.00%\n",
      "Epoch [31/100], Step [200/332], Loss: 0.0569, Accuracy: 31.00%\n",
      "Epoch [31/100], Step [300/332], Loss: 0.0402, Accuracy: 31.00%\n",
      "train Loss: 0.1798 Acc: 0.9383\n",
      "val Loss: 0.1098 Acc: 0.9608\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/332], Loss: 0.0198, Accuracy: 32.00%\n",
      "Epoch [32/100], Step [200/332], Loss: 0.0558, Accuracy: 32.00%\n",
      "Epoch [32/100], Step [300/332], Loss: 0.0677, Accuracy: 31.00%\n",
      "train Loss: 0.1215 Acc: 0.9574\n",
      "val Loss: 0.1382 Acc: 0.9472\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/332], Loss: 0.0324, Accuracy: 31.00%\n",
      "Epoch [33/100], Step [200/332], Loss: 0.1847, Accuracy: 29.00%\n",
      "Epoch [33/100], Step [300/332], Loss: 0.0256, Accuracy: 32.00%\n",
      "train Loss: 0.0981 Acc: 0.9662\n",
      "val Loss: 0.1029 Acc: 0.9630\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/332], Loss: 0.1361, Accuracy: 31.00%\n",
      "Epoch [34/100], Step [200/332], Loss: 0.0459, Accuracy: 31.00%\n",
      "Epoch [34/100], Step [300/332], Loss: 0.1412, Accuracy: 29.00%\n",
      "train Loss: 0.0840 Acc: 0.9679\n",
      "val Loss: 0.0854 Acc: 0.9679\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/332], Loss: 0.1357, Accuracy: 30.00%\n",
      "Epoch [35/100], Step [200/332], Loss: 0.1073, Accuracy: 31.00%\n",
      "Epoch [35/100], Step [300/332], Loss: 0.0604, Accuracy: 31.00%\n",
      "train Loss: 0.0746 Acc: 0.9747\n",
      "val Loss: 0.0770 Acc: 0.9666\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/332], Loss: 0.0089, Accuracy: 32.00%\n",
      "Epoch [36/100], Step [200/332], Loss: 0.2385, Accuracy: 31.00%\n",
      "Epoch [36/100], Step [300/332], Loss: 0.0213, Accuracy: 32.00%\n",
      "train Loss: 0.0584 Acc: 0.9789\n",
      "val Loss: 0.0683 Acc: 0.9745\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/332], Loss: 0.1760, Accuracy: 30.00%\n",
      "Epoch [37/100], Step [200/332], Loss: 0.1126, Accuracy: 31.00%\n",
      "Epoch [37/100], Step [300/332], Loss: 0.0064, Accuracy: 32.00%\n",
      "train Loss: 0.0422 Acc: 0.9865\n",
      "val Loss: 0.0619 Acc: 0.9789\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/332], Loss: 0.0127, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [200/332], Loss: 0.0083, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [300/332], Loss: 0.0789, Accuracy: 31.00%\n",
      "train Loss: 0.0334 Acc: 0.9893\n",
      "val Loss: 0.0621 Acc: 0.9793\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/332], Loss: 0.0045, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [200/332], Loss: 0.0041, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [300/332], Loss: 0.0268, Accuracy: 31.00%\n",
      "train Loss: 0.0285 Acc: 0.9900\n",
      "val Loss: 0.0448 Acc: 0.9850\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/332], Loss: 0.0039, Accuracy: 32.00%\n",
      "Epoch [40/100], Step [200/332], Loss: 0.1327, Accuracy: 30.00%\n",
      "Epoch [40/100], Step [300/332], Loss: 0.0279, Accuracy: 31.00%\n",
      "train Loss: 0.0223 Acc: 0.9922\n",
      "val Loss: 0.0459 Acc: 0.9842\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/332], Loss: 0.3405, Accuracy: 30.00%\n",
      "Epoch [41/100], Step [200/332], Loss: 0.1307, Accuracy: 31.00%\n",
      "Epoch [41/100], Step [300/332], Loss: 0.0181, Accuracy: 32.00%\n",
      "train Loss: 0.1496 Acc: 0.9501\n",
      "val Loss: 0.2420 Acc: 0.9037\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/332], Loss: 0.0161, Accuracy: 32.00%\n",
      "Epoch [42/100], Step [200/332], Loss: 0.0946, Accuracy: 31.00%\n",
      "Epoch [42/100], Step [300/332], Loss: 0.0368, Accuracy: 31.00%\n",
      "train Loss: 0.0861 Acc: 0.9696\n",
      "val Loss: 0.1050 Acc: 0.9648\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/332], Loss: 0.0672, Accuracy: 31.00%\n",
      "Epoch [43/100], Step [200/332], Loss: 0.1280, Accuracy: 30.00%\n",
      "Epoch [43/100], Step [300/332], Loss: 0.0173, Accuracy: 32.00%\n",
      "train Loss: 0.0799 Acc: 0.9712\n",
      "val Loss: 0.1772 Acc: 0.9318\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/332], Loss: 0.1042, Accuracy: 31.00%\n",
      "Epoch [44/100], Step [200/332], Loss: 0.0612, Accuracy: 31.00%\n",
      "Epoch [44/100], Step [300/332], Loss: 0.0040, Accuracy: 32.00%\n",
      "train Loss: 0.0673 Acc: 0.9759\n",
      "val Loss: 0.0545 Acc: 0.9811\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/332], Loss: 0.0065, Accuracy: 32.00%\n",
      "Epoch [45/100], Step [200/332], Loss: 0.0415, Accuracy: 31.00%\n",
      "Epoch [45/100], Step [300/332], Loss: 0.0046, Accuracy: 32.00%\n",
      "train Loss: 0.0539 Acc: 0.9807\n",
      "val Loss: 0.0692 Acc: 0.9771\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/332], Loss: 0.0053, Accuracy: 32.00%\n",
      "Epoch [46/100], Step [200/332], Loss: 0.0135, Accuracy: 32.00%\n",
      "Epoch [46/100], Step [300/332], Loss: 0.0370, Accuracy: 32.00%\n",
      "train Loss: 0.0459 Acc: 0.9838\n",
      "val Loss: 0.0525 Acc: 0.9824\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/332], Loss: 0.0056, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [200/332], Loss: 0.0057, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [300/332], Loss: 0.1437, Accuracy: 30.00%\n",
      "train Loss: 0.0290 Acc: 0.9894\n",
      "val Loss: 0.0815 Acc: 0.9732\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/332], Loss: 0.0148, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [200/332], Loss: 0.0035, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [300/332], Loss: 0.0465, Accuracy: 31.00%\n",
      "train Loss: 0.0243 Acc: 0.9915\n",
      "val Loss: 0.0529 Acc: 0.9793\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/332], Loss: 0.0140, Accuracy: 32.00%\n",
      "Epoch [49/100], Step [200/332], Loss: 0.0041, Accuracy: 32.00%\n",
      "Epoch [49/100], Step [300/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "train Loss: 0.0125 Acc: 0.9960\n",
      "val Loss: 0.0437 Acc: 0.9837\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [50/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [50/100], Step [300/332], Loss: 0.0042, Accuracy: 32.00%\n",
      "train Loss: 0.0109 Acc: 0.9967\n",
      "val Loss: 0.0426 Acc: 0.9828\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/332], Loss: 0.0739, Accuracy: 31.00%\n",
      "Epoch [51/100], Step [200/332], Loss: 0.0593, Accuracy: 31.00%\n",
      "Epoch [51/100], Step [300/332], Loss: 0.0952, Accuracy: 31.00%\n",
      "train Loss: 0.1525 Acc: 0.9486\n",
      "val Loss: 0.1306 Acc: 0.9582\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/332], Loss: 0.0928, Accuracy: 31.00%\n",
      "Epoch [52/100], Step [200/332], Loss: 0.2459, Accuracy: 29.00%\n",
      "Epoch [52/100], Step [300/332], Loss: 0.1402, Accuracy: 29.00%\n",
      "train Loss: 0.0907 Acc: 0.9682\n",
      "val Loss: 0.1075 Acc: 0.9635\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/332], Loss: 0.0042, Accuracy: 32.00%\n",
      "Epoch [53/100], Step [200/332], Loss: 0.0930, Accuracy: 31.00%\n",
      "Epoch [53/100], Step [300/332], Loss: 0.2040, Accuracy: 29.00%\n",
      "train Loss: 0.0697 Acc: 0.9743\n",
      "val Loss: 0.0926 Acc: 0.9727\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/332], Loss: 0.0152, Accuracy: 32.00%\n",
      "Epoch [54/100], Step [200/332], Loss: 0.0042, Accuracy: 32.00%\n",
      "Epoch [54/100], Step [300/332], Loss: 0.0646, Accuracy: 31.00%\n",
      "train Loss: 0.0522 Acc: 0.9813\n",
      "val Loss: 0.0595 Acc: 0.9776\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/332], Loss: 0.0196, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [200/332], Loss: 0.0273, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [300/332], Loss: 0.0075, Accuracy: 32.00%\n",
      "train Loss: 0.0469 Acc: 0.9823\n",
      "val Loss: 0.0782 Acc: 0.9701\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/332], Loss: 0.0033, Accuracy: 32.00%\n",
      "Epoch [56/100], Step [200/332], Loss: 0.0109, Accuracy: 32.00%\n",
      "Epoch [56/100], Step [300/332], Loss: 0.0056, Accuracy: 32.00%\n",
      "train Loss: 0.0346 Acc: 0.9892\n",
      "val Loss: 0.0507 Acc: 0.9837\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/332], Loss: 0.0186, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [200/332], Loss: 0.0080, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [300/332], Loss: 0.0064, Accuracy: 32.00%\n",
      "train Loss: 0.0269 Acc: 0.9910\n",
      "val Loss: 0.0401 Acc: 0.9868\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/332], Loss: 0.0310, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [200/332], Loss: 0.0069, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [300/332], Loss: 0.0617, Accuracy: 31.00%\n",
      "train Loss: 0.0148 Acc: 0.9947\n",
      "val Loss: 0.0493 Acc: 0.9842\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/332], Loss: 0.0050, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [200/332], Loss: 0.0027, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [300/332], Loss: 0.0318, Accuracy: 31.00%\n",
      "train Loss: 0.0131 Acc: 0.9953\n",
      "val Loss: 0.0537 Acc: 0.9837\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/332], Loss: 0.0012, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0100 Acc: 0.9963\n",
      "val Loss: 0.0403 Acc: 0.9868\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/332], Loss: 0.0563, Accuracy: 31.00%\n",
      "Epoch [61/100], Step [200/332], Loss: 0.3538, Accuracy: 30.00%\n",
      "Epoch [61/100], Step [300/332], Loss: 0.1617, Accuracy: 31.00%\n",
      "train Loss: 0.1038 Acc: 0.9653\n",
      "val Loss: 0.1680 Acc: 0.9468\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/332], Loss: 0.0158, Accuracy: 32.00%\n",
      "Epoch [62/100], Step [200/332], Loss: 0.2501, Accuracy: 27.00%\n",
      "Epoch [62/100], Step [300/332], Loss: 0.0297, Accuracy: 32.00%\n",
      "train Loss: 0.0750 Acc: 0.9738\n",
      "val Loss: 0.0609 Acc: 0.9780\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/332], Loss: 0.0117, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [200/332], Loss: 0.0257, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [300/332], Loss: 0.0029, Accuracy: 32.00%\n",
      "train Loss: 0.0515 Acc: 0.9820\n",
      "val Loss: 0.0532 Acc: 0.9811\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/332], Loss: 0.0106, Accuracy: 32.00%\n",
      "Epoch [64/100], Step [200/332], Loss: 0.0111, Accuracy: 32.00%\n",
      "Epoch [64/100], Step [300/332], Loss: 0.0525, Accuracy: 31.00%\n",
      "train Loss: 0.0429 Acc: 0.9849\n",
      "val Loss: 0.0530 Acc: 0.9806\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/332], Loss: 0.0627, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [200/332], Loss: 0.0104, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [300/332], Loss: 0.0191, Accuracy: 32.00%\n",
      "train Loss: 0.0406 Acc: 0.9856\n",
      "val Loss: 0.0531 Acc: 0.9846\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/332], Loss: 0.0373, Accuracy: 31.00%\n",
      "Epoch [66/100], Step [200/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "Epoch [66/100], Step [300/332], Loss: 0.0022, Accuracy: 32.00%\n",
      "train Loss: 0.0230 Acc: 0.9916\n",
      "val Loss: 0.0634 Acc: 0.9784\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/332], Loss: 0.0131, Accuracy: 32.00%\n",
      "Epoch [67/100], Step [200/332], Loss: 0.0011, Accuracy: 32.00%\n",
      "Epoch [67/100], Step [300/332], Loss: 0.0622, Accuracy: 31.00%\n",
      "train Loss: 0.0249 Acc: 0.9921\n",
      "val Loss: 0.0636 Acc: 0.9815\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/332], Loss: 0.0144, Accuracy: 32.00%\n",
      "Epoch [68/100], Step [200/332], Loss: 0.0447, Accuracy: 31.00%\n",
      "Epoch [68/100], Step [300/332], Loss: 0.0028, Accuracy: 32.00%\n",
      "train Loss: 0.0121 Acc: 0.9962\n",
      "val Loss: 0.0504 Acc: 0.9846\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/332], Loss: 0.0024, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [200/332], Loss: 0.0052, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [300/332], Loss: 0.0011, Accuracy: 32.00%\n",
      "train Loss: 0.0083 Acc: 0.9978\n",
      "val Loss: 0.0499 Acc: 0.9815\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/332], Loss: 0.0023, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [200/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [300/332], Loss: 0.0035, Accuracy: 32.00%\n",
      "train Loss: 0.0065 Acc: 0.9980\n",
      "val Loss: 0.0567 Acc: 0.9815\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/332], Loss: 0.1847, Accuracy: 29.00%\n",
      "Epoch [71/100], Step [200/332], Loss: 0.4013, Accuracy: 28.00%\n",
      "Epoch [71/100], Step [300/332], Loss: 0.1699, Accuracy: 31.00%\n",
      "train Loss: 0.1052 Acc: 0.9660\n",
      "val Loss: 0.1116 Acc: 0.9604\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/332], Loss: 0.2686, Accuracy: 29.00%\n",
      "Epoch [72/100], Step [200/332], Loss: 0.1098, Accuracy: 30.00%\n",
      "Epoch [72/100], Step [300/332], Loss: 0.0718, Accuracy: 31.00%\n",
      "train Loss: 0.0787 Acc: 0.9710\n",
      "val Loss: 0.1138 Acc: 0.9582\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/332], Loss: 0.0660, Accuracy: 31.00%\n",
      "Epoch [73/100], Step [200/332], Loss: 0.0253, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [300/332], Loss: 0.0465, Accuracy: 31.00%\n",
      "train Loss: 0.0540 Acc: 0.9800\n",
      "val Loss: 0.0742 Acc: 0.9754\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/332], Loss: 0.0545, Accuracy: 31.00%\n",
      "Epoch [74/100], Step [200/332], Loss: 0.0286, Accuracy: 31.00%\n",
      "Epoch [74/100], Step [300/332], Loss: 0.0183, Accuracy: 32.00%\n",
      "train Loss: 0.0476 Acc: 0.9831\n",
      "val Loss: 0.0702 Acc: 0.9762\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/332], Loss: 0.1857, Accuracy: 30.00%\n",
      "Epoch [75/100], Step [200/332], Loss: 0.0375, Accuracy: 31.00%\n",
      "Epoch [75/100], Step [300/332], Loss: 0.1832, Accuracy: 31.00%\n",
      "train Loss: 0.0350 Acc: 0.9884\n",
      "val Loss: 0.0671 Acc: 0.9806\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/332], Loss: 0.0063, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [200/332], Loss: 0.0028, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [300/332], Loss: 0.0061, Accuracy: 32.00%\n",
      "train Loss: 0.0249 Acc: 0.9924\n",
      "val Loss: 0.0558 Acc: 0.9842\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/332], Loss: 0.0129, Accuracy: 32.00%\n",
      "Epoch [77/100], Step [200/332], Loss: 0.0016, Accuracy: 32.00%\n",
      "Epoch [77/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0169 Acc: 0.9944\n",
      "val Loss: 0.0483 Acc: 0.9842\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/332], Loss: 0.0007, Accuracy: 32.00%\n",
      "Epoch [78/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [78/100], Step [300/332], Loss: 0.0404, Accuracy: 31.00%\n",
      "train Loss: 0.0095 Acc: 0.9961\n",
      "val Loss: 0.0419 Acc: 0.9859\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/332], Loss: 0.0007, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [200/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0092 Acc: 0.9967\n",
      "val Loss: 0.0386 Acc: 0.9872\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/332], Loss: 0.0025, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [200/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0070 Acc: 0.9979\n",
      "val Loss: 0.0394 Acc: 0.9872\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/332], Loss: 0.2716, Accuracy: 31.00%\n",
      "Epoch [81/100], Step [200/332], Loss: 0.0177, Accuracy: 32.00%\n",
      "Epoch [81/100], Step [300/332], Loss: 0.0355, Accuracy: 31.00%\n",
      "train Loss: 0.1053 Acc: 0.9645\n",
      "val Loss: 0.0955 Acc: 0.9732\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/332], Loss: 0.0054, Accuracy: 32.00%\n",
      "Epoch [82/100], Step [200/332], Loss: 0.0214, Accuracy: 32.00%\n",
      "Epoch [82/100], Step [300/332], Loss: 0.0060, Accuracy: 32.00%\n",
      "train Loss: 0.0644 Acc: 0.9773\n",
      "val Loss: 0.1031 Acc: 0.9705\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/332], Loss: 0.0119, Accuracy: 32.00%\n",
      "Epoch [83/100], Step [200/332], Loss: 0.0615, Accuracy: 31.00%\n",
      "Epoch [83/100], Step [300/332], Loss: 0.0365, Accuracy: 32.00%\n",
      "train Loss: 0.0454 Acc: 0.9830\n",
      "val Loss: 0.0694 Acc: 0.9776\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [200/332], Loss: 0.0373, Accuracy: 31.00%\n",
      "Epoch [84/100], Step [300/332], Loss: 0.0183, Accuracy: 32.00%\n",
      "train Loss: 0.0331 Acc: 0.9887\n",
      "val Loss: 0.0945 Acc: 0.9754\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/332], Loss: 0.0232, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [200/332], Loss: 0.0020, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [300/332], Loss: 0.0941, Accuracy: 31.00%\n",
      "train Loss: 0.0251 Acc: 0.9904\n",
      "val Loss: 0.1008 Acc: 0.9758\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [200/332], Loss: 0.0138, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [300/332], Loss: 0.0713, Accuracy: 30.00%\n",
      "train Loss: 0.0225 Acc: 0.9919\n",
      "val Loss: 0.0710 Acc: 0.9789\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/332], Loss: 0.0199, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [200/332], Loss: 0.0105, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [300/332], Loss: 0.0014, Accuracy: 32.00%\n",
      "train Loss: 0.0187 Acc: 0.9933\n",
      "val Loss: 0.0580 Acc: 0.9828\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/332], Loss: 0.0018, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [200/332], Loss: 0.0027, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [300/332], Loss: 0.0039, Accuracy: 32.00%\n",
      "train Loss: 0.0101 Acc: 0.9965\n",
      "val Loss: 0.0535 Acc: 0.9850\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [200/332], Loss: 0.0023, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [300/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "train Loss: 0.0062 Acc: 0.9977\n",
      "val Loss: 0.0546 Acc: 0.9837\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [300/332], Loss: 0.0457, Accuracy: 31.00%\n",
      "train Loss: 0.0067 Acc: 0.9980\n",
      "val Loss: 0.0541 Acc: 0.9837\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/332], Loss: 0.0208, Accuracy: 32.00%\n",
      "Epoch [91/100], Step [200/332], Loss: 0.0931, Accuracy: 31.00%\n",
      "Epoch [91/100], Step [300/332], Loss: 0.0063, Accuracy: 32.00%\n",
      "train Loss: 0.0765 Acc: 0.9736\n",
      "val Loss: 0.0979 Acc: 0.9679\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/332], Loss: 0.0086, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [200/332], Loss: 0.0118, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [300/332], Loss: 0.0454, Accuracy: 32.00%\n",
      "train Loss: 0.0649 Acc: 0.9788\n",
      "val Loss: 0.1922 Acc: 0.9441\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/332], Loss: 0.1078, Accuracy: 31.00%\n",
      "Epoch [93/100], Step [200/332], Loss: 0.0009, Accuracy: 32.00%\n",
      "Epoch [93/100], Step [300/332], Loss: 0.0800, Accuracy: 31.00%\n",
      "train Loss: 0.0460 Acc: 0.9841\n",
      "val Loss: 0.1176 Acc: 0.9630\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/332], Loss: 0.0025, Accuracy: 32.00%\n",
      "Epoch [94/100], Step [200/332], Loss: 0.0027, Accuracy: 32.00%\n",
      "Epoch [94/100], Step [300/332], Loss: 0.0047, Accuracy: 32.00%\n",
      "train Loss: 0.0348 Acc: 0.9876\n",
      "val Loss: 0.0642 Acc: 0.9762\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/332], Loss: 0.0093, Accuracy: 32.00%\n",
      "Epoch [95/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [95/100], Step [300/332], Loss: 0.0030, Accuracy: 32.00%\n",
      "train Loss: 0.0248 Acc: 0.9911\n",
      "val Loss: 0.0556 Acc: 0.9820\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [300/332], Loss: 0.0037, Accuracy: 32.00%\n",
      "train Loss: 0.0167 Acc: 0.9942\n",
      "val Loss: 0.0851 Acc: 0.9745\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [200/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [300/332], Loss: 0.1006, Accuracy: 31.00%\n",
      "train Loss: 0.0138 Acc: 0.9946\n",
      "val Loss: 0.0592 Acc: 0.9828\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [200/332], Loss: 0.0024, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [300/332], Loss: 0.1176, Accuracy: 31.00%\n",
      "train Loss: 0.0093 Acc: 0.9975\n",
      "val Loss: 0.0508 Acc: 0.9833\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [200/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0069 Acc: 0.9973\n",
      "val Loss: 0.0481 Acc: 0.9837\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0062 Acc: 0.9984\n",
      "val Loss: 0.0544 Acc: 0.9828\n",
      "\n",
      "Training complete in 132m 17s\n",
      "Best val Acc: 0.987242\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=iter_restart, T_mult=mul_restart, \n",
    "                                                           eta_min=lr_end, last_epoch=-1)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'covid_pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.986351228389445\n",
      "f1: 0.9813924786215426\n",
      "cm: [[ 527   13    3]\n",
      " [   7 1443    3]\n",
      " [   1    3  198]]\n",
      "outputs: [0 0 0 ... 2 2 2]\n",
      "targets: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
