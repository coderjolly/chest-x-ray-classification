{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/covid_pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"efficient_net_b1\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Covid Pneumonia dataset metrics\n",
    "norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/332], Loss: 0.9022, Accuracy: 22.00%\n",
      "Epoch [1/100], Step [200/332], Loss: 0.6747, Accuracy: 23.00%\n",
      "Epoch [1/100], Step [300/332], Loss: 0.7103, Accuracy: 26.00%\n",
      "train Loss: 0.7630 Acc: 0.6863\n",
      "val Loss: 0.6219 Acc: 0.7290\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/332], Loss: 0.5952, Accuracy: 22.00%\n",
      "Epoch [2/100], Step [200/332], Loss: 0.5911, Accuracy: 23.00%\n",
      "Epoch [2/100], Step [300/332], Loss: 0.4619, Accuracy: 27.00%\n",
      "train Loss: 0.6058 Acc: 0.7370\n",
      "val Loss: 0.6102 Acc: 0.7281\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/332], Loss: 0.6196, Accuracy: 23.00%\n",
      "Epoch [3/100], Step [200/332], Loss: 0.5227, Accuracy: 26.00%\n",
      "Epoch [3/100], Step [300/332], Loss: 0.6221, Accuracy: 25.00%\n",
      "train Loss: 0.5067 Acc: 0.7865\n",
      "val Loss: 1.0729 Acc: 0.4980\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/332], Loss: 0.3395, Accuracy: 29.00%\n",
      "Epoch [4/100], Step [200/332], Loss: 0.3845, Accuracy: 27.00%\n",
      "Epoch [4/100], Step [300/332], Loss: 0.3888, Accuracy: 28.00%\n",
      "train Loss: 0.4220 Acc: 0.8262\n",
      "val Loss: 0.4526 Acc: 0.8139\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/332], Loss: 0.2983, Accuracy: 29.00%\n",
      "Epoch [5/100], Step [200/332], Loss: 0.4836, Accuracy: 23.00%\n",
      "Epoch [5/100], Step [300/332], Loss: 0.1319, Accuracy: 32.00%\n",
      "train Loss: 0.3830 Acc: 0.8475\n",
      "val Loss: 0.2933 Acc: 0.8878\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/332], Loss: 0.3435, Accuracy: 28.00%\n",
      "Epoch [6/100], Step [200/332], Loss: 0.6083, Accuracy: 25.00%\n",
      "Epoch [6/100], Step [300/332], Loss: 0.2288, Accuracy: 29.00%\n",
      "train Loss: 0.3140 Acc: 0.8772\n",
      "val Loss: 0.2379 Acc: 0.9063\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/332], Loss: 0.1560, Accuracy: 30.00%\n",
      "Epoch [7/100], Step [200/332], Loss: 0.2856, Accuracy: 26.00%\n",
      "Epoch [7/100], Step [300/332], Loss: 0.2428, Accuracy: 30.00%\n",
      "train Loss: 0.2627 Acc: 0.8970\n",
      "val Loss: 1.1526 Acc: 0.6397\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/332], Loss: 0.2227, Accuracy: 29.00%\n",
      "Epoch [8/100], Step [200/332], Loss: 0.3250, Accuracy: 27.00%\n",
      "Epoch [8/100], Step [300/332], Loss: 0.2223, Accuracy: 28.00%\n",
      "train Loss: 0.2370 Acc: 0.9102\n",
      "val Loss: 0.2328 Acc: 0.9089\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/332], Loss: 0.1975, Accuracy: 29.00%\n",
      "Epoch [9/100], Step [200/332], Loss: 0.3537, Accuracy: 29.00%\n",
      "Epoch [9/100], Step [300/332], Loss: 0.1475, Accuracy: 30.00%\n",
      "train Loss: 0.2054 Acc: 0.9253\n",
      "val Loss: 0.1780 Acc: 0.9340\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/332], Loss: 0.3214, Accuracy: 29.00%\n",
      "Epoch [10/100], Step [200/332], Loss: 0.2643, Accuracy: 27.00%\n",
      "Epoch [10/100], Step [300/332], Loss: 0.1536, Accuracy: 30.00%\n",
      "train Loss: 0.1887 Acc: 0.9320\n",
      "val Loss: 0.1408 Acc: 0.9494\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/332], Loss: 0.0726, Accuracy: 31.00%\n",
      "Epoch [11/100], Step [200/332], Loss: 0.2774, Accuracy: 28.00%\n",
      "Epoch [11/100], Step [300/332], Loss: 0.0936, Accuracy: 31.00%\n",
      "train Loss: 0.1836 Acc: 0.9349\n",
      "val Loss: 0.1716 Acc: 0.9375\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/332], Loss: 0.3059, Accuracy: 26.00%\n",
      "Epoch [12/100], Step [200/332], Loss: 0.2230, Accuracy: 29.00%\n",
      "Epoch [12/100], Step [300/332], Loss: 0.1390, Accuracy: 30.00%\n",
      "train Loss: 0.1715 Acc: 0.9376\n",
      "val Loss: 0.1597 Acc: 0.9468\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/332], Loss: 0.1340, Accuracy: 30.00%\n",
      "Epoch [13/100], Step [200/332], Loss: 0.0364, Accuracy: 32.00%\n",
      "Epoch [13/100], Step [300/332], Loss: 0.0501, Accuracy: 32.00%\n",
      "train Loss: 0.1607 Acc: 0.9392\n",
      "val Loss: 0.3197 Acc: 0.8693\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/332], Loss: 0.3585, Accuracy: 30.00%\n",
      "Epoch [14/100], Step [200/332], Loss: 0.3798, Accuracy: 27.00%\n",
      "Epoch [14/100], Step [300/332], Loss: 0.1856, Accuracy: 30.00%\n",
      "train Loss: 0.1445 Acc: 0.9467\n",
      "val Loss: 0.2019 Acc: 0.9182\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/332], Loss: 0.1715, Accuracy: 29.00%\n",
      "Epoch [15/100], Step [200/332], Loss: 0.2334, Accuracy: 28.00%\n",
      "Epoch [15/100], Step [300/332], Loss: 0.3817, Accuracy: 28.00%\n",
      "train Loss: 0.1390 Acc: 0.9485\n",
      "val Loss: 0.1299 Acc: 0.9525\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/332], Loss: 0.1177, Accuracy: 31.00%\n",
      "Epoch [16/100], Step [200/332], Loss: 0.1447, Accuracy: 30.00%\n",
      "Epoch [16/100], Step [300/332], Loss: 0.0494, Accuracy: 32.00%\n",
      "train Loss: 0.1291 Acc: 0.9523\n",
      "val Loss: 0.1044 Acc: 0.9582\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/332], Loss: 0.2518, Accuracy: 30.00%\n",
      "Epoch [17/100], Step [200/332], Loss: 0.1178, Accuracy: 31.00%\n",
      "Epoch [17/100], Step [300/332], Loss: 0.2109, Accuracy: 30.00%\n",
      "train Loss: 0.1307 Acc: 0.9527\n",
      "val Loss: 0.2389 Acc: 0.9173\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/332], Loss: 0.1677, Accuracy: 28.00%\n",
      "Epoch [18/100], Step [200/332], Loss: 0.0322, Accuracy: 32.00%\n",
      "Epoch [18/100], Step [300/332], Loss: 0.0350, Accuracy: 31.00%\n",
      "train Loss: 0.1204 Acc: 0.9579\n",
      "val Loss: 0.1853 Acc: 0.9318\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/332], Loss: 0.1858, Accuracy: 30.00%\n",
      "Epoch [19/100], Step [200/332], Loss: 0.1084, Accuracy: 31.00%\n",
      "Epoch [19/100], Step [300/332], Loss: 0.1860, Accuracy: 29.00%\n",
      "train Loss: 0.1189 Acc: 0.9546\n",
      "val Loss: 0.1472 Acc: 0.9432\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/332], Loss: 0.1044, Accuracy: 30.00%\n",
      "Epoch [20/100], Step [200/332], Loss: 0.2376, Accuracy: 30.00%\n",
      "Epoch [20/100], Step [300/332], Loss: 0.0765, Accuracy: 31.00%\n",
      "train Loss: 0.1115 Acc: 0.9580\n",
      "val Loss: 0.1463 Acc: 0.9446\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/332], Loss: 0.1267, Accuracy: 31.00%\n",
      "Epoch [21/100], Step [200/332], Loss: 0.0362, Accuracy: 32.00%\n",
      "Epoch [21/100], Step [300/332], Loss: 0.0699, Accuracy: 31.00%\n",
      "train Loss: 0.1105 Acc: 0.9597\n",
      "val Loss: 0.1341 Acc: 0.9534\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/332], Loss: 0.0190, Accuracy: 32.00%\n",
      "Epoch [22/100], Step [200/332], Loss: 0.1650, Accuracy: 31.00%\n",
      "Epoch [22/100], Step [300/332], Loss: 0.0229, Accuracy: 32.00%\n",
      "train Loss: 0.1034 Acc: 0.9635\n",
      "val Loss: 0.1309 Acc: 0.9556\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/332], Loss: 0.2727, Accuracy: 30.00%\n",
      "Epoch [23/100], Step [200/332], Loss: 0.0832, Accuracy: 31.00%\n",
      "Epoch [23/100], Step [300/332], Loss: 0.0083, Accuracy: 32.00%\n",
      "train Loss: 0.0999 Acc: 0.9635\n",
      "val Loss: 0.4682 Acc: 0.8887\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/332], Loss: 0.1177, Accuracy: 31.00%\n",
      "Epoch [24/100], Step [200/332], Loss: 0.0567, Accuracy: 31.00%\n",
      "Epoch [24/100], Step [300/332], Loss: 0.0783, Accuracy: 32.00%\n",
      "train Loss: 0.1024 Acc: 0.9622\n",
      "val Loss: 0.1416 Acc: 0.9485\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/332], Loss: 0.1322, Accuracy: 29.00%\n",
      "Epoch [25/100], Step [200/332], Loss: 0.1154, Accuracy: 31.00%\n",
      "Epoch [25/100], Step [300/332], Loss: 0.0422, Accuracy: 31.00%\n",
      "train Loss: 0.0979 Acc: 0.9641\n",
      "val Loss: 0.2740 Acc: 0.8975\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/332], Loss: 0.0924, Accuracy: 31.00%\n",
      "Epoch [26/100], Step [200/332], Loss: 0.0237, Accuracy: 32.00%\n",
      "Epoch [26/100], Step [300/332], Loss: 0.1344, Accuracy: 31.00%\n",
      "train Loss: 0.0908 Acc: 0.9677\n",
      "val Loss: 0.1376 Acc: 0.9547\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/332], Loss: 0.1067, Accuracy: 31.00%\n",
      "Epoch [27/100], Step [200/332], Loss: 0.0726, Accuracy: 31.00%\n",
      "Epoch [27/100], Step [300/332], Loss: 0.0184, Accuracy: 32.00%\n",
      "train Loss: 0.0848 Acc: 0.9696\n",
      "val Loss: 0.1218 Acc: 0.9551\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/332], Loss: 0.1992, Accuracy: 28.00%\n",
      "Epoch [28/100], Step [200/332], Loss: 0.0089, Accuracy: 32.00%\n",
      "Epoch [28/100], Step [300/332], Loss: 0.0091, Accuracy: 32.00%\n",
      "train Loss: 0.0814 Acc: 0.9683\n",
      "val Loss: 0.1743 Acc: 0.9402\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/332], Loss: 0.1789, Accuracy: 29.00%\n",
      "Epoch [29/100], Step [200/332], Loss: 0.1465, Accuracy: 31.00%\n",
      "Epoch [29/100], Step [300/332], Loss: 0.0135, Accuracy: 32.00%\n",
      "train Loss: 0.0794 Acc: 0.9710\n",
      "val Loss: 0.1018 Acc: 0.9661\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/332], Loss: 0.0215, Accuracy: 32.00%\n",
      "Epoch [30/100], Step [200/332], Loss: 0.0616, Accuracy: 31.00%\n",
      "Epoch [30/100], Step [300/332], Loss: 0.0724, Accuracy: 31.00%\n",
      "train Loss: 0.0703 Acc: 0.9751\n",
      "val Loss: 0.1042 Acc: 0.9630\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/332], Loss: 0.0645, Accuracy: 31.00%\n",
      "Epoch [31/100], Step [200/332], Loss: 0.0126, Accuracy: 32.00%\n",
      "Epoch [31/100], Step [300/332], Loss: 0.0948, Accuracy: 30.00%\n",
      "train Loss: 0.0772 Acc: 0.9722\n",
      "val Loss: 0.1437 Acc: 0.9542\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/332], Loss: 0.0720, Accuracy: 30.00%\n",
      "Epoch [32/100], Step [200/332], Loss: 0.0111, Accuracy: 32.00%\n",
      "Epoch [32/100], Step [300/332], Loss: 0.1737, Accuracy: 31.00%\n",
      "train Loss: 0.0701 Acc: 0.9738\n",
      "val Loss: 0.1457 Acc: 0.9534\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/332], Loss: 0.0145, Accuracy: 32.00%\n",
      "Epoch [33/100], Step [200/332], Loss: 0.1116, Accuracy: 30.00%\n",
      "Epoch [33/100], Step [300/332], Loss: 0.0537, Accuracy: 31.00%\n",
      "train Loss: 0.0703 Acc: 0.9754\n",
      "val Loss: 0.0848 Acc: 0.9714\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/332], Loss: 0.0042, Accuracy: 32.00%\n",
      "Epoch [34/100], Step [200/332], Loss: 0.0153, Accuracy: 32.00%\n",
      "Epoch [34/100], Step [300/332], Loss: 0.1694, Accuracy: 29.00%\n",
      "train Loss: 0.0600 Acc: 0.9788\n",
      "val Loss: 0.1120 Acc: 0.9679\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/332], Loss: 0.0047, Accuracy: 32.00%\n",
      "Epoch [35/100], Step [200/332], Loss: 0.0573, Accuracy: 31.00%\n",
      "Epoch [35/100], Step [300/332], Loss: 0.0518, Accuracy: 31.00%\n",
      "train Loss: 0.0587 Acc: 0.9795\n",
      "val Loss: 0.0999 Acc: 0.9670\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/332], Loss: 0.2255, Accuracy: 31.00%\n",
      "Epoch [36/100], Step [200/332], Loss: 0.0903, Accuracy: 31.00%\n",
      "Epoch [36/100], Step [300/332], Loss: 0.0180, Accuracy: 32.00%\n",
      "train Loss: 0.0510 Acc: 0.9822\n",
      "val Loss: 0.1091 Acc: 0.9674\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/332], Loss: 0.0429, Accuracy: 32.00%\n",
      "Epoch [37/100], Step [200/332], Loss: 0.0030, Accuracy: 32.00%\n",
      "Epoch [37/100], Step [300/332], Loss: 0.0251, Accuracy: 32.00%\n",
      "train Loss: 0.0533 Acc: 0.9808\n",
      "val Loss: 0.1417 Acc: 0.9547\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/332], Loss: 0.0620, Accuracy: 31.00%\n",
      "Epoch [38/100], Step [200/332], Loss: 0.0031, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [300/332], Loss: 0.2348, Accuracy: 30.00%\n",
      "train Loss: 0.0483 Acc: 0.9827\n",
      "val Loss: 0.1126 Acc: 0.9626\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/332], Loss: 0.0235, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [200/332], Loss: 0.0083, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [300/332], Loss: 0.0395, Accuracy: 32.00%\n",
      "train Loss: 0.0454 Acc: 0.9839\n",
      "val Loss: 0.1541 Acc: 0.9516\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/332], Loss: 0.0104, Accuracy: 32.00%\n",
      "Epoch [40/100], Step [200/332], Loss: 0.0612, Accuracy: 31.00%\n",
      "Epoch [40/100], Step [300/332], Loss: 0.1965, Accuracy: 30.00%\n",
      "train Loss: 0.0518 Acc: 0.9811\n",
      "val Loss: 0.0972 Acc: 0.9714\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/332], Loss: 0.0105, Accuracy: 32.00%\n",
      "Epoch [41/100], Step [200/332], Loss: 0.0392, Accuracy: 31.00%\n",
      "Epoch [41/100], Step [300/332], Loss: 0.1128, Accuracy: 31.00%\n",
      "train Loss: 0.0430 Acc: 0.9850\n",
      "val Loss: 0.0945 Acc: 0.9696\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/332], Loss: 0.0366, Accuracy: 31.00%\n",
      "Epoch [42/100], Step [200/332], Loss: 0.0137, Accuracy: 32.00%\n",
      "Epoch [42/100], Step [300/332], Loss: 0.0039, Accuracy: 32.00%\n",
      "train Loss: 0.0418 Acc: 0.9842\n",
      "val Loss: 0.1046 Acc: 0.9701\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/332], Loss: 0.0095, Accuracy: 32.00%\n",
      "Epoch [43/100], Step [200/332], Loss: 0.0217, Accuracy: 32.00%\n",
      "Epoch [43/100], Step [300/332], Loss: 0.0512, Accuracy: 31.00%\n",
      "train Loss: 0.0421 Acc: 0.9854\n",
      "val Loss: 0.1126 Acc: 0.9657\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/332], Loss: 0.0499, Accuracy: 31.00%\n",
      "Epoch [44/100], Step [200/332], Loss: 0.0229, Accuracy: 32.00%\n",
      "Epoch [44/100], Step [300/332], Loss: 0.1323, Accuracy: 29.00%\n",
      "train Loss: 0.0481 Acc: 0.9811\n",
      "val Loss: 0.1373 Acc: 0.9560\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/332], Loss: 0.0032, Accuracy: 32.00%\n",
      "Epoch [45/100], Step [200/332], Loss: 0.0190, Accuracy: 32.00%\n",
      "Epoch [45/100], Step [300/332], Loss: 0.0161, Accuracy: 32.00%\n",
      "train Loss: 0.0316 Acc: 0.9885\n",
      "val Loss: 0.1127 Acc: 0.9723\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/332], Loss: 0.0069, Accuracy: 32.00%\n",
      "Epoch [46/100], Step [200/332], Loss: 0.0438, Accuracy: 31.00%\n",
      "Epoch [46/100], Step [300/332], Loss: 0.0047, Accuracy: 32.00%\n",
      "train Loss: 0.0344 Acc: 0.9882\n",
      "val Loss: 0.2068 Acc: 0.9384\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/332], Loss: 0.0028, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [200/332], Loss: 0.0092, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [300/332], Loss: 0.0477, Accuracy: 31.00%\n",
      "train Loss: 0.0298 Acc: 0.9900\n",
      "val Loss: 0.0984 Acc: 0.9723\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/332], Loss: 0.0245, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [200/332], Loss: 0.0038, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [300/332], Loss: 0.0083, Accuracy: 32.00%\n",
      "train Loss: 0.0267 Acc: 0.9906\n",
      "val Loss: 0.1846 Acc: 0.9534\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/332], Loss: 0.0572, Accuracy: 31.00%\n",
      "Epoch [49/100], Step [200/332], Loss: 0.0732, Accuracy: 30.00%\n",
      "Epoch [49/100], Step [300/332], Loss: 0.0026, Accuracy: 32.00%\n",
      "train Loss: 0.0276 Acc: 0.9898\n",
      "val Loss: 0.1509 Acc: 0.9635\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/332], Loss: 0.0015, Accuracy: 32.00%\n",
      "Epoch [50/100], Step [200/332], Loss: 0.0011, Accuracy: 32.00%\n",
      "Epoch [50/100], Step [300/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "train Loss: 0.0255 Acc: 0.9912\n",
      "val Loss: 0.1106 Acc: 0.9749\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/332], Loss: 0.0025, Accuracy: 32.00%\n",
      "Epoch [51/100], Step [200/332], Loss: 0.0757, Accuracy: 29.00%\n",
      "Epoch [51/100], Step [300/332], Loss: 0.0079, Accuracy: 32.00%\n",
      "train Loss: 0.0326 Acc: 0.9881\n",
      "val Loss: 0.1971 Acc: 0.9459\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/332], Loss: 0.0010, Accuracy: 32.00%\n",
      "Epoch [52/100], Step [200/332], Loss: 0.0141, Accuracy: 32.00%\n",
      "Epoch [52/100], Step [300/332], Loss: 0.0049, Accuracy: 32.00%\n",
      "train Loss: 0.0299 Acc: 0.9896\n",
      "val Loss: 0.1385 Acc: 0.9626\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [53/100], Step [200/332], Loss: 0.0015, Accuracy: 32.00%\n",
      "Epoch [53/100], Step [300/332], Loss: 0.0034, Accuracy: 32.00%\n",
      "train Loss: 0.0224 Acc: 0.9919\n",
      "val Loss: 0.1048 Acc: 0.9758\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/332], Loss: 0.0226, Accuracy: 32.00%\n",
      "Epoch [54/100], Step [200/332], Loss: 0.0172, Accuracy: 32.00%\n",
      "Epoch [54/100], Step [300/332], Loss: 0.1293, Accuracy: 31.00%\n",
      "train Loss: 0.0238 Acc: 0.9913\n",
      "val Loss: 0.0929 Acc: 0.9745\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/332], Loss: 0.0020, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [300/332], Loss: 0.0084, Accuracy: 32.00%\n",
      "train Loss: 0.0224 Acc: 0.9906\n",
      "val Loss: 0.0955 Acc: 0.9749\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [56/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [56/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0180 Acc: 0.9941\n",
      "val Loss: 0.1015 Acc: 0.9740\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [200/332], Loss: 0.0014, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [300/332], Loss: 0.0030, Accuracy: 32.00%\n",
      "train Loss: 0.0204 Acc: 0.9922\n",
      "val Loss: 0.1145 Acc: 0.9723\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/332], Loss: 0.0158, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [200/332], Loss: 0.0010, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [300/332], Loss: 0.0180, Accuracy: 32.00%\n",
      "train Loss: 0.0218 Acc: 0.9930\n",
      "val Loss: 0.1115 Acc: 0.9666\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/332], Loss: 0.0009, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [300/332], Loss: 0.0010, Accuracy: 32.00%\n",
      "train Loss: 0.0115 Acc: 0.9966\n",
      "val Loss: 0.1129 Acc: 0.9718\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/332], Loss: 0.0012, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [200/332], Loss: 0.0050, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [300/332], Loss: 0.1037, Accuracy: 30.00%\n",
      "train Loss: 0.0169 Acc: 0.9936\n",
      "val Loss: 0.1155 Acc: 0.9740\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/332], Loss: 0.0076, Accuracy: 32.00%\n",
      "Epoch [61/100], Step [200/332], Loss: 0.0009, Accuracy: 32.00%\n",
      "Epoch [61/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0138 Acc: 0.9942\n",
      "val Loss: 0.0944 Acc: 0.9776\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [62/100], Step [200/332], Loss: 0.0140, Accuracy: 32.00%\n",
      "Epoch [62/100], Step [300/332], Loss: 0.0406, Accuracy: 31.00%\n",
      "train Loss: 0.0153 Acc: 0.9949\n",
      "val Loss: 0.1011 Acc: 0.9776\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [200/332], Loss: 0.0041, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [300/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0104 Acc: 0.9963\n",
      "val Loss: 0.1187 Acc: 0.9758\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/332], Loss: 0.0153, Accuracy: 32.00%\n",
      "Epoch [64/100], Step [200/332], Loss: 0.0011, Accuracy: 32.00%\n",
      "Epoch [64/100], Step [300/332], Loss: 0.0032, Accuracy: 32.00%\n",
      "train Loss: 0.0160 Acc: 0.9950\n",
      "val Loss: 0.1241 Acc: 0.9710\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/332], Loss: 0.0007, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [300/332], Loss: 0.0401, Accuracy: 31.00%\n",
      "train Loss: 0.0137 Acc: 0.9950\n",
      "val Loss: 0.1161 Acc: 0.9749\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/332], Loss: 0.0133, Accuracy: 32.00%\n",
      "Epoch [66/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [66/100], Step [300/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "train Loss: 0.0085 Acc: 0.9973\n",
      "val Loss: 0.1053 Acc: 0.9762\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/332], Loss: 0.0552, Accuracy: 31.00%\n",
      "Epoch [67/100], Step [200/332], Loss: 0.0016, Accuracy: 32.00%\n",
      "Epoch [67/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0128 Acc: 0.9956\n",
      "val Loss: 0.1648 Acc: 0.9626\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/332], Loss: 0.0016, Accuracy: 32.00%\n",
      "Epoch [68/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [68/100], Step [300/332], Loss: 0.0187, Accuracy: 32.00%\n",
      "train Loss: 0.0091 Acc: 0.9967\n",
      "val Loss: 0.1288 Acc: 0.9727\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/332], Loss: 0.0048, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [300/332], Loss: 0.0050, Accuracy: 32.00%\n",
      "train Loss: 0.0098 Acc: 0.9970\n",
      "val Loss: 0.1097 Acc: 0.9789\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/332], Loss: 0.3801, Accuracy: 30.00%\n",
      "Epoch [70/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [300/332], Loss: 0.0493, Accuracy: 31.00%\n",
      "train Loss: 0.0104 Acc: 0.9961\n",
      "val Loss: 0.1712 Acc: 0.9644\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/332], Loss: 0.0015, Accuracy: 32.00%\n",
      "Epoch [71/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [71/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0097 Acc: 0.9965\n",
      "val Loss: 0.1291 Acc: 0.9749\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/332], Loss: 0.0024, Accuracy: 32.00%\n",
      "Epoch [72/100], Step [200/332], Loss: 0.0397, Accuracy: 31.00%\n",
      "Epoch [72/100], Step [300/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "train Loss: 0.0059 Acc: 0.9976\n",
      "val Loss: 0.1227 Acc: 0.9754\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [200/332], Loss: 0.0038, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [300/332], Loss: 0.0029, Accuracy: 32.00%\n",
      "train Loss: 0.0078 Acc: 0.9973\n",
      "val Loss: 0.1188 Acc: 0.9776\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/332], Loss: 0.0011, Accuracy: 32.00%\n",
      "Epoch [74/100], Step [200/332], Loss: 0.0344, Accuracy: 31.00%\n",
      "Epoch [74/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0072 Acc: 0.9975\n",
      "val Loss: 0.1059 Acc: 0.9802\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/332], Loss: 0.0187, Accuracy: 32.00%\n",
      "Epoch [75/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [75/100], Step [300/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "train Loss: 0.0084 Acc: 0.9976\n",
      "val Loss: 0.1288 Acc: 0.9789\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [300/332], Loss: 0.0033, Accuracy: 32.00%\n",
      "train Loss: 0.0070 Acc: 0.9974\n",
      "val Loss: 0.1046 Acc: 0.9784\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [77/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [77/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0057 Acc: 0.9983\n",
      "val Loss: 0.1110 Acc: 0.9798\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [78/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [78/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0057 Acc: 0.9983\n",
      "val Loss: 0.1198 Acc: 0.9723\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/332], Loss: 0.0026, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [300/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "train Loss: 0.0040 Acc: 0.9986\n",
      "val Loss: 0.1223 Acc: 0.9780\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0035 Acc: 0.9989\n",
      "val Loss: 0.1253 Acc: 0.9789\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [81/100], Step [200/332], Loss: 0.0015, Accuracy: 32.00%\n",
      "Epoch [81/100], Step [300/332], Loss: 0.0380, Accuracy: 31.00%\n",
      "train Loss: 0.0051 Acc: 0.9984\n",
      "val Loss: 0.1071 Acc: 0.9780\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [82/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [82/100], Step [300/332], Loss: 0.0024, Accuracy: 32.00%\n",
      "train Loss: 0.0034 Acc: 0.9989\n",
      "val Loss: 0.1130 Acc: 0.9802\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [83/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [83/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0045 Acc: 0.9988\n",
      "val Loss: 0.1303 Acc: 0.9784\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0050 Acc: 0.9984\n",
      "val Loss: 0.1228 Acc: 0.9762\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0031 Acc: 0.9989\n",
      "val Loss: 0.1255 Acc: 0.9776\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/332], Loss: 0.0122, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [200/332], Loss: 0.0010, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0018 Acc: 0.9997\n",
      "val Loss: 0.1268 Acc: 0.9784\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0018 Acc: 0.9995\n",
      "val Loss: 0.1354 Acc: 0.9780\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0042 Acc: 0.9989\n",
      "val Loss: 0.1311 Acc: 0.9767\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [300/332], Loss: 0.0019, Accuracy: 32.00%\n",
      "train Loss: 0.0027 Acc: 0.9992\n",
      "val Loss: 0.1164 Acc: 0.9806\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/332], Loss: 0.0082, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0020 Acc: 0.9994\n",
      "val Loss: 0.1290 Acc: 0.9793\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [91/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [91/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0026 Acc: 0.9992\n",
      "val Loss: 0.1266 Acc: 0.9784\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0015 Acc: 0.9994\n",
      "val Loss: 0.1223 Acc: 0.9806\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [93/100], Step [200/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [93/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0020 Acc: 0.9994\n",
      "val Loss: 0.1631 Acc: 0.9767\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [94/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [94/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0030 Acc: 0.9989\n",
      "val Loss: 0.1320 Acc: 0.9784\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "Epoch [95/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [95/100], Step [300/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "train Loss: 0.0015 Acc: 0.9996\n",
      "val Loss: 0.1282 Acc: 0.9762\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/332], Loss: 0.0019, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0023 Acc: 0.9995\n",
      "val Loss: 0.1312 Acc: 0.9758\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [300/332], Loss: 0.0014, Accuracy: 32.00%\n",
      "train Loss: 0.0029 Acc: 0.9992\n",
      "val Loss: 0.1366 Acc: 0.9784\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0009 Acc: 0.9997\n",
      "val Loss: 0.1352 Acc: 0.9798\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [200/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0016 Acc: 0.9992\n",
      "val Loss: 0.1419 Acc: 0.9758\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/332], Loss: 0.0014, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0012 Acc: 0.9996\n",
      "val Loss: 0.1277 Acc: 0.9798\n",
      "\n",
      "Training complete in 132m 55s\n",
      "Best val Acc: 0.980642\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end, last_epoch=-1)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'covid_pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9810822701275848\n",
      "f1: 0.9709662294805629\n",
      "cm: [[ 528   12    2]\n",
      " [  12 1511    6]\n",
      " [   4    7  191]]\n",
      "outputs: [0 0 0 ... 2 2 2]\n",
      "targets: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
