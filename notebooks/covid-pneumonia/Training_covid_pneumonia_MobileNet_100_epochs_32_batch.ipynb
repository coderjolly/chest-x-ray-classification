{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/covid_pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"mobile_net_v3_large\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Covid Pneumonia dataset metrics\n",
    "norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.0.weight\n",
      "\t features.1.block.1.1.weight\n",
      "\t features.1.block.1.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.0.weight\n",
      "\t features.7.block.2.1.weight\n",
      "\t features.7.block.2.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.0.weight\n",
      "\t features.8.block.2.1.weight\n",
      "\t features.8.block.2.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.0.weight\n",
      "\t features.9.block.2.1.weight\n",
      "\t features.9.block.2.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.0.weight\n",
      "\t features.10.block.2.1.weight\n",
      "\t features.10.block.2.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.block.0.0.weight\n",
      "\t features.12.block.0.1.weight\n",
      "\t features.12.block.0.1.bias\n",
      "\t features.12.block.1.0.weight\n",
      "\t features.12.block.1.1.weight\n",
      "\t features.12.block.1.1.bias\n",
      "\t features.12.block.2.fc1.weight\n",
      "\t features.12.block.2.fc1.bias\n",
      "\t features.12.block.2.fc2.weight\n",
      "\t features.12.block.2.fc2.bias\n",
      "\t features.12.block.3.0.weight\n",
      "\t features.12.block.3.1.weight\n",
      "\t features.12.block.3.1.bias\n",
      "\t features.13.block.0.0.weight\n",
      "\t features.13.block.0.1.weight\n",
      "\t features.13.block.0.1.bias\n",
      "\t features.13.block.1.0.weight\n",
      "\t features.13.block.1.1.weight\n",
      "\t features.13.block.1.1.bias\n",
      "\t features.13.block.2.fc1.weight\n",
      "\t features.13.block.2.fc1.bias\n",
      "\t features.13.block.2.fc2.weight\n",
      "\t features.13.block.2.fc2.bias\n",
      "\t features.13.block.3.0.weight\n",
      "\t features.13.block.3.1.weight\n",
      "\t features.13.block.3.1.bias\n",
      "\t features.14.block.0.0.weight\n",
      "\t features.14.block.0.1.weight\n",
      "\t features.14.block.0.1.bias\n",
      "\t features.14.block.1.0.weight\n",
      "\t features.14.block.1.1.weight\n",
      "\t features.14.block.1.1.bias\n",
      "\t features.14.block.2.fc1.weight\n",
      "\t features.14.block.2.fc1.bias\n",
      "\t features.14.block.2.fc2.weight\n",
      "\t features.14.block.2.fc2.bias\n",
      "\t features.14.block.3.0.weight\n",
      "\t features.14.block.3.1.weight\n",
      "\t features.14.block.3.1.bias\n",
      "\t features.15.block.0.0.weight\n",
      "\t features.15.block.0.1.weight\n",
      "\t features.15.block.0.1.bias\n",
      "\t features.15.block.1.0.weight\n",
      "\t features.15.block.1.1.weight\n",
      "\t features.15.block.1.1.bias\n",
      "\t features.15.block.2.fc1.weight\n",
      "\t features.15.block.2.fc1.bias\n",
      "\t features.15.block.2.fc2.weight\n",
      "\t features.15.block.2.fc2.bias\n",
      "\t features.15.block.3.0.weight\n",
      "\t features.15.block.3.1.weight\n",
      "\t features.15.block.3.1.bias\n",
      "\t features.16.0.weight\n",
      "\t features.16.1.weight\n",
      "\t features.16.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/332], Loss: 0.6550, Accuracy: 24.00%\n",
      "Epoch [1/100], Step [200/332], Loss: 0.9993, Accuracy: 19.00%\n",
      "Epoch [1/100], Step [300/332], Loss: 0.5119, Accuracy: 22.00%\n",
      "train Loss: 0.8363 Acc: 0.6879\n",
      "val Loss: 1.1647 Acc: 0.7013\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/332], Loss: 0.5759, Accuracy: 24.00%\n",
      "Epoch [2/100], Step [200/332], Loss: 0.6954, Accuracy: 24.00%\n",
      "Epoch [2/100], Step [300/332], Loss: 0.3354, Accuracy: 28.00%\n",
      "train Loss: 0.5366 Acc: 0.7724\n",
      "val Loss: 2.2784 Acc: 0.6595\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/332], Loss: 0.3222, Accuracy: 29.00%\n",
      "Epoch [3/100], Step [200/332], Loss: 0.3873, Accuracy: 29.00%\n",
      "Epoch [3/100], Step [300/332], Loss: 0.3275, Accuracy: 28.00%\n",
      "train Loss: 0.4653 Acc: 0.8074\n",
      "val Loss: 0.5728 Acc: 0.7809\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/332], Loss: 0.3552, Accuracy: 27.00%\n",
      "Epoch [4/100], Step [200/332], Loss: 0.3349, Accuracy: 28.00%\n",
      "Epoch [4/100], Step [300/332], Loss: 0.5224, Accuracy: 24.00%\n",
      "train Loss: 0.4074 Acc: 0.8320\n",
      "val Loss: 0.6972 Acc: 0.8003\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/332], Loss: 0.5457, Accuracy: 25.00%\n",
      "Epoch [5/100], Step [200/332], Loss: 0.2182, Accuracy: 29.00%\n",
      "Epoch [5/100], Step [300/332], Loss: 0.5447, Accuracy: 26.00%\n",
      "train Loss: 0.3454 Acc: 0.8579\n",
      "val Loss: 0.7017 Acc: 0.7664\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/332], Loss: 0.2901, Accuracy: 28.00%\n",
      "Epoch [6/100], Step [200/332], Loss: 0.3472, Accuracy: 27.00%\n",
      "Epoch [6/100], Step [300/332], Loss: 0.6907, Accuracy: 22.00%\n",
      "train Loss: 0.3024 Acc: 0.8814\n",
      "val Loss: 0.3932 Acc: 0.8385\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/332], Loss: 0.2775, Accuracy: 30.00%\n",
      "Epoch [7/100], Step [200/332], Loss: 0.3650, Accuracy: 26.00%\n",
      "Epoch [7/100], Step [300/332], Loss: 0.1701, Accuracy: 29.00%\n",
      "train Loss: 0.2421 Acc: 0.9102\n",
      "val Loss: 0.6260 Acc: 0.7963\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/332], Loss: 0.1290, Accuracy: 32.00%\n",
      "Epoch [8/100], Step [200/332], Loss: 0.2729, Accuracy: 30.00%\n",
      "Epoch [8/100], Step [300/332], Loss: 0.4799, Accuracy: 27.00%\n",
      "train Loss: 0.1940 Acc: 0.9294\n",
      "val Loss: 0.3601 Acc: 0.8605\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/332], Loss: 0.1207, Accuracy: 30.00%\n",
      "Epoch [9/100], Step [200/332], Loss: 0.1288, Accuracy: 30.00%\n",
      "Epoch [9/100], Step [300/332], Loss: 0.0882, Accuracy: 32.00%\n",
      "train Loss: 0.1582 Acc: 0.9426\n",
      "val Loss: 0.1955 Acc: 0.9318\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/332], Loss: 0.0984, Accuracy: 31.00%\n",
      "Epoch [10/100], Step [200/332], Loss: 0.1012, Accuracy: 31.00%\n",
      "Epoch [10/100], Step [300/332], Loss: 0.0401, Accuracy: 32.00%\n",
      "train Loss: 0.1363 Acc: 0.9501\n",
      "val Loss: 0.2731 Acc: 0.8971\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/332], Loss: 0.8782, Accuracy: 18.00%\n",
      "Epoch [11/100], Step [200/332], Loss: 0.4828, Accuracy: 28.00%\n",
      "Epoch [11/100], Step [300/332], Loss: 0.3912, Accuracy: 27.00%\n",
      "train Loss: 0.7740 Acc: 0.7255\n",
      "val Loss: 3.1584 Acc: 0.6762\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/332], Loss: 0.6345, Accuracy: 23.00%\n",
      "Epoch [12/100], Step [200/332], Loss: 0.5422, Accuracy: 26.00%\n",
      "Epoch [12/100], Step [300/332], Loss: 0.4636, Accuracy: 26.00%\n",
      "train Loss: 0.4456 Acc: 0.8128\n",
      "val Loss: 0.9816 Acc: 0.6502\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/332], Loss: 0.2631, Accuracy: 28.00%\n",
      "Epoch [13/100], Step [200/332], Loss: 0.2851, Accuracy: 30.00%\n",
      "Epoch [13/100], Step [300/332], Loss: 0.1406, Accuracy: 31.00%\n",
      "train Loss: 0.3443 Acc: 0.8623\n",
      "val Loss: 0.3832 Acc: 0.8390\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/332], Loss: 0.2152, Accuracy: 29.00%\n",
      "Epoch [14/100], Step [200/332], Loss: 0.2462, Accuracy: 29.00%\n",
      "Epoch [14/100], Step [300/332], Loss: 0.1259, Accuracy: 30.00%\n",
      "train Loss: 0.2722 Acc: 0.8960\n",
      "val Loss: 0.2783 Acc: 0.8988\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/332], Loss: 0.2436, Accuracy: 29.00%\n",
      "Epoch [15/100], Step [200/332], Loss: 0.2900, Accuracy: 28.00%\n",
      "Epoch [15/100], Step [300/332], Loss: 0.1642, Accuracy: 30.00%\n",
      "train Loss: 0.2478 Acc: 0.9059\n",
      "val Loss: 0.6033 Acc: 0.7796\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/332], Loss: 0.1074, Accuracy: 30.00%\n",
      "Epoch [16/100], Step [200/332], Loss: 0.1047, Accuracy: 31.00%\n",
      "Epoch [16/100], Step [300/332], Loss: 0.0852, Accuracy: 30.00%\n",
      "train Loss: 0.1977 Acc: 0.9259\n",
      "val Loss: 1.8441 Acc: 0.4879\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/332], Loss: 0.2233, Accuracy: 29.00%\n",
      "Epoch [17/100], Step [200/332], Loss: 0.0811, Accuracy: 31.00%\n",
      "Epoch [17/100], Step [300/332], Loss: 0.0649, Accuracy: 31.00%\n",
      "train Loss: 0.1734 Acc: 0.9355\n",
      "val Loss: 0.1858 Acc: 0.9292\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/332], Loss: 0.3771, Accuracy: 28.00%\n",
      "Epoch [18/100], Step [200/332], Loss: 0.2529, Accuracy: 29.00%\n",
      "Epoch [18/100], Step [300/332], Loss: 0.1053, Accuracy: 31.00%\n",
      "train Loss: 0.1404 Acc: 0.9494\n",
      "val Loss: 0.4515 Acc: 0.8152\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/332], Loss: 0.2614, Accuracy: 29.00%\n",
      "Epoch [19/100], Step [200/332], Loss: 0.2103, Accuracy: 29.00%\n",
      "Epoch [19/100], Step [300/332], Loss: 0.0904, Accuracy: 31.00%\n",
      "train Loss: 0.1220 Acc: 0.9546\n",
      "val Loss: 0.1480 Acc: 0.9437\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/332], Loss: 0.0156, Accuracy: 32.00%\n",
      "Epoch [20/100], Step [200/332], Loss: 0.0426, Accuracy: 32.00%\n",
      "Epoch [20/100], Step [300/332], Loss: 0.0059, Accuracy: 32.00%\n",
      "train Loss: 0.1043 Acc: 0.9634\n",
      "val Loss: 0.2964 Acc: 0.8878\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/332], Loss: 0.5538, Accuracy: 27.00%\n",
      "Epoch [21/100], Step [200/332], Loss: 2.0766, Accuracy: 19.00%\n",
      "Epoch [21/100], Step [300/332], Loss: 0.2886, Accuracy: 29.00%\n",
      "train Loss: 0.8500 Acc: 0.8254\n",
      "val Loss: 0.8293 Acc: 0.7910\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/332], Loss: 0.0605, Accuracy: 32.00%\n",
      "Epoch [22/100], Step [200/332], Loss: 0.2572, Accuracy: 30.00%\n",
      "Epoch [22/100], Step [300/332], Loss: 0.1135, Accuracy: 31.00%\n",
      "train Loss: 0.2518 Acc: 0.9056\n",
      "val Loss: 0.3183 Acc: 0.8861\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/332], Loss: 0.0968, Accuracy: 31.00%\n",
      "Epoch [23/100], Step [200/332], Loss: 0.3652, Accuracy: 28.00%\n",
      "Epoch [23/100], Step [300/332], Loss: 0.2473, Accuracy: 30.00%\n",
      "train Loss: 0.2051 Acc: 0.9247\n",
      "val Loss: 0.2675 Acc: 0.9010\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/332], Loss: 0.0799, Accuracy: 31.00%\n",
      "Epoch [24/100], Step [200/332], Loss: 0.1178, Accuracy: 31.00%\n",
      "Epoch [24/100], Step [300/332], Loss: 0.2101, Accuracy: 30.00%\n",
      "train Loss: 0.1749 Acc: 0.9355\n",
      "val Loss: 0.1294 Acc: 0.9551\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/332], Loss: 0.1981, Accuracy: 28.00%\n",
      "Epoch [25/100], Step [200/332], Loss: 0.0616, Accuracy: 31.00%\n",
      "Epoch [25/100], Step [300/332], Loss: 0.0465, Accuracy: 32.00%\n",
      "train Loss: 0.1622 Acc: 0.9412\n",
      "val Loss: 0.1904 Acc: 0.9336\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/332], Loss: 0.0149, Accuracy: 32.00%\n",
      "Epoch [26/100], Step [200/332], Loss: 0.2248, Accuracy: 29.00%\n",
      "Epoch [26/100], Step [300/332], Loss: 0.0899, Accuracy: 31.00%\n",
      "train Loss: 0.1374 Acc: 0.9519\n",
      "val Loss: 0.3186 Acc: 0.9006\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/332], Loss: 0.1278, Accuracy: 31.00%\n",
      "Epoch [27/100], Step [200/332], Loss: 0.2142, Accuracy: 30.00%\n",
      "Epoch [27/100], Step [300/332], Loss: 0.2617, Accuracy: 29.00%\n",
      "train Loss: 0.1187 Acc: 0.9591\n",
      "val Loss: 0.2691 Acc: 0.8909\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/332], Loss: 0.0316, Accuracy: 32.00%\n",
      "Epoch [28/100], Step [200/332], Loss: 0.0725, Accuracy: 31.00%\n",
      "Epoch [28/100], Step [300/332], Loss: 0.2732, Accuracy: 27.00%\n",
      "train Loss: 0.1020 Acc: 0.9640\n",
      "val Loss: 0.1530 Acc: 0.9472\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/332], Loss: 0.0162, Accuracy: 32.00%\n",
      "Epoch [29/100], Step [200/332], Loss: 0.0354, Accuracy: 32.00%\n",
      "Epoch [29/100], Step [300/332], Loss: 0.0569, Accuracy: 32.00%\n",
      "train Loss: 0.0879 Acc: 0.9708\n",
      "val Loss: 0.1201 Acc: 0.9569\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/332], Loss: 0.0833, Accuracy: 31.00%\n",
      "Epoch [30/100], Step [200/332], Loss: 0.0045, Accuracy: 32.00%\n",
      "Epoch [30/100], Step [300/332], Loss: 0.0253, Accuracy: 32.00%\n",
      "train Loss: 0.0725 Acc: 0.9745\n",
      "val Loss: 0.1003 Acc: 0.9679\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/332], Loss: 0.0472, Accuracy: 31.00%\n",
      "Epoch [31/100], Step [200/332], Loss: 0.2092, Accuracy: 29.00%\n",
      "Epoch [31/100], Step [300/332], Loss: 0.1165, Accuracy: 31.00%\n",
      "train Loss: 0.2041 Acc: 0.9273\n",
      "val Loss: 0.6730 Acc: 0.7620\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/332], Loss: 0.3303, Accuracy: 28.00%\n",
      "Epoch [32/100], Step [200/332], Loss: 0.1000, Accuracy: 31.00%\n",
      "Epoch [32/100], Step [300/332], Loss: 0.3256, Accuracy: 29.00%\n",
      "train Loss: 0.1787 Acc: 0.9374\n",
      "val Loss: 0.4128 Acc: 0.8729\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/332], Loss: 0.0612, Accuracy: 31.00%\n",
      "Epoch [33/100], Step [200/332], Loss: 0.0920, Accuracy: 31.00%\n",
      "Epoch [33/100], Step [300/332], Loss: 0.5883, Accuracy: 28.00%\n",
      "train Loss: 0.1515 Acc: 0.9445\n",
      "val Loss: 1.3488 Acc: 0.7664\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/332], Loss: 0.2539, Accuracy: 29.00%\n",
      "Epoch [34/100], Step [200/332], Loss: 0.0212, Accuracy: 32.00%\n",
      "Epoch [34/100], Step [300/332], Loss: 0.0849, Accuracy: 31.00%\n",
      "train Loss: 0.1480 Acc: 0.9470\n",
      "val Loss: 2.2148 Acc: 0.5755\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/332], Loss: 0.0398, Accuracy: 32.00%\n",
      "Epoch [35/100], Step [200/332], Loss: 0.3667, Accuracy: 28.00%\n",
      "Epoch [35/100], Step [300/332], Loss: 0.1953, Accuracy: 30.00%\n",
      "train Loss: 0.1229 Acc: 0.9570\n",
      "val Loss: 0.1153 Acc: 0.9595\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/332], Loss: 0.1486, Accuracy: 31.00%\n",
      "Epoch [36/100], Step [200/332], Loss: 0.1062, Accuracy: 31.00%\n",
      "Epoch [36/100], Step [300/332], Loss: 0.0716, Accuracy: 32.00%\n",
      "train Loss: 0.1062 Acc: 0.9621\n",
      "val Loss: 0.4404 Acc: 0.8500\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/332], Loss: 0.1456, Accuracy: 31.00%\n",
      "Epoch [37/100], Step [200/332], Loss: 0.0994, Accuracy: 30.00%\n",
      "Epoch [37/100], Step [300/332], Loss: 0.3063, Accuracy: 29.00%\n",
      "train Loss: 0.0829 Acc: 0.9719\n",
      "val Loss: 0.1106 Acc: 0.9582\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/332], Loss: 0.0172, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [200/332], Loss: 0.0576, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [300/332], Loss: 0.0103, Accuracy: 32.00%\n",
      "train Loss: 0.0707 Acc: 0.9752\n",
      "val Loss: 0.0961 Acc: 0.9727\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/332], Loss: 0.0441, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [200/332], Loss: 0.0276, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [300/332], Loss: 0.0298, Accuracy: 32.00%\n",
      "train Loss: 0.0592 Acc: 0.9795\n",
      "val Loss: 0.1816 Acc: 0.9393\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/332], Loss: 0.1017, Accuracy: 31.00%\n",
      "Epoch [40/100], Step [200/332], Loss: 0.1790, Accuracy: 31.00%\n",
      "Epoch [40/100], Step [300/332], Loss: 0.0093, Accuracy: 32.00%\n",
      "train Loss: 0.0430 Acc: 0.9852\n",
      "val Loss: 0.1030 Acc: 0.9688\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/332], Loss: 0.6232, Accuracy: 25.00%\n",
      "Epoch [41/100], Step [200/332], Loss: 0.3480, Accuracy: 27.00%\n",
      "Epoch [41/100], Step [300/332], Loss: 0.4443, Accuracy: 24.00%\n",
      "train Loss: 0.5974 Acc: 0.8072\n",
      "val Loss: 244.2122 Acc: 0.3141\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/332], Loss: 0.4597, Accuracy: 25.00%\n",
      "Epoch [42/100], Step [200/332], Loss: 0.3635, Accuracy: 27.00%\n",
      "Epoch [42/100], Step [300/332], Loss: 0.4106, Accuracy: 27.00%\n",
      "train Loss: 0.3578 Acc: 0.8557\n",
      "val Loss: 1.4187 Acc: 0.7360\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/332], Loss: 0.3362, Accuracy: 28.00%\n",
      "Epoch [43/100], Step [200/332], Loss: 0.3747, Accuracy: 26.00%\n",
      "Epoch [43/100], Step [300/332], Loss: 0.5827, Accuracy: 28.00%\n",
      "train Loss: 0.3012 Acc: 0.8937\n",
      "val Loss: 0.4308 Acc: 0.8434\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/332], Loss: 0.1345, Accuracy: 30.00%\n",
      "Epoch [44/100], Step [200/332], Loss: 0.1222, Accuracy: 31.00%\n",
      "Epoch [44/100], Step [300/332], Loss: 0.2238, Accuracy: 29.00%\n",
      "train Loss: 0.2306 Acc: 0.9260\n",
      "val Loss: 0.3997 Acc: 0.8817\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/332], Loss: 0.1790, Accuracy: 30.00%\n",
      "Epoch [45/100], Step [200/332], Loss: 0.2420, Accuracy: 28.00%\n",
      "Epoch [45/100], Step [300/332], Loss: 0.0931, Accuracy: 31.00%\n",
      "train Loss: 0.1964 Acc: 0.9371\n",
      "val Loss: 1.9288 Acc: 0.4633\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/332], Loss: 0.1014, Accuracy: 30.00%\n",
      "Epoch [46/100], Step [200/332], Loss: 0.1173, Accuracy: 31.00%\n",
      "Epoch [46/100], Step [300/332], Loss: 0.2751, Accuracy: 29.00%\n",
      "train Loss: 0.1543 Acc: 0.9481\n",
      "val Loss: 0.1899 Acc: 0.9380\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/332], Loss: 0.1139, Accuracy: 30.00%\n",
      "Epoch [47/100], Step [200/332], Loss: 0.0321, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [300/332], Loss: 0.0792, Accuracy: 30.00%\n",
      "train Loss: 0.1189 Acc: 0.9641\n",
      "val Loss: 0.1917 Acc: 0.9344\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/332], Loss: 0.0308, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [200/332], Loss: 0.0190, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [300/332], Loss: 0.1415, Accuracy: 31.00%\n",
      "train Loss: 0.1025 Acc: 0.9679\n",
      "val Loss: 0.2503 Acc: 0.9239\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/332], Loss: 0.0476, Accuracy: 32.00%\n",
      "Epoch [49/100], Step [200/332], Loss: 0.0434, Accuracy: 31.00%\n",
      "Epoch [49/100], Step [300/332], Loss: 0.1581, Accuracy: 31.00%\n",
      "train Loss: 0.0858 Acc: 0.9745\n",
      "val Loss: 0.1375 Acc: 0.9586\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/332], Loss: 0.2002, Accuracy: 31.00%\n",
      "Epoch [50/100], Step [200/332], Loss: 0.1358, Accuracy: 30.00%\n",
      "Epoch [50/100], Step [300/332], Loss: 0.0088, Accuracy: 32.00%\n",
      "train Loss: 0.0726 Acc: 0.9771\n",
      "val Loss: 0.0900 Acc: 0.9727\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/332], Loss: 0.1263, Accuracy: 30.00%\n",
      "Epoch [51/100], Step [200/332], Loss: 0.1231, Accuracy: 31.00%\n",
      "Epoch [51/100], Step [300/332], Loss: 0.0926, Accuracy: 31.00%\n",
      "train Loss: 0.1994 Acc: 0.9358\n",
      "val Loss: 0.3103 Acc: 0.8940\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/332], Loss: 0.2390, Accuracy: 27.00%\n",
      "Epoch [52/100], Step [200/332], Loss: 0.0488, Accuracy: 32.00%\n",
      "Epoch [52/100], Step [300/332], Loss: 0.1104, Accuracy: 31.00%\n",
      "train Loss: 0.1595 Acc: 0.9464\n",
      "val Loss: 0.1767 Acc: 0.9384\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/332], Loss: 0.2894, Accuracy: 28.00%\n",
      "Epoch [53/100], Step [200/332], Loss: 0.1579, Accuracy: 30.00%\n",
      "Epoch [53/100], Step [300/332], Loss: 0.0335, Accuracy: 32.00%\n",
      "train Loss: 0.1385 Acc: 0.9559\n",
      "val Loss: 0.2283 Acc: 0.9151\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/332], Loss: 0.2415, Accuracy: 29.00%\n",
      "Epoch [54/100], Step [200/332], Loss: 0.1543, Accuracy: 30.00%\n",
      "Epoch [54/100], Step [300/332], Loss: 0.1540, Accuracy: 30.00%\n",
      "train Loss: 0.1489 Acc: 0.9514\n",
      "val Loss: 0.2642 Acc: 0.9208\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/332], Loss: 0.1077, Accuracy: 31.00%\n",
      "Epoch [55/100], Step [200/332], Loss: 0.0055, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [300/332], Loss: 0.4277, Accuracy: 30.00%\n",
      "train Loss: 0.1132 Acc: 0.9629\n",
      "val Loss: 0.3049 Acc: 0.9256\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/332], Loss: 0.1399, Accuracy: 31.00%\n",
      "Epoch [56/100], Step [200/332], Loss: 0.1393, Accuracy: 30.00%\n",
      "Epoch [56/100], Step [300/332], Loss: 0.0524, Accuracy: 31.00%\n",
      "train Loss: 0.0912 Acc: 0.9699\n",
      "val Loss: 0.2869 Acc: 0.9366\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/332], Loss: 0.1534, Accuracy: 30.00%\n",
      "Epoch [57/100], Step [200/332], Loss: 0.0423, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [300/332], Loss: 0.0708, Accuracy: 31.00%\n",
      "train Loss: 0.0826 Acc: 0.9742\n",
      "val Loss: 0.1626 Acc: 0.9393\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [200/332], Loss: 0.0112, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [300/332], Loss: 0.0047, Accuracy: 32.00%\n",
      "train Loss: 0.0581 Acc: 0.9825\n",
      "val Loss: 0.1146 Acc: 0.9683\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/332], Loss: 0.0628, Accuracy: 31.00%\n",
      "Epoch [59/100], Step [200/332], Loss: 0.0042, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [300/332], Loss: 0.0553, Accuracy: 32.00%\n",
      "train Loss: 0.0522 Acc: 0.9826\n",
      "val Loss: 0.0821 Acc: 0.9798\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/332], Loss: 0.1571, Accuracy: 31.00%\n",
      "Epoch [60/100], Step [200/332], Loss: 0.0053, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [300/332], Loss: 0.0137, Accuracy: 32.00%\n",
      "train Loss: 0.0373 Acc: 0.9882\n",
      "val Loss: 0.0862 Acc: 0.9762\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/332], Loss: 0.0226, Accuracy: 32.00%\n",
      "Epoch [61/100], Step [200/332], Loss: 0.0503, Accuracy: 32.00%\n",
      "Epoch [61/100], Step [300/332], Loss: 0.0499, Accuracy: 32.00%\n",
      "train Loss: 0.1553 Acc: 0.9515\n",
      "val Loss: 0.3059 Acc: 0.9085\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/332], Loss: 0.3443, Accuracy: 30.00%\n",
      "Epoch [62/100], Step [200/332], Loss: 0.1405, Accuracy: 29.00%\n",
      "Epoch [62/100], Step [300/332], Loss: 0.2278, Accuracy: 29.00%\n",
      "train Loss: 0.1831 Acc: 0.9432\n",
      "val Loss: 0.2911 Acc: 0.9327\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/332], Loss: 0.0154, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [200/332], Loss: 0.1698, Accuracy: 31.00%\n",
      "Epoch [63/100], Step [300/332], Loss: 0.0250, Accuracy: 32.00%\n",
      "train Loss: 0.1259 Acc: 0.9615\n",
      "val Loss: 0.3723 Acc: 0.9041\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/332], Loss: 0.0486, Accuracy: 31.00%\n",
      "Epoch [64/100], Step [200/332], Loss: 0.1205, Accuracy: 30.00%\n",
      "Epoch [64/100], Step [300/332], Loss: 0.0776, Accuracy: 31.00%\n",
      "train Loss: 0.1104 Acc: 0.9644\n",
      "val Loss: 0.1586 Acc: 0.9507\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/332], Loss: 0.0921, Accuracy: 31.00%\n",
      "Epoch [65/100], Step [200/332], Loss: 0.0144, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [300/332], Loss: 0.0566, Accuracy: 32.00%\n",
      "train Loss: 0.0884 Acc: 0.9700\n",
      "val Loss: 0.5228 Acc: 0.8742\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/332], Loss: 0.0305, Accuracy: 32.00%\n",
      "Epoch [66/100], Step [200/332], Loss: 0.0175, Accuracy: 32.00%\n",
      "Epoch [66/100], Step [300/332], Loss: 0.0330, Accuracy: 31.00%\n",
      "train Loss: 0.0697 Acc: 0.9775\n",
      "val Loss: 0.3075 Acc: 0.9428\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [67/100], Step [200/332], Loss: 0.0691, Accuracy: 30.00%\n",
      "Epoch [67/100], Step [300/332], Loss: 0.0746, Accuracy: 31.00%\n",
      "train Loss: 0.0581 Acc: 0.9817\n",
      "val Loss: 0.1027 Acc: 0.9736\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/332], Loss: 0.0726, Accuracy: 31.00%\n",
      "Epoch [68/100], Step [200/332], Loss: 0.1782, Accuracy: 30.00%\n",
      "Epoch [68/100], Step [300/332], Loss: 0.0127, Accuracy: 32.00%\n",
      "train Loss: 0.0538 Acc: 0.9844\n",
      "val Loss: 0.0965 Acc: 0.9758\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/332], Loss: 0.0376, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [200/332], Loss: 0.0067, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [300/332], Loss: 0.0026, Accuracy: 32.00%\n",
      "train Loss: 0.0346 Acc: 0.9883\n",
      "val Loss: 0.0936 Acc: 0.9762\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/332], Loss: 0.0089, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [300/332], Loss: 0.0087, Accuracy: 32.00%\n",
      "train Loss: 0.0339 Acc: 0.9900\n",
      "val Loss: 0.1065 Acc: 0.9745\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/332], Loss: 0.1809, Accuracy: 31.00%\n",
      "Epoch [71/100], Step [200/332], Loss: 0.0859, Accuracy: 31.00%\n",
      "Epoch [71/100], Step [300/332], Loss: 0.1833, Accuracy: 30.00%\n",
      "train Loss: 0.1600 Acc: 0.9451\n",
      "val Loss: 0.2713 Acc: 0.9155\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/332], Loss: 0.2128, Accuracy: 28.00%\n",
      "Epoch [72/100], Step [200/332], Loss: 0.1436, Accuracy: 31.00%\n",
      "Epoch [72/100], Step [300/332], Loss: 0.1158, Accuracy: 31.00%\n",
      "train Loss: 0.1666 Acc: 0.9432\n",
      "val Loss: 0.1819 Acc: 0.9406\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/332], Loss: 0.0722, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [200/332], Loss: 0.0469, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [300/332], Loss: 0.0793, Accuracy: 31.00%\n",
      "train Loss: 0.1112 Acc: 0.9617\n",
      "val Loss: 6.1135 Acc: 0.4593\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/332], Loss: 0.0626, Accuracy: 31.00%\n",
      "Epoch [74/100], Step [200/332], Loss: 0.0885, Accuracy: 30.00%\n",
      "Epoch [74/100], Step [300/332], Loss: 0.0130, Accuracy: 32.00%\n",
      "train Loss: 0.0934 Acc: 0.9676\n",
      "val Loss: 0.2881 Acc: 0.9437\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/332], Loss: 0.0206, Accuracy: 32.00%\n",
      "Epoch [75/100], Step [200/332], Loss: 0.0683, Accuracy: 31.00%\n",
      "Epoch [75/100], Step [300/332], Loss: 0.0547, Accuracy: 31.00%\n",
      "train Loss: 0.0745 Acc: 0.9763\n",
      "val Loss: 0.3131 Acc: 0.9380\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/332], Loss: 0.0026, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [200/332], Loss: 0.0476, Accuracy: 31.00%\n",
      "Epoch [76/100], Step [300/332], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0686 Acc: 0.9779\n",
      "val Loss: 0.1456 Acc: 0.9622\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/332], Loss: 0.0296, Accuracy: 31.00%\n",
      "Epoch [77/100], Step [200/332], Loss: 0.0708, Accuracy: 31.00%\n",
      "Epoch [77/100], Step [300/332], Loss: 0.1060, Accuracy: 31.00%\n",
      "train Loss: 0.0520 Acc: 0.9836\n",
      "val Loss: 0.1046 Acc: 0.9696\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/332], Loss: 0.0920, Accuracy: 31.00%\n",
      "Epoch [78/100], Step [200/332], Loss: 0.0425, Accuracy: 31.00%\n",
      "Epoch [78/100], Step [300/332], Loss: 0.0198, Accuracy: 32.00%\n",
      "train Loss: 0.0418 Acc: 0.9864\n",
      "val Loss: 0.1267 Acc: 0.9595\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/332], Loss: 0.1418, Accuracy: 31.00%\n",
      "Epoch [79/100], Step [200/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [300/332], Loss: 0.0094, Accuracy: 32.00%\n",
      "train Loss: 0.0287 Acc: 0.9906\n",
      "val Loss: 0.1029 Acc: 0.9740\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/332], Loss: 0.0260, Accuracy: 31.00%\n",
      "Epoch [80/100], Step [200/332], Loss: 0.0150, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0293 Acc: 0.9909\n",
      "val Loss: 0.0944 Acc: 0.9789\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/332], Loss: 0.0505, Accuracy: 31.00%\n",
      "Epoch [81/100], Step [200/332], Loss: 0.1576, Accuracy: 30.00%\n",
      "Epoch [81/100], Step [300/332], Loss: 0.0835, Accuracy: 31.00%\n",
      "train Loss: 0.1385 Acc: 0.9524\n",
      "val Loss: 1.9375 Acc: 0.6881\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/332], Loss: 0.0894, Accuracy: 31.00%\n",
      "Epoch [82/100], Step [200/332], Loss: 0.0138, Accuracy: 32.00%\n",
      "Epoch [82/100], Step [300/332], Loss: 0.3647, Accuracy: 31.00%\n",
      "train Loss: 0.1121 Acc: 0.9646\n",
      "val Loss: 0.3574 Acc: 0.9195\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/332], Loss: 0.0999, Accuracy: 31.00%\n",
      "Epoch [83/100], Step [200/332], Loss: 0.0927, Accuracy: 31.00%\n",
      "Epoch [83/100], Step [300/332], Loss: 0.0350, Accuracy: 31.00%\n",
      "train Loss: 0.0947 Acc: 0.9704\n",
      "val Loss: 0.2192 Acc: 0.9441\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/332], Loss: 0.0232, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [200/332], Loss: 0.0547, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [300/332], Loss: 0.2333, Accuracy: 31.00%\n",
      "train Loss: 0.0959 Acc: 0.9707\n",
      "val Loss: 0.1515 Acc: 0.9446\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/332], Loss: 0.0531, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [200/332], Loss: 0.0078, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [300/332], Loss: 0.1871, Accuracy: 30.00%\n",
      "train Loss: 0.0661 Acc: 0.9767\n",
      "val Loss: 0.1781 Acc: 0.9481\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/332], Loss: 0.0661, Accuracy: 31.00%\n",
      "Epoch [86/100], Step [200/332], Loss: 0.0034, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [300/332], Loss: 0.0278, Accuracy: 31.00%\n",
      "train Loss: 0.0474 Acc: 0.9841\n",
      "val Loss: 0.0867 Acc: 0.9736\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/332], Loss: 0.0024, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [200/332], Loss: 0.0543, Accuracy: 31.00%\n",
      "Epoch [87/100], Step [300/332], Loss: 0.0747, Accuracy: 31.00%\n",
      "train Loss: 0.0380 Acc: 0.9877\n",
      "val Loss: 0.0895 Acc: 0.9767\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [200/332], Loss: 0.0557, Accuracy: 31.00%\n",
      "Epoch [88/100], Step [300/332], Loss: 0.0012, Accuracy: 32.00%\n",
      "train Loss: 0.0313 Acc: 0.9892\n",
      "val Loss: 0.0780 Acc: 0.9776\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/332], Loss: 0.0114, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [200/332], Loss: 0.0515, Accuracy: 31.00%\n",
      "Epoch [89/100], Step [300/332], Loss: 0.0023, Accuracy: 32.00%\n",
      "train Loss: 0.0252 Acc: 0.9921\n",
      "val Loss: 0.0874 Acc: 0.9806\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/332], Loss: 0.0710, Accuracy: 31.00%\n",
      "Epoch [90/100], Step [200/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [300/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "train Loss: 0.0178 Acc: 0.9940\n",
      "val Loss: 0.0805 Acc: 0.9811\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/332], Loss: 0.0532, Accuracy: 31.00%\n",
      "Epoch [91/100], Step [200/332], Loss: 0.0286, Accuracy: 32.00%\n",
      "Epoch [91/100], Step [300/332], Loss: 0.1892, Accuracy: 30.00%\n",
      "train Loss: 0.1154 Acc: 0.9630\n",
      "val Loss: 0.7013 Acc: 0.8975\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/332], Loss: 0.0807, Accuracy: 31.00%\n",
      "Epoch [92/100], Step [200/332], Loss: 0.0196, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [300/332], Loss: 0.1232, Accuracy: 30.00%\n",
      "train Loss: 0.1224 Acc: 0.9620\n",
      "val Loss: 0.2570 Acc: 0.9265\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/332], Loss: 0.1294, Accuracy: 31.00%\n",
      "Epoch [93/100], Step [200/332], Loss: 0.0621, Accuracy: 32.00%\n",
      "Epoch [93/100], Step [300/332], Loss: 0.1784, Accuracy: 30.00%\n",
      "train Loss: 0.1099 Acc: 0.9661\n",
      "val Loss: 0.2425 Acc: 0.9116\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/332], Loss: 0.0192, Accuracy: 32.00%\n",
      "Epoch [94/100], Step [200/332], Loss: 0.0758, Accuracy: 31.00%\n",
      "Epoch [94/100], Step [300/332], Loss: 0.0843, Accuracy: 31.00%\n",
      "train Loss: 0.0872 Acc: 0.9724\n",
      "val Loss: 0.4253 Acc: 0.8733\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/332], Loss: 0.1679, Accuracy: 31.00%\n",
      "Epoch [95/100], Step [200/332], Loss: 0.2716, Accuracy: 31.00%\n",
      "Epoch [95/100], Step [300/332], Loss: 0.0035, Accuracy: 32.00%\n",
      "train Loss: 0.0616 Acc: 0.9818\n",
      "val Loss: 0.3907 Acc: 0.8935\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/332], Loss: 0.0147, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [200/332], Loss: 0.0232, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [300/332], Loss: 0.3273, Accuracy: 31.00%\n",
      "train Loss: 0.0534 Acc: 0.9818\n",
      "val Loss: 0.1374 Acc: 0.9648\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/332], Loss: 0.0143, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [300/332], Loss: 0.0421, Accuracy: 31.00%\n",
      "train Loss: 0.0346 Acc: 0.9891\n",
      "val Loss: 0.1577 Acc: 0.9714\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/332], Loss: 0.0070, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [300/332], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0280 Acc: 0.9905\n",
      "val Loss: 0.1252 Acc: 0.9674\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/332], Loss: 0.0278, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [200/332], Loss: 0.0072, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0219 Acc: 0.9927\n",
      "val Loss: 0.0972 Acc: 0.9776\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/332], Loss: 0.0172, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [300/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "train Loss: 0.0182 Acc: 0.9943\n",
      "val Loss: 0.1309 Acc: 0.9714\n",
      "\n",
      "Training complete in 76m 40s\n",
      "Best val Acc: 0.981082\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=iter_restart, T_mult=mul_restart, \n",
    "                                                           eta_min=lr_end, last_epoch=-1)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'covid_pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.978161965423112\n",
      "f1: 0.9719751084426695\n",
      "cm: [[ 524   17    2]\n",
      " [  17 1430    6]\n",
      " [   1    5  196]]\n",
      "outputs: [0 1 0 ... 2 2 2]\n",
      "targets: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
