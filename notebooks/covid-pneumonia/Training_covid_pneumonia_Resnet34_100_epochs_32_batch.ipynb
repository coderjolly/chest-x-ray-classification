{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/covid_pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"resnet34\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Covid Pneumonia dataset metrics\n",
    "norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/332], Loss: 0.6065, Accuracy: 20.00%\n",
      "Epoch [1/100], Step [200/332], Loss: 0.6664, Accuracy: 21.00%\n",
      "Epoch [1/100], Step [300/332], Loss: 0.6217, Accuracy: 22.00%\n",
      "train Loss: 0.7172 Acc: 0.6983\n",
      "val Loss: 0.6211 Acc: 0.7211\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/332], Loss: 0.6991, Accuracy: 22.00%\n",
      "Epoch [2/100], Step [200/332], Loss: 0.4355, Accuracy: 25.00%\n",
      "Epoch [2/100], Step [300/332], Loss: 0.4773, Accuracy: 26.00%\n",
      "train Loss: 0.5295 Acc: 0.7679\n",
      "val Loss: 0.5855 Acc: 0.7250\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/332], Loss: 0.6187, Accuracy: 23.00%\n",
      "Epoch [3/100], Step [200/332], Loss: 0.3804, Accuracy: 25.00%\n",
      "Epoch [3/100], Step [300/332], Loss: 0.3525, Accuracy: 26.00%\n",
      "train Loss: 0.4242 Acc: 0.8197\n",
      "val Loss: 0.3958 Acc: 0.8341\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/332], Loss: 0.3658, Accuracy: 26.00%\n",
      "Epoch [4/100], Step [200/332], Loss: 0.3956, Accuracy: 25.00%\n",
      "Epoch [4/100], Step [300/332], Loss: 0.1791, Accuracy: 30.00%\n",
      "train Loss: 0.3594 Acc: 0.8496\n",
      "val Loss: 0.4871 Acc: 0.7791\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/332], Loss: 0.3278, Accuracy: 27.00%\n",
      "Epoch [5/100], Step [200/332], Loss: 0.2165, Accuracy: 29.00%\n",
      "Epoch [5/100], Step [300/332], Loss: 0.3395, Accuracy: 27.00%\n",
      "train Loss: 0.3100 Acc: 0.8724\n",
      "val Loss: 0.3143 Acc: 0.8680\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/332], Loss: 0.3141, Accuracy: 27.00%\n",
      "Epoch [6/100], Step [200/332], Loss: 0.1578, Accuracy: 31.00%\n",
      "Epoch [6/100], Step [300/332], Loss: 0.1931, Accuracy: 30.00%\n",
      "train Loss: 0.2639 Acc: 0.8956\n",
      "val Loss: 0.2406 Acc: 0.9028\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/332], Loss: 0.2184, Accuracy: 29.00%\n",
      "Epoch [7/100], Step [200/332], Loss: 0.1151, Accuracy: 31.00%\n",
      "Epoch [7/100], Step [300/332], Loss: 0.3269, Accuracy: 28.00%\n",
      "train Loss: 0.2258 Acc: 0.9099\n",
      "val Loss: 0.1849 Acc: 0.9336\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/332], Loss: 0.2263, Accuracy: 29.00%\n",
      "Epoch [8/100], Step [200/332], Loss: 0.2170, Accuracy: 31.00%\n",
      "Epoch [8/100], Step [300/332], Loss: 0.2040, Accuracy: 29.00%\n",
      "train Loss: 0.1884 Acc: 0.9257\n",
      "val Loss: 0.2035 Acc: 0.9177\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/332], Loss: 0.2263, Accuracy: 30.00%\n",
      "Epoch [9/100], Step [200/332], Loss: 0.1886, Accuracy: 30.00%\n",
      "Epoch [9/100], Step [300/332], Loss: 0.1252, Accuracy: 31.00%\n",
      "train Loss: 0.1504 Acc: 0.9437\n",
      "val Loss: 0.1416 Acc: 0.9459\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/332], Loss: 0.1510, Accuracy: 30.00%\n",
      "Epoch [10/100], Step [200/332], Loss: 0.0791, Accuracy: 31.00%\n",
      "Epoch [10/100], Step [300/332], Loss: 0.1376, Accuracy: 30.00%\n",
      "train Loss: 0.1243 Acc: 0.9533\n",
      "val Loss: 0.1212 Acc: 0.9547\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/332], Loss: 0.2792, Accuracy: 26.00%\n",
      "Epoch [11/100], Step [200/332], Loss: 0.0959, Accuracy: 31.00%\n",
      "Epoch [11/100], Step [300/332], Loss: 0.3222, Accuracy: 29.00%\n",
      "train Loss: 0.2743 Acc: 0.8909\n",
      "val Loss: 0.2038 Acc: 0.9234\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/332], Loss: 0.3686, Accuracy: 27.00%\n",
      "Epoch [12/100], Step [200/332], Loss: 0.4760, Accuracy: 28.00%\n",
      "Epoch [12/100], Step [300/332], Loss: 0.1797, Accuracy: 29.00%\n",
      "train Loss: 0.2158 Acc: 0.9165\n",
      "val Loss: 0.2635 Acc: 0.8988\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/332], Loss: 0.1870, Accuracy: 29.00%\n",
      "Epoch [13/100], Step [200/332], Loss: 0.2618, Accuracy: 29.00%\n",
      "Epoch [13/100], Step [300/332], Loss: 0.0848, Accuracy: 31.00%\n",
      "train Loss: 0.1823 Acc: 0.9313\n",
      "val Loss: 0.3389 Acc: 0.8601\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/332], Loss: 0.0403, Accuracy: 32.00%\n",
      "Epoch [14/100], Step [200/332], Loss: 0.2054, Accuracy: 29.00%\n",
      "Epoch [14/100], Step [300/332], Loss: 0.1496, Accuracy: 30.00%\n",
      "train Loss: 0.1538 Acc: 0.9426\n",
      "val Loss: 0.1730 Acc: 0.9349\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/332], Loss: 0.1628, Accuracy: 30.00%\n",
      "Epoch [15/100], Step [200/332], Loss: 0.0716, Accuracy: 31.00%\n",
      "Epoch [15/100], Step [300/332], Loss: 0.1705, Accuracy: 29.00%\n",
      "train Loss: 0.1267 Acc: 0.9520\n",
      "val Loss: 0.1767 Acc: 0.9292\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/332], Loss: 0.0852, Accuracy: 31.00%\n",
      "Epoch [16/100], Step [200/332], Loss: 0.0758, Accuracy: 30.00%\n",
      "Epoch [16/100], Step [300/332], Loss: 0.1252, Accuracy: 30.00%\n",
      "train Loss: 0.1010 Acc: 0.9618\n",
      "val Loss: 0.1969 Acc: 0.9314\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/332], Loss: 0.0966, Accuracy: 31.00%\n",
      "Epoch [17/100], Step [200/332], Loss: 0.0295, Accuracy: 32.00%\n",
      "Epoch [17/100], Step [300/332], Loss: 0.1147, Accuracy: 29.00%\n",
      "train Loss: 0.0806 Acc: 0.9711\n",
      "val Loss: 0.0932 Acc: 0.9683\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/332], Loss: 0.0921, Accuracy: 31.00%\n",
      "Epoch [18/100], Step [200/332], Loss: 0.0605, Accuracy: 31.00%\n",
      "Epoch [18/100], Step [300/332], Loss: 0.0180, Accuracy: 32.00%\n",
      "train Loss: 0.0588 Acc: 0.9790\n",
      "val Loss: 0.0756 Acc: 0.9732\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/332], Loss: 0.1168, Accuracy: 31.00%\n",
      "Epoch [19/100], Step [200/332], Loss: 0.0169, Accuracy: 32.00%\n",
      "Epoch [19/100], Step [300/332], Loss: 0.1482, Accuracy: 31.00%\n",
      "train Loss: 0.0437 Acc: 0.9855\n",
      "val Loss: 0.0618 Acc: 0.9784\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/332], Loss: 0.0614, Accuracy: 30.00%\n",
      "Epoch [20/100], Step [200/332], Loss: 0.0012, Accuracy: 32.00%\n",
      "Epoch [20/100], Step [300/332], Loss: 0.1379, Accuracy: 31.00%\n",
      "train Loss: 0.0333 Acc: 0.9893\n",
      "val Loss: 0.0574 Acc: 0.9820\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/332], Loss: 0.2179, Accuracy: 28.00%\n",
      "Epoch [21/100], Step [200/332], Loss: 0.1480, Accuracy: 30.00%\n",
      "Epoch [21/100], Step [300/332], Loss: 0.0998, Accuracy: 30.00%\n",
      "train Loss: 0.1541 Acc: 0.9434\n",
      "val Loss: 0.1749 Acc: 0.9318\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/332], Loss: 0.0506, Accuracy: 31.00%\n",
      "Epoch [22/100], Step [200/332], Loss: 0.0414, Accuracy: 32.00%\n",
      "Epoch [22/100], Step [300/332], Loss: 0.0476, Accuracy: 31.00%\n",
      "train Loss: 0.1222 Acc: 0.9540\n",
      "val Loss: 0.2757 Acc: 0.8852\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/332], Loss: 0.0161, Accuracy: 32.00%\n",
      "Epoch [23/100], Step [200/332], Loss: 0.1558, Accuracy: 31.00%\n",
      "Epoch [23/100], Step [300/332], Loss: 0.0613, Accuracy: 31.00%\n",
      "train Loss: 0.0859 Acc: 0.9675\n",
      "val Loss: 0.1185 Acc: 0.9626\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/332], Loss: 0.0331, Accuracy: 32.00%\n",
      "Epoch [24/100], Step [200/332], Loss: 0.0838, Accuracy: 31.00%\n",
      "Epoch [24/100], Step [300/332], Loss: 0.0556, Accuracy: 31.00%\n",
      "train Loss: 0.0763 Acc: 0.9731\n",
      "val Loss: 0.1201 Acc: 0.9591\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/332], Loss: 0.1483, Accuracy: 30.00%\n",
      "Epoch [25/100], Step [200/332], Loss: 0.0512, Accuracy: 31.00%\n",
      "Epoch [25/100], Step [300/332], Loss: 0.0269, Accuracy: 32.00%\n",
      "train Loss: 0.0601 Acc: 0.9791\n",
      "val Loss: 0.0888 Acc: 0.9683\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/332], Loss: 0.0746, Accuracy: 31.00%\n",
      "Epoch [26/100], Step [200/332], Loss: 0.0079, Accuracy: 32.00%\n",
      "Epoch [26/100], Step [300/332], Loss: 0.0069, Accuracy: 32.00%\n",
      "train Loss: 0.0444 Acc: 0.9845\n",
      "val Loss: 0.0776 Acc: 0.9776\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/332], Loss: 0.0647, Accuracy: 31.00%\n",
      "Epoch [27/100], Step [200/332], Loss: 0.0055, Accuracy: 32.00%\n",
      "Epoch [27/100], Step [300/332], Loss: 0.0089, Accuracy: 32.00%\n",
      "train Loss: 0.0246 Acc: 0.9916\n",
      "val Loss: 0.0717 Acc: 0.9767\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/332], Loss: 0.0272, Accuracy: 32.00%\n",
      "Epoch [28/100], Step [200/332], Loss: 0.0093, Accuracy: 32.00%\n",
      "Epoch [28/100], Step [300/332], Loss: 0.0759, Accuracy: 31.00%\n",
      "train Loss: 0.0258 Acc: 0.9904\n",
      "val Loss: 0.0731 Acc: 0.9793\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/332], Loss: 0.0433, Accuracy: 31.00%\n",
      "Epoch [29/100], Step [200/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "Epoch [29/100], Step [300/332], Loss: 0.0225, Accuracy: 32.00%\n",
      "train Loss: 0.0121 Acc: 0.9968\n",
      "val Loss: 0.0620 Acc: 0.9811\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/332], Loss: 0.0570, Accuracy: 31.00%\n",
      "Epoch [30/100], Step [200/332], Loss: 0.0061, Accuracy: 32.00%\n",
      "Epoch [30/100], Step [300/332], Loss: 0.0111, Accuracy: 32.00%\n",
      "train Loss: 0.0089 Acc: 0.9973\n",
      "val Loss: 0.0608 Acc: 0.9833\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/332], Loss: 0.1855, Accuracy: 30.00%\n",
      "Epoch [31/100], Step [200/332], Loss: 0.0380, Accuracy: 32.00%\n",
      "Epoch [31/100], Step [300/332], Loss: 0.1008, Accuracy: 31.00%\n",
      "train Loss: 0.1188 Acc: 0.9566\n",
      "val Loss: 0.1855 Acc: 0.9292\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/332], Loss: 0.0216, Accuracy: 32.00%\n",
      "Epoch [32/100], Step [200/332], Loss: 0.1520, Accuracy: 31.00%\n",
      "Epoch [32/100], Step [300/332], Loss: 0.0787, Accuracy: 31.00%\n",
      "train Loss: 0.0705 Acc: 0.9738\n",
      "val Loss: 0.1812 Acc: 0.9397\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/332], Loss: 0.0084, Accuracy: 32.00%\n",
      "Epoch [33/100], Step [200/332], Loss: 0.0205, Accuracy: 32.00%\n",
      "Epoch [33/100], Step [300/332], Loss: 0.0633, Accuracy: 31.00%\n",
      "train Loss: 0.0575 Acc: 0.9798\n",
      "val Loss: 0.0897 Acc: 0.9701\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/332], Loss: 0.0137, Accuracy: 32.00%\n",
      "Epoch [34/100], Step [200/332], Loss: 0.0588, Accuracy: 31.00%\n",
      "Epoch [34/100], Step [300/332], Loss: 0.0311, Accuracy: 32.00%\n",
      "train Loss: 0.0522 Acc: 0.9820\n",
      "val Loss: 0.0835 Acc: 0.9745\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/332], Loss: 0.0176, Accuracy: 32.00%\n",
      "Epoch [35/100], Step [200/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "Epoch [35/100], Step [300/332], Loss: 0.0641, Accuracy: 31.00%\n",
      "train Loss: 0.0314 Acc: 0.9904\n",
      "val Loss: 0.0833 Acc: 0.9705\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/332], Loss: 0.0745, Accuracy: 31.00%\n",
      "Epoch [36/100], Step [200/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [36/100], Step [300/332], Loss: 0.0020, Accuracy: 32.00%\n",
      "train Loss: 0.0272 Acc: 0.9912\n",
      "val Loss: 0.0597 Acc: 0.9784\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "Epoch [37/100], Step [200/332], Loss: 0.0079, Accuracy: 32.00%\n",
      "Epoch [37/100], Step [300/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "train Loss: 0.0153 Acc: 0.9952\n",
      "val Loss: 0.0578 Acc: 0.9806\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [38/100], Step [300/332], Loss: 0.0259, Accuracy: 31.00%\n",
      "train Loss: 0.0093 Acc: 0.9968\n",
      "val Loss: 0.0695 Acc: 0.9793\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "Epoch [39/100], Step [200/332], Loss: 0.0616, Accuracy: 31.00%\n",
      "Epoch [39/100], Step [300/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "train Loss: 0.0067 Acc: 0.9977\n",
      "val Loss: 0.0602 Acc: 0.9815\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [40/100], Step [200/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [40/100], Step [300/332], Loss: 0.0009, Accuracy: 32.00%\n",
      "train Loss: 0.0048 Acc: 0.9987\n",
      "val Loss: 0.0579 Acc: 0.9815\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/332], Loss: 0.1382, Accuracy: 31.00%\n",
      "Epoch [41/100], Step [200/332], Loss: 0.3055, Accuracy: 28.00%\n",
      "Epoch [41/100], Step [300/332], Loss: 0.0665, Accuracy: 31.00%\n",
      "train Loss: 0.0788 Acc: 0.9738\n",
      "val Loss: 0.1220 Acc: 0.9613\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/332], Loss: 0.0295, Accuracy: 31.00%\n",
      "Epoch [42/100], Step [200/332], Loss: 0.0366, Accuracy: 31.00%\n",
      "Epoch [42/100], Step [300/332], Loss: 0.0389, Accuracy: 32.00%\n",
      "train Loss: 0.0556 Acc: 0.9800\n",
      "val Loss: 0.0858 Acc: 0.9701\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/332], Loss: 0.0032, Accuracy: 32.00%\n",
      "Epoch [43/100], Step [200/332], Loss: 0.0051, Accuracy: 32.00%\n",
      "Epoch [43/100], Step [300/332], Loss: 0.0538, Accuracy: 31.00%\n",
      "train Loss: 0.0355 Acc: 0.9879\n",
      "val Loss: 0.0823 Acc: 0.9736\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/332], Loss: 0.1077, Accuracy: 31.00%\n",
      "Epoch [44/100], Step [200/332], Loss: 0.0439, Accuracy: 31.00%\n",
      "Epoch [44/100], Step [300/332], Loss: 0.0077, Accuracy: 32.00%\n",
      "train Loss: 0.0263 Acc: 0.9898\n",
      "val Loss: 0.1017 Acc: 0.9714\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/332], Loss: 0.0970, Accuracy: 30.00%\n",
      "Epoch [45/100], Step [200/332], Loss: 0.0296, Accuracy: 32.00%\n",
      "Epoch [45/100], Step [300/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0232 Acc: 0.9911\n",
      "val Loss: 0.0828 Acc: 0.9745\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [46/100], Step [200/332], Loss: 0.0189, Accuracy: 32.00%\n",
      "Epoch [46/100], Step [300/332], Loss: 0.0044, Accuracy: 32.00%\n",
      "train Loss: 0.0102 Acc: 0.9970\n",
      "val Loss: 0.0735 Acc: 0.9784\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/332], Loss: 0.0038, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [47/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0056 Acc: 0.9984\n",
      "val Loss: 0.0739 Acc: 0.9802\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [48/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0067 Acc: 0.9978\n",
      "val Loss: 0.0906 Acc: 0.9749\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/332], Loss: 0.0014, Accuracy: 32.00%\n",
      "Epoch [49/100], Step [200/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [49/100], Step [300/332], Loss: 0.0043, Accuracy: 32.00%\n",
      "train Loss: 0.0033 Acc: 0.9992\n",
      "val Loss: 0.0581 Acc: 0.9842\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [50/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [50/100], Step [300/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "train Loss: 0.0033 Acc: 0.9994\n",
      "val Loss: 0.0663 Acc: 0.9811\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/332], Loss: 0.1240, Accuracy: 30.00%\n",
      "Epoch [51/100], Step [200/332], Loss: 0.0453, Accuracy: 31.00%\n",
      "Epoch [51/100], Step [300/332], Loss: 0.0255, Accuracy: 32.00%\n",
      "train Loss: 0.0716 Acc: 0.9749\n",
      "val Loss: 0.2112 Acc: 0.9296\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/332], Loss: 0.0059, Accuracy: 32.00%\n",
      "Epoch [52/100], Step [200/332], Loss: 0.0089, Accuracy: 32.00%\n",
      "Epoch [52/100], Step [300/332], Loss: 0.0419, Accuracy: 31.00%\n",
      "train Loss: 0.0374 Acc: 0.9874\n",
      "val Loss: 0.0802 Acc: 0.9723\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/332], Loss: 0.0893, Accuracy: 31.00%\n",
      "Epoch [53/100], Step [200/332], Loss: 0.0205, Accuracy: 32.00%\n",
      "Epoch [53/100], Step [300/332], Loss: 0.0211, Accuracy: 32.00%\n",
      "train Loss: 0.0276 Acc: 0.9900\n",
      "val Loss: 0.1479 Acc: 0.9551\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/332], Loss: 0.0010, Accuracy: 32.00%\n",
      "Epoch [54/100], Step [200/332], Loss: 0.0114, Accuracy: 32.00%\n",
      "Epoch [54/100], Step [300/332], Loss: 0.0290, Accuracy: 31.00%\n",
      "train Loss: 0.0200 Acc: 0.9929\n",
      "val Loss: 0.0603 Acc: 0.9820\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [55/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0082 Acc: 0.9976\n",
      "val Loss: 0.0853 Acc: 0.9732\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/332], Loss: 0.0021, Accuracy: 32.00%\n",
      "Epoch [56/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [56/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0050 Acc: 0.9985\n",
      "val Loss: 0.0701 Acc: 0.9828\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/332], Loss: 0.0071, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [57/100], Step [300/332], Loss: 0.0099, Accuracy: 32.00%\n",
      "train Loss: 0.0045 Acc: 0.9985\n",
      "val Loss: 0.0751 Acc: 0.9806\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [58/100], Step [200/332], Loss: 0.0334, Accuracy: 31.00%\n",
      "Epoch [58/100], Step [300/332], Loss: 0.0053, Accuracy: 32.00%\n",
      "train Loss: 0.0045 Acc: 0.9985\n",
      "val Loss: 0.0692 Acc: 0.9811\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [59/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0017 Acc: 0.9997\n",
      "val Loss: 0.0670 Acc: 0.9837\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [60/100], Step [300/332], Loss: 0.0168, Accuracy: 32.00%\n",
      "train Loss: 0.0022 Acc: 0.9997\n",
      "val Loss: 0.0652 Acc: 0.9815\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/332], Loss: 0.1145, Accuracy: 30.00%\n",
      "Epoch [61/100], Step [200/332], Loss: 0.0606, Accuracy: 31.00%\n",
      "Epoch [61/100], Step [300/332], Loss: 0.0029, Accuracy: 32.00%\n",
      "train Loss: 0.0561 Acc: 0.9823\n",
      "val Loss: 0.0769 Acc: 0.9762\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/332], Loss: 0.0017, Accuracy: 32.00%\n",
      "Epoch [62/100], Step [200/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [62/100], Step [300/332], Loss: 0.0342, Accuracy: 31.00%\n",
      "train Loss: 0.0295 Acc: 0.9894\n",
      "val Loss: 0.1264 Acc: 0.9639\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/332], Loss: 0.0077, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [200/332], Loss: 0.0143, Accuracy: 32.00%\n",
      "Epoch [63/100], Step [300/332], Loss: 0.0210, Accuracy: 32.00%\n",
      "train Loss: 0.0217 Acc: 0.9922\n",
      "val Loss: 0.0935 Acc: 0.9674\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/332], Loss: 0.0058, Accuracy: 32.00%\n",
      "Epoch [64/100], Step [200/332], Loss: 0.0012, Accuracy: 32.00%\n",
      "Epoch [64/100], Step [300/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "train Loss: 0.0139 Acc: 0.9956\n",
      "val Loss: 0.0701 Acc: 0.9811\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/332], Loss: 0.0087, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [200/332], Loss: 0.0010, Accuracy: 32.00%\n",
      "Epoch [65/100], Step [300/332], Loss: 0.0007, Accuracy: 32.00%\n",
      "train Loss: 0.0125 Acc: 0.9953\n",
      "val Loss: 0.0873 Acc: 0.9767\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/332], Loss: 0.0301, Accuracy: 31.00%\n",
      "Epoch [66/100], Step [200/332], Loss: 0.0224, Accuracy: 32.00%\n",
      "Epoch [66/100], Step [300/332], Loss: 0.0037, Accuracy: 32.00%\n",
      "train Loss: 0.0067 Acc: 0.9974\n",
      "val Loss: 0.0734 Acc: 0.9771\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [67/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [67/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0029 Acc: 0.9992\n",
      "val Loss: 0.0909 Acc: 0.9740\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [68/100], Step [200/332], Loss: 0.0032, Accuracy: 32.00%\n",
      "Epoch [68/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0018 Acc: 0.9994\n",
      "val Loss: 0.0700 Acc: 0.9811\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [69/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0018 Acc: 0.9994\n",
      "val Loss: 0.0624 Acc: 0.9828\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [70/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0009 Acc: 0.9998\n",
      "val Loss: 0.0603 Acc: 0.9837\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/332], Loss: 0.0340, Accuracy: 31.00%\n",
      "Epoch [71/100], Step [200/332], Loss: 0.1244, Accuracy: 30.00%\n",
      "Epoch [71/100], Step [300/332], Loss: 0.0025, Accuracy: 32.00%\n",
      "train Loss: 0.0500 Acc: 0.9827\n",
      "val Loss: 0.1076 Acc: 0.9657\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/332], Loss: 0.0015, Accuracy: 32.00%\n",
      "Epoch [72/100], Step [200/332], Loss: 0.0067, Accuracy: 32.00%\n",
      "Epoch [72/100], Step [300/332], Loss: 0.1177, Accuracy: 31.00%\n",
      "train Loss: 0.0320 Acc: 0.9884\n",
      "val Loss: 0.0974 Acc: 0.9762\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/332], Loss: 0.0034, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [200/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [73/100], Step [300/332], Loss: 0.0011, Accuracy: 32.00%\n",
      "train Loss: 0.0130 Acc: 0.9959\n",
      "val Loss: 0.0894 Acc: 0.9771\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "Epoch [74/100], Step [200/332], Loss: 0.0089, Accuracy: 32.00%\n",
      "Epoch [74/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0098 Acc: 0.9965\n",
      "val Loss: 0.0797 Acc: 0.9793\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [75/100], Step [200/332], Loss: 0.0009, Accuracy: 32.00%\n",
      "Epoch [75/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0053 Acc: 0.9979\n",
      "val Loss: 0.0787 Acc: 0.9802\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/332], Loss: 0.0031, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [76/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0048 Acc: 0.9985\n",
      "val Loss: 0.0805 Acc: 0.9780\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [77/100], Step [200/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [77/100], Step [300/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "train Loss: 0.0047 Acc: 0.9987\n",
      "val Loss: 0.0702 Acc: 0.9811\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/332], Loss: 0.0012, Accuracy: 32.00%\n",
      "Epoch [78/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [78/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0017 Acc: 0.9995\n",
      "val Loss: 0.0741 Acc: 0.9828\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [200/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "Epoch [79/100], Step [300/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "train Loss: 0.0009 Acc: 0.9997\n",
      "val Loss: 0.0755 Acc: 0.9824\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [200/332], Loss: 0.0079, Accuracy: 32.00%\n",
      "Epoch [80/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0006 Acc: 0.9998\n",
      "val Loss: 0.0703 Acc: 0.9837\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [81/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [81/100], Step [300/332], Loss: 0.1326, Accuracy: 30.00%\n",
      "train Loss: 0.0404 Acc: 0.9873\n",
      "val Loss: 0.1169 Acc: 0.9674\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/332], Loss: 0.0225, Accuracy: 32.00%\n",
      "Epoch [82/100], Step [200/332], Loss: 0.0695, Accuracy: 31.00%\n",
      "Epoch [82/100], Step [300/332], Loss: 0.0950, Accuracy: 30.00%\n",
      "train Loss: 0.0320 Acc: 0.9878\n",
      "val Loss: 0.0761 Acc: 0.9745\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/332], Loss: 0.0066, Accuracy: 32.00%\n",
      "Epoch [83/100], Step [200/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "Epoch [83/100], Step [300/332], Loss: 0.0016, Accuracy: 32.00%\n",
      "train Loss: 0.0112 Acc: 0.9957\n",
      "val Loss: 0.0704 Acc: 0.9828\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/332], Loss: 0.0016, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [200/332], Loss: 0.0013, Accuracy: 32.00%\n",
      "Epoch [84/100], Step [300/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0078 Acc: 0.9979\n",
      "val Loss: 0.0692 Acc: 0.9793\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [200/332], Loss: 0.0036, Accuracy: 32.00%\n",
      "Epoch [85/100], Step [300/332], Loss: 0.0016, Accuracy: 32.00%\n",
      "train Loss: 0.0041 Acc: 0.9984\n",
      "val Loss: 0.0856 Acc: 0.9820\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [86/100], Step [300/332], Loss: 0.0004, Accuracy: 32.00%\n",
      "train Loss: 0.0026 Acc: 0.9992\n",
      "val Loss: 0.0579 Acc: 0.9837\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [87/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0032 Acc: 0.9989\n",
      "val Loss: 0.0545 Acc: 0.9833\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/332], Loss: 0.0014, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [88/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0014 Acc: 0.9997\n",
      "val Loss: 0.0557 Acc: 0.9868\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [89/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.0584 Acc: 0.9859\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [90/100], Step [300/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 0.0585 Acc: 0.9864\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/332], Loss: 0.0009, Accuracy: 32.00%\n",
      "Epoch [91/100], Step [200/332], Loss: 0.0550, Accuracy: 31.00%\n",
      "Epoch [91/100], Step [300/332], Loss: 0.1126, Accuracy: 31.00%\n",
      "train Loss: 0.0403 Acc: 0.9861\n",
      "val Loss: 0.1384 Acc: 0.9569\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/332], Loss: 0.0035, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [200/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "Epoch [92/100], Step [300/332], Loss: 0.0008, Accuracy: 32.00%\n",
      "train Loss: 0.0191 Acc: 0.9937\n",
      "val Loss: 0.0773 Acc: 0.9771\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [93/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [93/100], Step [300/332], Loss: 0.0575, Accuracy: 31.00%\n",
      "train Loss: 0.0073 Acc: 0.9972\n",
      "val Loss: 0.1610 Acc: 0.9688\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/332], Loss: 0.1042, Accuracy: 31.00%\n",
      "Epoch [94/100], Step [200/332], Loss: 0.0144, Accuracy: 32.00%\n",
      "Epoch [94/100], Step [300/332], Loss: 0.0006, Accuracy: 32.00%\n",
      "train Loss: 0.0155 Acc: 0.9945\n",
      "val Loss: 0.1443 Acc: 0.9591\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [95/100], Step [200/332], Loss: 0.0026, Accuracy: 32.00%\n",
      "Epoch [95/100], Step [300/332], Loss: 0.0229, Accuracy: 32.00%\n",
      "train Loss: 0.0072 Acc: 0.9975\n",
      "val Loss: 0.0884 Acc: 0.9749\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [200/332], Loss: 0.0002, Accuracy: 32.00%\n",
      "Epoch [96/100], Step [300/332], Loss: 0.0018, Accuracy: 32.00%\n",
      "train Loss: 0.0033 Acc: 0.9990\n",
      "val Loss: 0.0566 Acc: 0.9824\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/332], Loss: 0.0028, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [97/100], Step [300/332], Loss: 0.0003, Accuracy: 32.00%\n",
      "train Loss: 0.0013 Acc: 0.9993\n",
      "val Loss: 0.0605 Acc: 0.9842\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [98/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0009 Acc: 0.9997\n",
      "val Loss: 0.0585 Acc: 0.9837\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [200/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [99/100], Step [300/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "train Loss: 0.0007 Acc: 0.9998\n",
      "val Loss: 0.0565 Acc: 0.9837\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/332], Loss: 0.0000, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [200/332], Loss: 0.0001, Accuracy: 32.00%\n",
      "Epoch [100/100], Step [300/332], Loss: 0.0005, Accuracy: 32.00%\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 0.0565 Acc: 0.9833\n",
      "\n",
      "Training complete in 112m 54s\n",
      "Best val Acc: 0.986802\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=iter_restart, T_mult=mul_restart, \n",
    "                                                           eta_min=lr_end, last_epoch=-1)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'covid_pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9840764331210191\n",
      "f1: 0.9753083505749677\n",
      "cm: [[ 532   10    1]\n",
      " [   8 1440    5]\n",
      " [   4    7  191]]\n",
      "outputs: [0 0 0 ... 2 2 2]\n",
      "targets: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
