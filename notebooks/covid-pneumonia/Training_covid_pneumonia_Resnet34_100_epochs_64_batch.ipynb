{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/covid_pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"resnet34\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 3\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 64\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "# Covid Pneumonia dataset metrics\n",
    "norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# How many epochs to restart.\n",
    "iter_restart = 10\n",
    "\n",
    "# Multiplication factor after restart.\n",
    "mul_restart = 1\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/166], Loss: 0.5453, Accuracy: 47.00%\n",
      "train Loss: 0.6588 Acc: 0.7305\n",
      "val Loss: 0.6634 Acc: 0.7123\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/166], Loss: 0.3023, Accuracy: 58.00%\n",
      "train Loss: 0.4830 Acc: 0.7948\n",
      "val Loss: 0.6562 Acc: 0.6837\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/166], Loss: 0.3374, Accuracy: 53.00%\n",
      "train Loss: 0.3837 Acc: 0.8375\n",
      "val Loss: 0.4070 Acc: 0.8385\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/166], Loss: 0.3359, Accuracy: 57.00%\n",
      "train Loss: 0.3158 Acc: 0.8712\n",
      "val Loss: 0.3638 Acc: 0.8473\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/166], Loss: 0.3450, Accuracy: 55.00%\n",
      "train Loss: 0.2850 Acc: 0.8851\n",
      "val Loss: 0.3727 Acc: 0.8557\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/166], Loss: 0.4036, Accuracy: 56.00%\n",
      "train Loss: 0.2603 Acc: 0.8944\n",
      "val Loss: 0.3081 Acc: 0.8861\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/166], Loss: 0.1685, Accuracy: 58.00%\n",
      "train Loss: 0.2177 Acc: 0.9145\n",
      "val Loss: 0.3223 Acc: 0.8887\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/166], Loss: 0.1881, Accuracy: 58.00%\n",
      "train Loss: 0.1956 Acc: 0.9241\n",
      "val Loss: 0.2104 Acc: 0.9190\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/166], Loss: 0.3230, Accuracy: 54.00%\n",
      "train Loss: 0.1657 Acc: 0.9386\n",
      "val Loss: 0.1938 Acc: 0.9305\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/166], Loss: 0.1369, Accuracy: 61.00%\n",
      "train Loss: 0.1377 Acc: 0.9471\n",
      "val Loss: 0.1572 Acc: 0.9410\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/166], Loss: 0.2106, Accuracy: 58.00%\n",
      "train Loss: 0.2643 Acc: 0.8944\n",
      "val Loss: 0.2409 Acc: 0.9067\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/166], Loss: 0.2164, Accuracy: 59.00%\n",
      "train Loss: 0.2201 Acc: 0.9130\n",
      "val Loss: 0.5888 Acc: 0.7334\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/166], Loss: 0.1941, Accuracy: 58.00%\n",
      "train Loss: 0.2107 Acc: 0.9208\n",
      "val Loss: 0.2837 Acc: 0.8839\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/166], Loss: 0.1692, Accuracy: 58.00%\n",
      "train Loss: 0.1783 Acc: 0.9326\n",
      "val Loss: 0.1871 Acc: 0.9287\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/166], Loss: 0.1343, Accuracy: 59.00%\n",
      "train Loss: 0.1527 Acc: 0.9420\n",
      "val Loss: 0.2089 Acc: 0.9125\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/166], Loss: 0.1459, Accuracy: 60.00%\n",
      "train Loss: 0.1248 Acc: 0.9545\n",
      "val Loss: 0.1555 Acc: 0.9437\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/166], Loss: 0.1006, Accuracy: 61.00%\n",
      "train Loss: 0.1083 Acc: 0.9591\n",
      "val Loss: 0.3992 Acc: 0.8605\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/166], Loss: 0.1168, Accuracy: 61.00%\n",
      "train Loss: 0.0856 Acc: 0.9693\n",
      "val Loss: 0.1434 Acc: 0.9494\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/166], Loss: 0.1293, Accuracy: 61.00%\n",
      "train Loss: 0.0683 Acc: 0.9752\n",
      "val Loss: 0.1035 Acc: 0.9591\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/166], Loss: 0.0205, Accuracy: 64.00%\n",
      "train Loss: 0.0529 Acc: 0.9819\n",
      "val Loss: 0.0970 Acc: 0.9692\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/166], Loss: 0.1922, Accuracy: 60.00%\n",
      "train Loss: 0.1707 Acc: 0.9363\n",
      "val Loss: 0.2731 Acc: 0.8953\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/166], Loss: 0.2639, Accuracy: 59.00%\n",
      "train Loss: 0.1417 Acc: 0.9480\n",
      "val Loss: 0.6240 Acc: 0.7976\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/166], Loss: 0.0774, Accuracy: 61.00%\n",
      "train Loss: 0.1175 Acc: 0.9541\n",
      "val Loss: 0.1568 Acc: 0.9415\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/166], Loss: 0.1691, Accuracy: 60.00%\n",
      "train Loss: 0.0953 Acc: 0.9646\n",
      "val Loss: 0.1133 Acc: 0.9617\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/166], Loss: 0.0623, Accuracy: 61.00%\n",
      "train Loss: 0.0743 Acc: 0.9740\n",
      "val Loss: 0.1297 Acc: 0.9582\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/166], Loss: 0.0099, Accuracy: 64.00%\n",
      "train Loss: 0.0601 Acc: 0.9775\n",
      "val Loss: 0.1078 Acc: 0.9644\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/166], Loss: 0.0163, Accuracy: 64.00%\n",
      "train Loss: 0.0457 Acc: 0.9842\n",
      "val Loss: 0.1022 Acc: 0.9608\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/166], Loss: 0.0063, Accuracy: 64.00%\n",
      "train Loss: 0.0333 Acc: 0.9876\n",
      "val Loss: 0.0998 Acc: 0.9714\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/166], Loss: 0.0033, Accuracy: 64.00%\n",
      "train Loss: 0.0229 Acc: 0.9926\n",
      "val Loss: 0.0787 Acc: 0.9754\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/166], Loss: 0.0017, Accuracy: 64.00%\n",
      "train Loss: 0.0141 Acc: 0.9952\n",
      "val Loss: 0.0810 Acc: 0.9771\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/166], Loss: 0.2100, Accuracy: 59.00%\n",
      "train Loss: 0.1030 Acc: 0.9621\n",
      "val Loss: 0.2882 Acc: 0.8975\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/166], Loss: 0.0576, Accuracy: 63.00%\n",
      "train Loss: 0.0928 Acc: 0.9678\n",
      "val Loss: 0.3461 Acc: 0.9015\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/166], Loss: 0.0334, Accuracy: 64.00%\n",
      "train Loss: 0.0785 Acc: 0.9696\n",
      "val Loss: 0.1400 Acc: 0.9507\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/166], Loss: 0.0358, Accuracy: 64.00%\n",
      "train Loss: 0.0602 Acc: 0.9801\n",
      "val Loss: 0.1230 Acc: 0.9617\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/166], Loss: 0.1429, Accuracy: 60.00%\n",
      "train Loss: 0.0389 Acc: 0.9872\n",
      "val Loss: 0.1705 Acc: 0.9406\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/166], Loss: 0.0207, Accuracy: 63.00%\n",
      "train Loss: 0.0351 Acc: 0.9879\n",
      "val Loss: 0.1109 Acc: 0.9652\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/166], Loss: 0.0695, Accuracy: 63.00%\n",
      "train Loss: 0.0163 Acc: 0.9944\n",
      "val Loss: 0.0818 Acc: 0.9745\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/166], Loss: 0.0390, Accuracy: 63.00%\n",
      "train Loss: 0.0131 Acc: 0.9958\n",
      "val Loss: 0.0793 Acc: 0.9798\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/166], Loss: 0.0020, Accuracy: 64.00%\n",
      "train Loss: 0.0111 Acc: 0.9962\n",
      "val Loss: 0.0723 Acc: 0.9780\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/166], Loss: 0.0010, Accuracy: 64.00%\n",
      "train Loss: 0.0056 Acc: 0.9984\n",
      "val Loss: 0.0781 Acc: 0.9776\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/166], Loss: 0.0320, Accuracy: 64.00%\n",
      "train Loss: 0.0860 Acc: 0.9710\n",
      "val Loss: 0.1952 Acc: 0.9309\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/166], Loss: 0.1629, Accuracy: 58.00%\n",
      "train Loss: 0.0743 Acc: 0.9723\n",
      "val Loss: 0.1090 Acc: 0.9630\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/166], Loss: 0.0203, Accuracy: 64.00%\n",
      "train Loss: 0.0502 Acc: 0.9810\n",
      "val Loss: 0.2948 Acc: 0.9142\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/166], Loss: 0.0188, Accuracy: 63.00%\n",
      "train Loss: 0.0385 Acc: 0.9867\n",
      "val Loss: 0.1295 Acc: 0.9547\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/166], Loss: 0.0384, Accuracy: 63.00%\n",
      "train Loss: 0.0244 Acc: 0.9912\n",
      "val Loss: 0.0924 Acc: 0.9732\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/166], Loss: 0.0115, Accuracy: 64.00%\n",
      "train Loss: 0.0164 Acc: 0.9942\n",
      "val Loss: 0.1209 Acc: 0.9644\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/166], Loss: 0.0075, Accuracy: 64.00%\n",
      "train Loss: 0.0131 Acc: 0.9960\n",
      "val Loss: 0.0865 Acc: 0.9767\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/166], Loss: 0.0100, Accuracy: 64.00%\n",
      "train Loss: 0.0064 Acc: 0.9985\n",
      "val Loss: 0.0735 Acc: 0.9793\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/166], Loss: 0.0010, Accuracy: 64.00%\n",
      "train Loss: 0.0046 Acc: 0.9986\n",
      "val Loss: 0.0736 Acc: 0.9793\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/166], Loss: 0.0012, Accuracy: 64.00%\n",
      "train Loss: 0.0029 Acc: 0.9990\n",
      "val Loss: 0.0746 Acc: 0.9793\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/166], Loss: 0.0159, Accuracy: 64.00%\n",
      "train Loss: 0.0634 Acc: 0.9777\n",
      "val Loss: 1.1232 Acc: 0.8460\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/166], Loss: 0.0175, Accuracy: 64.00%\n",
      "train Loss: 0.0505 Acc: 0.9827\n",
      "val Loss: 0.0970 Acc: 0.9692\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/166], Loss: 0.0507, Accuracy: 63.00%\n",
      "train Loss: 0.0388 Acc: 0.9853\n",
      "val Loss: 0.5201 Acc: 0.8821\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/166], Loss: 0.0953, Accuracy: 62.00%\n",
      "train Loss: 0.0263 Acc: 0.9911\n",
      "val Loss: 0.0991 Acc: 0.9688\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/166], Loss: 0.0104, Accuracy: 64.00%\n",
      "train Loss: 0.0157 Acc: 0.9946\n",
      "val Loss: 0.0994 Acc: 0.9714\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/166], Loss: 0.0441, Accuracy: 63.00%\n",
      "train Loss: 0.0126 Acc: 0.9957\n",
      "val Loss: 0.0774 Acc: 0.9762\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/166], Loss: 0.0001, Accuracy: 64.00%\n",
      "train Loss: 0.0053 Acc: 0.9984\n",
      "val Loss: 0.0799 Acc: 0.9767\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/166], Loss: 0.0013, Accuracy: 64.00%\n",
      "train Loss: 0.0027 Acc: 0.9992\n",
      "val Loss: 0.0685 Acc: 0.9811\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/166], Loss: 0.0010, Accuracy: 64.00%\n",
      "train Loss: 0.0016 Acc: 0.9995\n",
      "val Loss: 0.0651 Acc: 0.9842\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/166], Loss: 0.0000, Accuracy: 64.00%\n",
      "train Loss: 0.0013 Acc: 0.9998\n",
      "val Loss: 0.0697 Acc: 0.9837\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/166], Loss: 0.1407, Accuracy: 61.00%\n",
      "train Loss: 0.0481 Acc: 0.9836\n",
      "val Loss: 0.1247 Acc: 0.9551\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/166], Loss: 0.0042, Accuracy: 64.00%\n",
      "train Loss: 0.0441 Acc: 0.9847\n",
      "val Loss: 0.1552 Acc: 0.9586\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/166], Loss: 0.0291, Accuracy: 63.00%\n",
      "train Loss: 0.0270 Acc: 0.9908\n",
      "val Loss: 0.0999 Acc: 0.9657\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/166], Loss: 0.0242, Accuracy: 63.00%\n",
      "train Loss: 0.0231 Acc: 0.9917\n",
      "val Loss: 0.1264 Acc: 0.9674\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/166], Loss: 0.0023, Accuracy: 64.00%\n",
      "train Loss: 0.0121 Acc: 0.9959\n",
      "val Loss: 0.0939 Acc: 0.9754\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/166], Loss: 0.0008, Accuracy: 64.00%\n",
      "train Loss: 0.0107 Acc: 0.9958\n",
      "val Loss: 0.0738 Acc: 0.9806\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/166], Loss: 0.0011, Accuracy: 64.00%\n",
      "train Loss: 0.0032 Acc: 0.9990\n",
      "val Loss: 0.0739 Acc: 0.9793\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/166], Loss: 0.0001, Accuracy: 64.00%\n",
      "train Loss: 0.0029 Acc: 0.9988\n",
      "val Loss: 0.0704 Acc: 0.9828\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/166], Loss: 0.0042, Accuracy: 64.00%\n",
      "train Loss: 0.0010 Acc: 0.9999\n",
      "val Loss: 0.0707 Acc: 0.9820\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/166], Loss: 0.0001, Accuracy: 64.00%\n",
      "train Loss: 0.0021 Acc: 0.9994\n",
      "val Loss: 0.0686 Acc: 0.9815\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/166], Loss: 0.1057, Accuracy: 62.00%\n",
      "train Loss: 0.0525 Acc: 0.9809\n",
      "val Loss: 0.1403 Acc: 0.9564\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/166], Loss: 0.0099, Accuracy: 64.00%\n",
      "train Loss: 0.0405 Acc: 0.9853\n",
      "val Loss: 0.1243 Acc: 0.9600\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/166], Loss: 0.0012, Accuracy: 64.00%\n",
      "train Loss: 0.0161 Acc: 0.9941\n",
      "val Loss: 0.1153 Acc: 0.9688\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/166], Loss: 0.0076, Accuracy: 64.00%\n",
      "train Loss: 0.0144 Acc: 0.9954\n",
      "val Loss: 0.2722 Acc: 0.9336\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/166], Loss: 0.0076, Accuracy: 64.00%\n",
      "train Loss: 0.0096 Acc: 0.9971\n",
      "val Loss: 0.0778 Acc: 0.9771\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/166], Loss: 0.0018, Accuracy: 64.00%\n",
      "train Loss: 0.0045 Acc: 0.9989\n",
      "val Loss: 0.0772 Acc: 0.9727\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/166], Loss: 0.0010, Accuracy: 64.00%\n",
      "train Loss: 0.0018 Acc: 0.9997\n",
      "val Loss: 0.0666 Acc: 0.9789\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/166], Loss: 0.0003, Accuracy: 64.00%\n",
      "train Loss: 0.0012 Acc: 0.9997\n",
      "val Loss: 0.0714 Acc: 0.9806\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/166], Loss: 0.0042, Accuracy: 64.00%\n",
      "train Loss: 0.0010 Acc: 0.9997\n",
      "val Loss: 0.0787 Acc: 0.9802\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/166], Loss: 0.0002, Accuracy: 64.00%\n",
      "train Loss: 0.0010 Acc: 0.9997\n",
      "val Loss: 0.0744 Acc: 0.9793\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/166], Loss: 0.1211, Accuracy: 60.00%\n",
      "train Loss: 0.0407 Acc: 0.9861\n",
      "val Loss: 0.2807 Acc: 0.9300\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/166], Loss: 0.0041, Accuracy: 64.00%\n",
      "train Loss: 0.0430 Acc: 0.9843\n",
      "val Loss: 0.1083 Acc: 0.9657\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/166], Loss: 0.0180, Accuracy: 63.00%\n",
      "train Loss: 0.0176 Acc: 0.9942\n",
      "val Loss: 0.1132 Acc: 0.9661\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/166], Loss: 0.0221, Accuracy: 63.00%\n",
      "train Loss: 0.0094 Acc: 0.9966\n",
      "val Loss: 0.1109 Acc: 0.9710\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/166], Loss: 0.0543, Accuracy: 63.00%\n",
      "train Loss: 0.0088 Acc: 0.9967\n",
      "val Loss: 0.0847 Acc: 0.9776\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/166], Loss: 0.0002, Accuracy: 64.00%\n",
      "train Loss: 0.0046 Acc: 0.9986\n",
      "val Loss: 0.0706 Acc: 0.9811\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/166], Loss: 0.0000, Accuracy: 64.00%\n",
      "train Loss: 0.0017 Acc: 0.9998\n",
      "val Loss: 0.0832 Acc: 0.9811\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/166], Loss: 0.0001, Accuracy: 64.00%\n",
      "train Loss: 0.0020 Acc: 0.9996\n",
      "val Loss: 0.0703 Acc: 0.9842\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/166], Loss: 0.0002, Accuracy: 64.00%\n",
      "train Loss: 0.0010 Acc: 0.9996\n",
      "val Loss: 0.0709 Acc: 0.9850\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/166], Loss: 0.0003, Accuracy: 64.00%\n",
      "train Loss: 0.0009 Acc: 0.9997\n",
      "val Loss: 0.0700 Acc: 0.9859\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/166], Loss: 0.0000, Accuracy: 64.00%\n",
      "train Loss: 0.0375 Acc: 0.9891\n",
      "val Loss: 0.4632 Acc: 0.8839\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/166], Loss: 0.0022, Accuracy: 64.00%\n",
      "train Loss: 0.0367 Acc: 0.9875\n",
      "val Loss: 0.0762 Acc: 0.9749\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/166], Loss: 0.0012, Accuracy: 64.00%\n",
      "train Loss: 0.0113 Acc: 0.9960\n",
      "val Loss: 0.0924 Acc: 0.9723\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/166], Loss: 0.0062, Accuracy: 64.00%\n",
      "train Loss: 0.0099 Acc: 0.9968\n",
      "val Loss: 0.0775 Acc: 0.9811\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/166], Loss: 0.0009, Accuracy: 64.00%\n",
      "train Loss: 0.0048 Acc: 0.9984\n",
      "val Loss: 0.0670 Acc: 0.9855\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/166], Loss: 0.0015, Accuracy: 64.00%\n",
      "train Loss: 0.0035 Acc: 0.9992\n",
      "val Loss: 0.0741 Acc: 0.9837\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/166], Loss: 0.0006, Accuracy: 64.00%\n",
      "train Loss: 0.0016 Acc: 0.9996\n",
      "val Loss: 0.0646 Acc: 0.9842\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/166], Loss: 0.0009, Accuracy: 64.00%\n",
      "train Loss: 0.0013 Acc: 0.9997\n",
      "val Loss: 0.0722 Acc: 0.9828\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/166], Loss: 0.0002, Accuracy: 64.00%\n",
      "train Loss: 0.0009 Acc: 0.9998\n",
      "val Loss: 0.0697 Acc: 0.9833\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/166], Loss: 0.0000, Accuracy: 64.00%\n",
      "train Loss: 0.0006 Acc: 0.9999\n",
      "val Loss: 0.0627 Acc: 0.9859\n",
      "\n",
      "Training complete in 113m 51s\n",
      "Best val Acc: 0.985922\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=iter_restart, T_mult=mul_restart, \n",
    "                                                           eta_min=lr_end, last_epoch=-1)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'covid_pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt, '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9777070063694268\n",
      "f1: 0.9706436893428764\n",
      "cm: [[ 514   27    2]\n",
      " [   7 1440    6]\n",
      " [   2    5  195]]\n",
      "outputs: [0 0 1 ... 2 2 2]\n",
      "targets: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
