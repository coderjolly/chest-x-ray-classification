{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50b02a4-afe3-4b9a-b6d7-862e313d05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d93b8e70-1b13-4b94-8150-4c9f8b02de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data import load_data\n",
    "from multilabel.loader import MultiLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b975bc31-b4f3-4e5f-9396-c95faec6f4ba",
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deeddf6b-ec3d-46f7-8f52-b3e4d1f81d4c",
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab4f91ac-bf77-4376-b36e-1a51d38616f8",
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data/xray8\"\n",
    "images_dir = \"../../data/xray8/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5252376-80da-41de-8a9e-6238b5f97cf0",
   "metadata": {
    "id": "Tw4oZtz0j47N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,\"train.csv\"))\n",
    "val = pd.read_csv(os.path.join(data_dir,\"val.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_dir,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "486f40f3-3dfa-4e06-8942-454c70a8eff2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "GrhqYNEPj47N",
    "outputId": "ae41146c-5e99-4e5f-dcae-8166dd2c2bbc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>FilePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00017638_000.png</td>\n",
       "      <td>17638</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>images_008/images/00017638_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00011258_000.png</td>\n",
       "      <td>11258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>images_005/images/00011258_000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index  Patient ID  Effusion  No Finding  Mass  Nodule  \\\n",
       "0  00017638_000.png       17638         0           1     0       0   \n",
       "1  00011258_000.png       11258         0           1     0       0   \n",
       "\n",
       "   Atelectasis  Pneumothorax  Consolidation  \\\n",
       "0            0             0              0   \n",
       "1            0             0              0   \n",
       "\n",
       "                             FilePath  \n",
       "0  images_008/images/00017638_000.png  \n",
       "1  images_005/images/00011258_000.png  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b8eeb-90a1-453d-a7c2-23e54922d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ec7a71c-ba12-468e-8d73-1b2ee9116c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "batch_size = 64\n",
    "image_size=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ff5601b-4b32-4c04-914a-16a463ecf5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = T.Compose([T.Resize(size=image_size),\n",
    "                 T.ToTensor(),\n",
    "                 T.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1))])\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\")).drop(['FilePath', 'Patient ID'], axis=1).set_index('Image Index')\n",
    "test = pd.read_csv(os.path.join(data_dir, \"test.csv\")).drop(['FilePath', 'Patient ID'], axis=1).set_index('Image Index')\n",
    "val = pd.read_csv(os.path.join(data_dir, \"val.csv\")).drop(['FilePath', 'Patient ID'], axis=1).set_index('Image Index')\n",
    "\n",
    "train_dataset = MultiLabelDataset(root=os.path.join(data_dir, \"train\"),\n",
    "                                     dataframe=train,\n",
    "                                     transform=aug)\n",
    "val_dataset = MultiLabelDataset(root=os.path.join(data_dir, \"val\"),\n",
    "                                   dataframe=val,\n",
    "                                   transform=aug)\n",
    "test_dataset = MultiLabelDataset(root=os.path.join(data_dir, \"test\"),\n",
    "                                    dataframe=test,\n",
    "                                    transform=aug)\n",
    "\n",
    "data_loader_train = td.DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=num_workers,\n",
    "                                  pin_memory=True)\n",
    "data_loader_val = td.DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True)\n",
    "data_loader_test = td.DataLoader(test_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 drop_last=False,\n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6a41e8d-adba-4505-b52b-5bb44ab8ac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 320/320 [00:38<00:00,  8.30it/s]\n"
     ]
    }
   ],
   "source": [
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs, labels in tqdm(data_loader_train):\n",
    "    psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d5c5785-1d3a-4dc2-8286-06fd146764e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4955, 0.4955, 0.4955])\n",
      "std:  tensor([0.2892, 0.2892, 0.2892])\n"
     ]
    }
   ],
   "source": [
    "count = len(train) * image_size * image_size\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3b127-fee8-4225-8451-eb33e087186e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8df119e9-08b9-4b90-9a1c-842d8fbd0ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:15<00:00,  4.20it/s]\n"
     ]
    }
   ],
   "source": [
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs, labels in tqdm(data_loader_val):\n",
    "    psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b1fb5ac-34ef-4864-94a5-ad8b3187dbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4956, 0.4956, 0.4956])\n",
      "std:  tensor([0.2889, 0.2889, 0.2889])\n"
     ]
    }
   ],
   "source": [
    "count = len(val) * image_size * image_size\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e3458-23f7-4472-92d3-f3ba348de9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8efa995-00f6-4d29-b02e-a99832cb978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:15<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs, labels in tqdm(data_loader_test):\n",
    "    psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d93c5238-fd26-44e9-8d6f-8caf7620ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4957, 0.4957, 0.4957])\n",
      "std:  tensor([0.2889, 0.2889, 0.2889])\n"
     ]
    }
   ],
   "source": [
    "count = len(test) * image_size * image_size\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffe414-f01b-4917-92f4-1672f78add44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae8f8ffa-e8a7-482b-ab08-0eb3796c20c8",
   "metadata": {},
   "source": [
    "## Calculating pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc88c0c-9a80-46d1-939a-0f895b1fed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_weights(class_counts,data):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    neg_counts = [len(data)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "        pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d964b4d-0198-48d8-be2b-8dd911b9ea96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 6., 6., 3., 7., 9.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_pos_weights([5158, 4896, 2771, 2857, 4974, 2502, 2028], data_loader_train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9f2247a-c9c8-47cf-9580-e55adb98e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9edcd06e-bb97-44a0-b222-37e33adcb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "b = None\n",
    "for inp, tar in data_loader_train:\n",
    "    a = inp\n",
    "    b = tar\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0afa5-4b85-4f5f-89c9-9fa87f5f8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "[2., 3., 6., 6., 3., 7., 9.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7e9babc-06cf-4b85-947f-6556261df62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931)\n",
      "tensor(0.8912)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loss = criterion(torch.zeros(64, 7), b)\n",
    "print(loss)\n",
    "\n",
    "criterion_weighted = nn.BCEWithLogitsLoss(pos_weight=torch.as_tensor([2., 3., 6., 6., 3., 7., 9.], dtype=torch.float))\n",
    "loss_weighted = criterion_weighted(torch.zeros(64, 7), b)\n",
    "print(loss_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c2c27bc-e921-4854-ab9b-46232aadb6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931)\n",
      "tensor(1.1569)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loss = criterion(torch.zeros(64, 7), b)\n",
    "print(loss)\n",
    "\n",
    "criterion_weighted = nn.BCEWithLogitsLoss(pos_weight=torch.as_tensor(20450*7/25186, dtype=torch.float))\n",
    "loss_weighted = criterion_weighted(torch.zeros(64, 7), b)\n",
    "print(loss_weighted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
