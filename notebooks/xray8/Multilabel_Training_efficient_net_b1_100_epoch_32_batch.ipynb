{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/xray8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"efficient_net_b1\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 7\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4951, 0.4951, 0.4951], [0.2896, 0.2896, 0.2896])\n",
    "\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Effusion',\n",
       " 'No Finding',\n",
       " 'Mass',\n",
       " 'Nodule',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Consolidation']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/640], Loss: 0.4579, Accuracy: 25.86%\n",
      "Epoch [1/100], Step [200/640], Loss: 0.4356, Accuracy: 26.57%\n",
      "Epoch [1/100], Step [300/640], Loss: 0.4487, Accuracy: 26.43%\n",
      "Epoch [1/100], Step [400/640], Loss: 0.4771, Accuracy: 25.43%\n",
      "Epoch [1/100], Step [500/640], Loss: 0.4105, Accuracy: 26.86%\n",
      "Epoch [1/100], Step [600/640], Loss: 0.4191, Accuracy: 26.86%\n",
      "train Loss: 0.4506 Acc: 0.8236\n",
      "Epoch [1/100], Step [100/640], Loss: 0.4644, Accuracy: 26.00%\n",
      "val Loss: 0.4401 Acc: 0.8256\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/640], Loss: 0.3881, Accuracy: 27.00%\n",
      "Epoch [2/100], Step [200/640], Loss: 0.3905, Accuracy: 27.14%\n",
      "Epoch [2/100], Step [300/640], Loss: 0.4892, Accuracy: 25.71%\n",
      "Epoch [2/100], Step [400/640], Loss: 0.4396, Accuracy: 26.14%\n",
      "Epoch [2/100], Step [500/640], Loss: 0.4266, Accuracy: 26.71%\n",
      "Epoch [2/100], Step [600/640], Loss: 0.3985, Accuracy: 26.43%\n",
      "train Loss: 0.4314 Acc: 0.8243\n",
      "Epoch [2/100], Step [100/640], Loss: 0.5029, Accuracy: 26.00%\n",
      "val Loss: 0.4514 Acc: 0.8256\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/640], Loss: 0.3986, Accuracy: 26.43%\n",
      "Epoch [3/100], Step [200/640], Loss: 0.4524, Accuracy: 26.29%\n",
      "Epoch [3/100], Step [300/640], Loss: 0.4242, Accuracy: 26.14%\n",
      "Epoch [3/100], Step [400/640], Loss: 0.4350, Accuracy: 26.14%\n",
      "Epoch [3/100], Step [500/640], Loss: 0.3939, Accuracy: 26.57%\n",
      "Epoch [3/100], Step [600/640], Loss: 0.4075, Accuracy: 26.43%\n",
      "train Loss: 0.4278 Acc: 0.8247\n",
      "Epoch [3/100], Step [100/640], Loss: 0.4609, Accuracy: 26.00%\n",
      "val Loss: 0.4260 Acc: 0.8259\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/640], Loss: 0.4144, Accuracy: 26.14%\n",
      "Epoch [4/100], Step [200/640], Loss: 0.4097, Accuracy: 26.57%\n",
      "Epoch [4/100], Step [300/640], Loss: 0.4184, Accuracy: 26.71%\n",
      "Epoch [4/100], Step [400/640], Loss: 0.4735, Accuracy: 25.86%\n",
      "Epoch [4/100], Step [500/640], Loss: 0.3710, Accuracy: 26.57%\n",
      "Epoch [4/100], Step [600/640], Loss: 0.4327, Accuracy: 25.86%\n",
      "train Loss: 0.4236 Acc: 0.8254\n",
      "Epoch [4/100], Step [100/640], Loss: 0.5058, Accuracy: 25.29%\n",
      "val Loss: 0.4203 Acc: 0.8281\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/640], Loss: 0.4702, Accuracy: 25.29%\n",
      "Epoch [5/100], Step [200/640], Loss: 0.4767, Accuracy: 25.43%\n",
      "Epoch [5/100], Step [300/640], Loss: 0.3399, Accuracy: 27.00%\n",
      "Epoch [5/100], Step [400/640], Loss: 0.4292, Accuracy: 26.29%\n",
      "Epoch [5/100], Step [500/640], Loss: 0.4176, Accuracy: 26.71%\n",
      "Epoch [5/100], Step [600/640], Loss: 0.3938, Accuracy: 27.00%\n",
      "train Loss: 0.4216 Acc: 0.8256\n",
      "Epoch [5/100], Step [100/640], Loss: 0.4627, Accuracy: 26.43%\n",
      "val Loss: 0.4170 Acc: 0.8292\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/640], Loss: 0.4155, Accuracy: 26.14%\n",
      "Epoch [6/100], Step [200/640], Loss: 0.4288, Accuracy: 27.00%\n",
      "Epoch [6/100], Step [300/640], Loss: 0.4196, Accuracy: 26.29%\n",
      "Epoch [6/100], Step [400/640], Loss: 0.4240, Accuracy: 26.71%\n",
      "Epoch [6/100], Step [500/640], Loss: 0.3868, Accuracy: 26.71%\n",
      "Epoch [6/100], Step [600/640], Loss: 0.4117, Accuracy: 27.00%\n",
      "train Loss: 0.4170 Acc: 0.8263\n",
      "Epoch [6/100], Step [100/640], Loss: 0.5372, Accuracy: 25.14%\n",
      "val Loss: 0.4556 Acc: 0.8235\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/640], Loss: 0.3878, Accuracy: 26.86%\n",
      "Epoch [7/100], Step [200/640], Loss: 0.3941, Accuracy: 26.57%\n",
      "Epoch [7/100], Step [300/640], Loss: 0.4189, Accuracy: 25.86%\n",
      "Epoch [7/100], Step [400/640], Loss: 0.4028, Accuracy: 26.29%\n",
      "Epoch [7/100], Step [500/640], Loss: 0.4417, Accuracy: 26.29%\n",
      "Epoch [7/100], Step [600/640], Loss: 0.3593, Accuracy: 27.14%\n",
      "train Loss: 0.4146 Acc: 0.8272\n",
      "Epoch [7/100], Step [100/640], Loss: 0.4673, Accuracy: 26.00%\n",
      "val Loss: 0.4134 Acc: 0.8300\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/640], Loss: 0.3833, Accuracy: 27.29%\n",
      "Epoch [8/100], Step [200/640], Loss: 0.3568, Accuracy: 27.57%\n",
      "Epoch [8/100], Step [300/640], Loss: 0.4072, Accuracy: 26.29%\n",
      "Epoch [8/100], Step [400/640], Loss: 0.5074, Accuracy: 25.57%\n",
      "Epoch [8/100], Step [500/640], Loss: 0.4303, Accuracy: 26.71%\n",
      "Epoch [8/100], Step [600/640], Loss: 0.4029, Accuracy: 26.43%\n",
      "train Loss: 0.4119 Acc: 0.8276\n",
      "Epoch [8/100], Step [100/640], Loss: 0.4856, Accuracy: 26.14%\n",
      "val Loss: 0.4121 Acc: 0.8273\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/640], Loss: 0.4076, Accuracy: 26.14%\n",
      "Epoch [9/100], Step [200/640], Loss: 0.4302, Accuracy: 25.86%\n",
      "Epoch [9/100], Step [300/640], Loss: 0.4397, Accuracy: 26.86%\n",
      "Epoch [9/100], Step [400/640], Loss: 0.4172, Accuracy: 26.71%\n",
      "Epoch [9/100], Step [500/640], Loss: 0.4485, Accuracy: 25.86%\n",
      "Epoch [9/100], Step [600/640], Loss: 0.4035, Accuracy: 26.57%\n",
      "train Loss: 0.4099 Acc: 0.8284\n",
      "Epoch [9/100], Step [100/640], Loss: 0.5125, Accuracy: 26.43%\n",
      "val Loss: 0.4286 Acc: 0.8311\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/640], Loss: 0.4191, Accuracy: 26.57%\n",
      "Epoch [10/100], Step [200/640], Loss: 0.3779, Accuracy: 26.86%\n",
      "Epoch [10/100], Step [300/640], Loss: 0.4187, Accuracy: 26.43%\n",
      "Epoch [10/100], Step [400/640], Loss: 0.4453, Accuracy: 26.43%\n",
      "Epoch [10/100], Step [500/640], Loss: 0.3704, Accuracy: 27.29%\n",
      "Epoch [10/100], Step [600/640], Loss: 0.4213, Accuracy: 26.43%\n",
      "train Loss: 0.4079 Acc: 0.8285\n",
      "Epoch [10/100], Step [100/640], Loss: 0.4698, Accuracy: 26.57%\n",
      "val Loss: 0.4191 Acc: 0.8305\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/640], Loss: 0.3992, Accuracy: 26.57%\n",
      "Epoch [11/100], Step [200/640], Loss: 0.4326, Accuracy: 26.57%\n",
      "Epoch [11/100], Step [300/640], Loss: 0.4542, Accuracy: 26.29%\n",
      "Epoch [11/100], Step [400/640], Loss: 0.4167, Accuracy: 26.43%\n",
      "Epoch [11/100], Step [500/640], Loss: 0.3898, Accuracy: 27.00%\n",
      "Epoch [11/100], Step [600/640], Loss: 0.3757, Accuracy: 27.00%\n",
      "train Loss: 0.4055 Acc: 0.8299\n",
      "Epoch [11/100], Step [100/640], Loss: 0.5126, Accuracy: 25.43%\n",
      "val Loss: 0.4093 Acc: 0.8330\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/640], Loss: 0.3553, Accuracy: 26.86%\n",
      "Epoch [12/100], Step [200/640], Loss: 0.4154, Accuracy: 27.29%\n",
      "Epoch [12/100], Step [300/640], Loss: 0.4508, Accuracy: 26.43%\n",
      "Epoch [12/100], Step [400/640], Loss: 0.4382, Accuracy: 26.57%\n",
      "Epoch [12/100], Step [500/640], Loss: 0.3880, Accuracy: 27.00%\n",
      "Epoch [12/100], Step [600/640], Loss: 0.3530, Accuracy: 27.00%\n",
      "train Loss: 0.4042 Acc: 0.8302\n",
      "Epoch [12/100], Step [100/640], Loss: 0.4841, Accuracy: 25.29%\n",
      "val Loss: 0.4279 Acc: 0.8296\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/640], Loss: 0.3816, Accuracy: 26.29%\n",
      "Epoch [13/100], Step [200/640], Loss: 0.3702, Accuracy: 27.00%\n",
      "Epoch [13/100], Step [300/640], Loss: 0.3740, Accuracy: 26.57%\n",
      "Epoch [13/100], Step [400/640], Loss: 0.3746, Accuracy: 26.43%\n",
      "Epoch [13/100], Step [500/640], Loss: 0.4310, Accuracy: 26.14%\n",
      "Epoch [13/100], Step [600/640], Loss: 0.4194, Accuracy: 25.71%\n",
      "train Loss: 0.4017 Acc: 0.8310\n",
      "Epoch [13/100], Step [100/640], Loss: 0.4946, Accuracy: 25.86%\n",
      "val Loss: 0.4100 Acc: 0.8337\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/640], Loss: 0.3991, Accuracy: 26.43%\n",
      "Epoch [14/100], Step [200/640], Loss: 0.4009, Accuracy: 26.57%\n",
      "Epoch [14/100], Step [300/640], Loss: 0.4221, Accuracy: 26.29%\n",
      "Epoch [14/100], Step [400/640], Loss: 0.3671, Accuracy: 26.43%\n",
      "Epoch [14/100], Step [500/640], Loss: 0.3625, Accuracy: 26.43%\n",
      "Epoch [14/100], Step [600/640], Loss: 0.4013, Accuracy: 26.43%\n",
      "train Loss: 0.3981 Acc: 0.8318\n",
      "Epoch [14/100], Step [100/640], Loss: 0.4326, Accuracy: 26.00%\n",
      "val Loss: 0.3974 Acc: 0.8302\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/640], Loss: 0.3534, Accuracy: 26.71%\n",
      "Epoch [15/100], Step [200/640], Loss: 0.3516, Accuracy: 27.71%\n",
      "Epoch [15/100], Step [300/640], Loss: 0.4377, Accuracy: 26.57%\n",
      "Epoch [15/100], Step [400/640], Loss: 0.4093, Accuracy: 26.29%\n",
      "Epoch [15/100], Step [500/640], Loss: 0.3402, Accuracy: 27.43%\n",
      "Epoch [15/100], Step [600/640], Loss: 0.3895, Accuracy: 26.29%\n",
      "train Loss: 0.3959 Acc: 0.8327\n",
      "Epoch [15/100], Step [100/640], Loss: 0.4700, Accuracy: 26.71%\n",
      "val Loss: 0.3945 Acc: 0.8354\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/640], Loss: 0.4011, Accuracy: 26.00%\n",
      "Epoch [16/100], Step [200/640], Loss: 0.3733, Accuracy: 27.14%\n",
      "Epoch [16/100], Step [300/640], Loss: 0.4056, Accuracy: 26.29%\n",
      "Epoch [16/100], Step [400/640], Loss: 0.3737, Accuracy: 26.71%\n",
      "Epoch [16/100], Step [500/640], Loss: 0.4270, Accuracy: 26.43%\n",
      "Epoch [16/100], Step [600/640], Loss: 0.3743, Accuracy: 27.43%\n",
      "train Loss: 0.3931 Acc: 0.8340\n",
      "Epoch [16/100], Step [100/640], Loss: 0.4707, Accuracy: 26.14%\n",
      "val Loss: 0.4305 Acc: 0.8253\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/640], Loss: 0.3946, Accuracy: 25.86%\n",
      "Epoch [17/100], Step [200/640], Loss: 0.3492, Accuracy: 26.57%\n",
      "Epoch [17/100], Step [300/640], Loss: 0.3757, Accuracy: 26.71%\n",
      "Epoch [17/100], Step [400/640], Loss: 0.3968, Accuracy: 26.71%\n",
      "Epoch [17/100], Step [500/640], Loss: 0.3670, Accuracy: 26.86%\n",
      "Epoch [17/100], Step [600/640], Loss: 0.4021, Accuracy: 26.71%\n",
      "train Loss: 0.3898 Acc: 0.8346\n",
      "Epoch [17/100], Step [100/640], Loss: 0.4710, Accuracy: 25.86%\n",
      "val Loss: 0.3882 Acc: 0.8366\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/640], Loss: 0.4173, Accuracy: 26.71%\n",
      "Epoch [18/100], Step [200/640], Loss: 0.4108, Accuracy: 27.14%\n",
      "Epoch [18/100], Step [300/640], Loss: 0.4035, Accuracy: 26.29%\n",
      "Epoch [18/100], Step [400/640], Loss: 0.4408, Accuracy: 25.29%\n",
      "Epoch [18/100], Step [500/640], Loss: 0.3679, Accuracy: 27.29%\n",
      "Epoch [18/100], Step [600/640], Loss: 0.3771, Accuracy: 27.00%\n",
      "train Loss: 0.3877 Acc: 0.8357\n",
      "Epoch [18/100], Step [100/640], Loss: 0.4621, Accuracy: 25.57%\n",
      "val Loss: 0.3902 Acc: 0.8335\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/640], Loss: 0.4266, Accuracy: 25.86%\n",
      "Epoch [19/100], Step [200/640], Loss: 0.3654, Accuracy: 27.00%\n",
      "Epoch [19/100], Step [300/640], Loss: 0.3485, Accuracy: 26.86%\n",
      "Epoch [19/100], Step [400/640], Loss: 0.3801, Accuracy: 26.43%\n",
      "Epoch [19/100], Step [500/640], Loss: 0.3593, Accuracy: 26.86%\n",
      "Epoch [19/100], Step [600/640], Loss: 0.3622, Accuracy: 27.00%\n",
      "train Loss: 0.3857 Acc: 0.8368\n",
      "Epoch [19/100], Step [100/640], Loss: 0.4031, Accuracy: 26.29%\n",
      "val Loss: 0.3857 Acc: 0.8382\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/640], Loss: 0.4251, Accuracy: 27.14%\n",
      "Epoch [20/100], Step [200/640], Loss: 0.3684, Accuracy: 26.71%\n",
      "Epoch [20/100], Step [300/640], Loss: 0.4153, Accuracy: 25.57%\n",
      "Epoch [20/100], Step [400/640], Loss: 0.3445, Accuracy: 27.43%\n",
      "Epoch [20/100], Step [500/640], Loss: 0.3716, Accuracy: 26.71%\n",
      "Epoch [20/100], Step [600/640], Loss: 0.3691, Accuracy: 26.43%\n",
      "train Loss: 0.3820 Acc: 0.8383\n",
      "Epoch [20/100], Step [100/640], Loss: 0.4876, Accuracy: 25.43%\n",
      "val Loss: 0.3919 Acc: 0.8374\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/640], Loss: 0.3239, Accuracy: 27.43%\n",
      "Epoch [21/100], Step [200/640], Loss: 0.3323, Accuracy: 27.00%\n",
      "Epoch [21/100], Step [300/640], Loss: 0.3594, Accuracy: 26.86%\n",
      "Epoch [21/100], Step [400/640], Loss: 0.3558, Accuracy: 27.86%\n",
      "Epoch [21/100], Step [500/640], Loss: 0.4713, Accuracy: 25.43%\n",
      "Epoch [21/100], Step [600/640], Loss: 0.3806, Accuracy: 26.43%\n",
      "train Loss: 0.3816 Acc: 0.8388\n",
      "Epoch [21/100], Step [100/640], Loss: 0.4565, Accuracy: 26.43%\n",
      "val Loss: 0.3796 Acc: 0.8403\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/640], Loss: 0.4010, Accuracy: 27.14%\n",
      "Epoch [22/100], Step [200/640], Loss: 0.3600, Accuracy: 27.29%\n",
      "Epoch [22/100], Step [300/640], Loss: 0.4097, Accuracy: 26.57%\n",
      "Epoch [22/100], Step [400/640], Loss: 0.3719, Accuracy: 26.86%\n",
      "Epoch [22/100], Step [500/640], Loss: 0.3610, Accuracy: 26.71%\n",
      "Epoch [22/100], Step [600/640], Loss: 0.4405, Accuracy: 26.43%\n",
      "train Loss: 0.3777 Acc: 0.8398\n",
      "Epoch [22/100], Step [100/640], Loss: 0.4133, Accuracy: 26.57%\n",
      "val Loss: 0.3871 Acc: 0.8391\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/640], Loss: 0.3720, Accuracy: 27.43%\n",
      "Epoch [23/100], Step [200/640], Loss: 0.3704, Accuracy: 26.71%\n",
      "Epoch [23/100], Step [300/640], Loss: 0.3867, Accuracy: 27.14%\n",
      "Epoch [23/100], Step [400/640], Loss: 0.3310, Accuracy: 27.86%\n",
      "Epoch [23/100], Step [500/640], Loss: 0.4107, Accuracy: 26.29%\n",
      "Epoch [23/100], Step [600/640], Loss: 0.3688, Accuracy: 26.14%\n",
      "train Loss: 0.3764 Acc: 0.8402\n",
      "Epoch [23/100], Step [100/640], Loss: 0.4972, Accuracy: 26.00%\n",
      "val Loss: 0.3941 Acc: 0.8410\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/640], Loss: 0.3679, Accuracy: 28.00%\n",
      "Epoch [24/100], Step [200/640], Loss: 0.3824, Accuracy: 27.14%\n",
      "Epoch [24/100], Step [300/640], Loss: 0.3747, Accuracy: 26.29%\n",
      "Epoch [24/100], Step [400/640], Loss: 0.4292, Accuracy: 26.29%\n",
      "Epoch [24/100], Step [500/640], Loss: 0.3294, Accuracy: 28.14%\n",
      "Epoch [24/100], Step [600/640], Loss: 0.4201, Accuracy: 26.14%\n",
      "train Loss: 0.3739 Acc: 0.8410\n",
      "Epoch [24/100], Step [100/640], Loss: 0.4184, Accuracy: 26.86%\n",
      "val Loss: 0.3824 Acc: 0.8376\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/640], Loss: 0.3784, Accuracy: 26.57%\n",
      "Epoch [25/100], Step [200/640], Loss: 0.3930, Accuracy: 27.14%\n",
      "Epoch [25/100], Step [300/640], Loss: 0.3784, Accuracy: 26.43%\n",
      "Epoch [25/100], Step [400/640], Loss: 0.3656, Accuracy: 26.57%\n",
      "Epoch [25/100], Step [500/640], Loss: 0.3887, Accuracy: 26.86%\n",
      "Epoch [25/100], Step [600/640], Loss: 0.4127, Accuracy: 26.71%\n",
      "train Loss: 0.3722 Acc: 0.8419\n",
      "Epoch [25/100], Step [100/640], Loss: 0.4483, Accuracy: 26.29%\n",
      "val Loss: 0.3789 Acc: 0.8441\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/640], Loss: 0.3876, Accuracy: 26.14%\n",
      "Epoch [26/100], Step [200/640], Loss: 0.3801, Accuracy: 27.43%\n",
      "Epoch [26/100], Step [300/640], Loss: 0.4324, Accuracy: 26.57%\n",
      "Epoch [26/100], Step [400/640], Loss: 0.4490, Accuracy: 26.14%\n",
      "Epoch [26/100], Step [500/640], Loss: 0.4239, Accuracy: 25.86%\n",
      "Epoch [26/100], Step [600/640], Loss: 0.3158, Accuracy: 27.29%\n",
      "train Loss: 0.3696 Acc: 0.8426\n",
      "Epoch [26/100], Step [100/640], Loss: 0.3784, Accuracy: 27.29%\n",
      "val Loss: 0.3924 Acc: 0.8398\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/640], Loss: 0.3539, Accuracy: 26.71%\n",
      "Epoch [27/100], Step [200/640], Loss: 0.3477, Accuracy: 27.00%\n",
      "Epoch [27/100], Step [300/640], Loss: 0.3882, Accuracy: 26.86%\n",
      "Epoch [27/100], Step [400/640], Loss: 0.4221, Accuracy: 27.43%\n",
      "Epoch [27/100], Step [500/640], Loss: 0.3775, Accuracy: 26.57%\n",
      "Epoch [27/100], Step [600/640], Loss: 0.3757, Accuracy: 26.57%\n",
      "train Loss: 0.3675 Acc: 0.8432\n",
      "Epoch [27/100], Step [100/640], Loss: 0.4475, Accuracy: 26.57%\n",
      "val Loss: 0.3806 Acc: 0.8421\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/640], Loss: 0.4153, Accuracy: 26.14%\n",
      "Epoch [28/100], Step [200/640], Loss: 0.3561, Accuracy: 27.00%\n",
      "Epoch [28/100], Step [300/640], Loss: 0.3247, Accuracy: 27.71%\n",
      "Epoch [28/100], Step [400/640], Loss: 0.3634, Accuracy: 27.00%\n",
      "Epoch [28/100], Step [500/640], Loss: 0.3746, Accuracy: 26.14%\n",
      "Epoch [28/100], Step [600/640], Loss: 0.3795, Accuracy: 26.57%\n",
      "train Loss: 0.3654 Acc: 0.8450\n",
      "Epoch [28/100], Step [100/640], Loss: 0.4264, Accuracy: 26.71%\n",
      "val Loss: 0.3775 Acc: 0.8450\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/640], Loss: 0.2594, Accuracy: 28.43%\n",
      "Epoch [29/100], Step [200/640], Loss: 0.3425, Accuracy: 27.86%\n",
      "Epoch [29/100], Step [300/640], Loss: 0.3956, Accuracy: 26.86%\n",
      "Epoch [29/100], Step [400/640], Loss: 0.3714, Accuracy: 26.57%\n",
      "Epoch [29/100], Step [500/640], Loss: 0.3817, Accuracy: 27.14%\n",
      "Epoch [29/100], Step [600/640], Loss: 0.4114, Accuracy: 26.43%\n",
      "train Loss: 0.3639 Acc: 0.8455\n",
      "Epoch [29/100], Step [100/640], Loss: 0.4593, Accuracy: 26.14%\n",
      "val Loss: 0.3754 Acc: 0.8432\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/640], Loss: 0.3817, Accuracy: 27.14%\n",
      "Epoch [30/100], Step [200/640], Loss: 0.4365, Accuracy: 26.14%\n",
      "Epoch [30/100], Step [300/640], Loss: 0.3322, Accuracy: 27.00%\n",
      "Epoch [30/100], Step [400/640], Loss: 0.3651, Accuracy: 26.86%\n",
      "Epoch [30/100], Step [500/640], Loss: 0.4119, Accuracy: 27.00%\n",
      "Epoch [30/100], Step [600/640], Loss: 0.3893, Accuracy: 26.86%\n",
      "train Loss: 0.3602 Acc: 0.8473\n",
      "Epoch [30/100], Step [100/640], Loss: 0.4256, Accuracy: 26.57%\n",
      "val Loss: 0.3737 Acc: 0.8446\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/640], Loss: 0.3316, Accuracy: 27.71%\n",
      "Epoch [31/100], Step [200/640], Loss: 0.3640, Accuracy: 26.14%\n",
      "Epoch [31/100], Step [300/640], Loss: 0.3220, Accuracy: 27.71%\n",
      "Epoch [31/100], Step [400/640], Loss: 0.3439, Accuracy: 26.86%\n",
      "Epoch [31/100], Step [500/640], Loss: 0.3856, Accuracy: 26.71%\n",
      "Epoch [31/100], Step [600/640], Loss: 0.4031, Accuracy: 26.71%\n",
      "train Loss: 0.3583 Acc: 0.8479\n",
      "Epoch [31/100], Step [100/640], Loss: 0.4211, Accuracy: 26.57%\n",
      "val Loss: 0.3743 Acc: 0.8470\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/640], Loss: 0.3757, Accuracy: 27.29%\n",
      "Epoch [32/100], Step [200/640], Loss: 0.3442, Accuracy: 26.86%\n",
      "Epoch [32/100], Step [300/640], Loss: 0.3320, Accuracy: 27.57%\n",
      "Epoch [32/100], Step [400/640], Loss: 0.3989, Accuracy: 26.86%\n",
      "Epoch [32/100], Step [500/640], Loss: 0.3417, Accuracy: 28.00%\n",
      "Epoch [32/100], Step [600/640], Loss: 0.4046, Accuracy: 26.14%\n",
      "train Loss: 0.3563 Acc: 0.8481\n",
      "Epoch [32/100], Step [100/640], Loss: 0.4075, Accuracy: 26.71%\n",
      "val Loss: 0.3741 Acc: 0.8455\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/640], Loss: 0.3815, Accuracy: 27.29%\n",
      "Epoch [33/100], Step [200/640], Loss: 0.3494, Accuracy: 26.14%\n",
      "Epoch [33/100], Step [300/640], Loss: 0.3707, Accuracy: 27.14%\n",
      "Epoch [33/100], Step [400/640], Loss: 0.3870, Accuracy: 27.14%\n",
      "Epoch [33/100], Step [500/640], Loss: 0.3715, Accuracy: 27.00%\n",
      "Epoch [33/100], Step [600/640], Loss: 0.3317, Accuracy: 28.00%\n",
      "train Loss: 0.3536 Acc: 0.8507\n",
      "Epoch [33/100], Step [100/640], Loss: 0.4293, Accuracy: 26.86%\n",
      "val Loss: 0.3728 Acc: 0.8477\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/640], Loss: 0.3136, Accuracy: 27.71%\n",
      "Epoch [34/100], Step [200/640], Loss: 0.2992, Accuracy: 28.29%\n",
      "Epoch [34/100], Step [300/640], Loss: 0.3176, Accuracy: 27.43%\n",
      "Epoch [34/100], Step [400/640], Loss: 0.3802, Accuracy: 27.00%\n",
      "Epoch [34/100], Step [500/640], Loss: 0.3204, Accuracy: 27.86%\n",
      "Epoch [34/100], Step [600/640], Loss: 0.3716, Accuracy: 26.71%\n",
      "train Loss: 0.3517 Acc: 0.8508\n",
      "Epoch [34/100], Step [100/640], Loss: 0.3900, Accuracy: 27.29%\n",
      "val Loss: 0.3784 Acc: 0.8478\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/640], Loss: 0.3572, Accuracy: 27.29%\n",
      "Epoch [35/100], Step [200/640], Loss: 0.3739, Accuracy: 27.57%\n",
      "Epoch [35/100], Step [300/640], Loss: 0.3111, Accuracy: 28.43%\n",
      "Epoch [35/100], Step [400/640], Loss: 0.3936, Accuracy: 26.57%\n",
      "Epoch [35/100], Step [500/640], Loss: 0.3298, Accuracy: 27.14%\n",
      "Epoch [35/100], Step [600/640], Loss: 0.3962, Accuracy: 25.71%\n",
      "train Loss: 0.3482 Acc: 0.8519\n",
      "Epoch [35/100], Step [100/640], Loss: 0.4258, Accuracy: 26.43%\n",
      "val Loss: 0.3921 Acc: 0.8415\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/640], Loss: 0.3959, Accuracy: 26.71%\n",
      "Epoch [36/100], Step [200/640], Loss: 0.4155, Accuracy: 26.86%\n",
      "Epoch [36/100], Step [300/640], Loss: 0.3111, Accuracy: 27.86%\n",
      "Epoch [36/100], Step [400/640], Loss: 0.3919, Accuracy: 26.57%\n",
      "Epoch [36/100], Step [500/640], Loss: 0.2925, Accuracy: 27.29%\n",
      "Epoch [36/100], Step [600/640], Loss: 0.4368, Accuracy: 26.57%\n",
      "train Loss: 0.3446 Acc: 0.8540\n",
      "Epoch [36/100], Step [100/640], Loss: 0.4337, Accuracy: 27.14%\n",
      "val Loss: 0.3853 Acc: 0.8429\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/640], Loss: 0.3117, Accuracy: 28.00%\n",
      "Epoch [37/100], Step [200/640], Loss: 0.4209, Accuracy: 26.00%\n",
      "Epoch [37/100], Step [300/640], Loss: 0.2785, Accuracy: 28.00%\n",
      "Epoch [37/100], Step [400/640], Loss: 0.3297, Accuracy: 27.86%\n",
      "Epoch [37/100], Step [500/640], Loss: 0.4405, Accuracy: 25.57%\n",
      "Epoch [37/100], Step [600/640], Loss: 0.4229, Accuracy: 27.14%\n",
      "train Loss: 0.3420 Acc: 0.8556\n",
      "Epoch [37/100], Step [100/640], Loss: 0.4116, Accuracy: 26.71%\n",
      "val Loss: 0.3775 Acc: 0.8449\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/640], Loss: 0.2997, Accuracy: 27.57%\n",
      "Epoch [38/100], Step [200/640], Loss: 0.2627, Accuracy: 28.43%\n",
      "Epoch [38/100], Step [300/640], Loss: 0.2912, Accuracy: 27.71%\n",
      "Epoch [38/100], Step [400/640], Loss: 0.3664, Accuracy: 26.43%\n",
      "Epoch [38/100], Step [500/640], Loss: 0.3656, Accuracy: 27.14%\n",
      "Epoch [38/100], Step [600/640], Loss: 0.2953, Accuracy: 28.14%\n",
      "train Loss: 0.3391 Acc: 0.8563\n",
      "Epoch [38/100], Step [100/640], Loss: 0.4444, Accuracy: 26.14%\n",
      "val Loss: 0.3866 Acc: 0.8435\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/640], Loss: 0.3028, Accuracy: 26.71%\n",
      "Epoch [39/100], Step [200/640], Loss: 0.2710, Accuracy: 28.71%\n",
      "Epoch [39/100], Step [300/640], Loss: 0.3236, Accuracy: 28.00%\n",
      "Epoch [39/100], Step [400/640], Loss: 0.3036, Accuracy: 27.57%\n",
      "Epoch [39/100], Step [500/640], Loss: 0.3460, Accuracy: 26.86%\n",
      "Epoch [39/100], Step [600/640], Loss: 0.3762, Accuracy: 26.71%\n",
      "train Loss: 0.3371 Acc: 0.8571\n",
      "Epoch [39/100], Step [100/640], Loss: 0.4270, Accuracy: 26.86%\n",
      "val Loss: 0.3827 Acc: 0.8446\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/640], Loss: 0.3264, Accuracy: 27.29%\n",
      "Epoch [40/100], Step [200/640], Loss: 0.3335, Accuracy: 27.71%\n",
      "Epoch [40/100], Step [300/640], Loss: 0.3773, Accuracy: 27.57%\n",
      "Epoch [40/100], Step [400/640], Loss: 0.3313, Accuracy: 27.57%\n",
      "Epoch [40/100], Step [500/640], Loss: 0.3263, Accuracy: 27.43%\n",
      "Epoch [40/100], Step [600/640], Loss: 0.3645, Accuracy: 27.00%\n",
      "train Loss: 0.3342 Acc: 0.8580\n",
      "Epoch [40/100], Step [100/640], Loss: 0.4932, Accuracy: 26.14%\n",
      "val Loss: 0.3896 Acc: 0.8466\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/640], Loss: 0.3707, Accuracy: 26.86%\n",
      "Epoch [41/100], Step [200/640], Loss: 0.3213, Accuracy: 26.86%\n",
      "Epoch [41/100], Step [300/640], Loss: 0.2573, Accuracy: 28.43%\n",
      "Epoch [41/100], Step [400/640], Loss: 0.3353, Accuracy: 28.00%\n",
      "Epoch [41/100], Step [500/640], Loss: 0.3325, Accuracy: 28.29%\n",
      "Epoch [41/100], Step [600/640], Loss: 0.3632, Accuracy: 26.86%\n",
      "train Loss: 0.3306 Acc: 0.8599\n",
      "Epoch [41/100], Step [100/640], Loss: 0.4058, Accuracy: 26.86%\n",
      "val Loss: 0.3826 Acc: 0.8467\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/640], Loss: 0.3580, Accuracy: 27.00%\n",
      "Epoch [42/100], Step [200/640], Loss: 0.2953, Accuracy: 28.00%\n",
      "Epoch [42/100], Step [300/640], Loss: 0.3490, Accuracy: 28.14%\n",
      "Epoch [42/100], Step [400/640], Loss: 0.2663, Accuracy: 28.00%\n",
      "Epoch [42/100], Step [500/640], Loss: 0.3603, Accuracy: 27.57%\n",
      "Epoch [42/100], Step [600/640], Loss: 0.4230, Accuracy: 26.71%\n",
      "train Loss: 0.3267 Acc: 0.8611\n",
      "Epoch [42/100], Step [100/640], Loss: 0.4577, Accuracy: 26.43%\n",
      "val Loss: 0.3931 Acc: 0.8435\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/640], Loss: 0.3233, Accuracy: 28.29%\n",
      "Epoch [43/100], Step [200/640], Loss: 0.2726, Accuracy: 28.29%\n",
      "Epoch [43/100], Step [300/640], Loss: 0.3898, Accuracy: 26.71%\n",
      "Epoch [43/100], Step [400/640], Loss: 0.3417, Accuracy: 27.00%\n",
      "Epoch [43/100], Step [500/640], Loss: 0.2704, Accuracy: 28.14%\n",
      "Epoch [43/100], Step [600/640], Loss: 0.3838, Accuracy: 27.00%\n",
      "train Loss: 0.3236 Acc: 0.8636\n",
      "Epoch [43/100], Step [100/640], Loss: 0.4095, Accuracy: 26.86%\n",
      "val Loss: 0.3997 Acc: 0.8454\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/640], Loss: 0.2670, Accuracy: 28.14%\n",
      "Epoch [44/100], Step [200/640], Loss: 0.3217, Accuracy: 27.57%\n",
      "Epoch [44/100], Step [300/640], Loss: 0.3525, Accuracy: 27.14%\n",
      "Epoch [44/100], Step [400/640], Loss: 0.3064, Accuracy: 28.00%\n",
      "Epoch [44/100], Step [500/640], Loss: 0.3394, Accuracy: 27.29%\n",
      "Epoch [44/100], Step [600/640], Loss: 0.3310, Accuracy: 28.14%\n",
      "train Loss: 0.3204 Acc: 0.8639\n",
      "Epoch [44/100], Step [100/640], Loss: 0.4536, Accuracy: 27.29%\n",
      "val Loss: 0.3961 Acc: 0.8457\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/640], Loss: 0.3204, Accuracy: 26.71%\n",
      "Epoch [45/100], Step [200/640], Loss: 0.2494, Accuracy: 28.71%\n",
      "Epoch [45/100], Step [300/640], Loss: 0.2502, Accuracy: 28.71%\n",
      "Epoch [45/100], Step [400/640], Loss: 0.2695, Accuracy: 28.43%\n",
      "Epoch [45/100], Step [500/640], Loss: 0.3494, Accuracy: 27.29%\n",
      "Epoch [45/100], Step [600/640], Loss: 0.3393, Accuracy: 27.43%\n",
      "train Loss: 0.3166 Acc: 0.8661\n",
      "Epoch [45/100], Step [100/640], Loss: 0.4433, Accuracy: 26.00%\n",
      "val Loss: 0.3950 Acc: 0.8455\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/640], Loss: 0.2898, Accuracy: 28.00%\n",
      "Epoch [46/100], Step [200/640], Loss: 0.3455, Accuracy: 27.43%\n",
      "Epoch [46/100], Step [300/640], Loss: 0.3020, Accuracy: 27.86%\n",
      "Epoch [46/100], Step [400/640], Loss: 0.3705, Accuracy: 26.71%\n",
      "Epoch [46/100], Step [500/640], Loss: 0.3440, Accuracy: 26.57%\n",
      "Epoch [46/100], Step [600/640], Loss: 0.3500, Accuracy: 27.29%\n",
      "train Loss: 0.3129 Acc: 0.8672\n",
      "Epoch [46/100], Step [100/640], Loss: 0.4431, Accuracy: 27.00%\n",
      "val Loss: 0.3987 Acc: 0.8451\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/640], Loss: 0.3738, Accuracy: 26.71%\n",
      "Epoch [47/100], Step [200/640], Loss: 0.3044, Accuracy: 28.00%\n",
      "Epoch [47/100], Step [300/640], Loss: 0.2459, Accuracy: 28.29%\n",
      "Epoch [47/100], Step [400/640], Loss: 0.3093, Accuracy: 27.86%\n",
      "Epoch [47/100], Step [500/640], Loss: 0.2585, Accuracy: 28.57%\n",
      "Epoch [47/100], Step [600/640], Loss: 0.3407, Accuracy: 27.29%\n",
      "train Loss: 0.3105 Acc: 0.8683\n",
      "Epoch [47/100], Step [100/640], Loss: 0.4351, Accuracy: 26.43%\n",
      "val Loss: 0.4059 Acc: 0.8449\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/640], Loss: 0.2569, Accuracy: 28.00%\n",
      "Epoch [48/100], Step [200/640], Loss: 0.2834, Accuracy: 27.43%\n",
      "Epoch [48/100], Step [300/640], Loss: 0.3003, Accuracy: 28.29%\n",
      "Epoch [48/100], Step [400/640], Loss: 0.2547, Accuracy: 29.14%\n",
      "Epoch [48/100], Step [500/640], Loss: 0.3594, Accuracy: 27.29%\n",
      "Epoch [48/100], Step [600/640], Loss: 0.3382, Accuracy: 28.14%\n",
      "train Loss: 0.3048 Acc: 0.8701\n",
      "Epoch [48/100], Step [100/640], Loss: 0.4260, Accuracy: 26.57%\n",
      "val Loss: 0.4043 Acc: 0.8418\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/640], Loss: 0.4508, Accuracy: 26.29%\n",
      "Epoch [49/100], Step [200/640], Loss: 0.3865, Accuracy: 27.29%\n",
      "Epoch [49/100], Step [300/640], Loss: 0.3840, Accuracy: 27.29%\n",
      "Epoch [49/100], Step [400/640], Loss: 0.2329, Accuracy: 29.29%\n",
      "Epoch [49/100], Step [500/640], Loss: 0.2633, Accuracy: 28.43%\n",
      "Epoch [49/100], Step [600/640], Loss: 0.3332, Accuracy: 27.86%\n",
      "train Loss: 0.3026 Acc: 0.8713\n",
      "Epoch [49/100], Step [100/640], Loss: 0.4301, Accuracy: 27.00%\n",
      "val Loss: 0.4141 Acc: 0.8431\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/640], Loss: 0.2059, Accuracy: 29.14%\n",
      "Epoch [50/100], Step [200/640], Loss: 0.2349, Accuracy: 28.57%\n",
      "Epoch [50/100], Step [300/640], Loss: 0.2560, Accuracy: 28.14%\n",
      "Epoch [50/100], Step [400/640], Loss: 0.2719, Accuracy: 28.00%\n",
      "Epoch [50/100], Step [500/640], Loss: 0.3243, Accuracy: 27.43%\n",
      "Epoch [50/100], Step [600/640], Loss: 0.3210, Accuracy: 27.57%\n",
      "train Loss: 0.2988 Acc: 0.8739\n",
      "Epoch [50/100], Step [100/640], Loss: 0.3815, Accuracy: 27.43%\n",
      "val Loss: 0.4140 Acc: 0.8397\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/640], Loss: 0.3769, Accuracy: 27.29%\n",
      "Epoch [51/100], Step [200/640], Loss: 0.3121, Accuracy: 27.43%\n",
      "Epoch [51/100], Step [300/640], Loss: 0.3336, Accuracy: 27.57%\n",
      "Epoch [51/100], Step [400/640], Loss: 0.3376, Accuracy: 28.14%\n",
      "Epoch [51/100], Step [500/640], Loss: 0.3029, Accuracy: 28.00%\n",
      "Epoch [51/100], Step [600/640], Loss: 0.2668, Accuracy: 28.14%\n",
      "train Loss: 0.2950 Acc: 0.8752\n",
      "Epoch [51/100], Step [100/640], Loss: 0.5436, Accuracy: 26.00%\n",
      "val Loss: 0.4380 Acc: 0.8436\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/640], Loss: 0.2838, Accuracy: 28.29%\n",
      "Epoch [52/100], Step [200/640], Loss: 0.2521, Accuracy: 28.00%\n",
      "Epoch [52/100], Step [300/640], Loss: 0.3203, Accuracy: 28.14%\n",
      "Epoch [52/100], Step [400/640], Loss: 0.2676, Accuracy: 27.43%\n",
      "Epoch [52/100], Step [500/640], Loss: 0.3450, Accuracy: 26.71%\n",
      "Epoch [52/100], Step [600/640], Loss: 0.3590, Accuracy: 27.29%\n",
      "train Loss: 0.2898 Acc: 0.8771\n",
      "Epoch [52/100], Step [100/640], Loss: 0.4689, Accuracy: 26.00%\n",
      "val Loss: 0.4251 Acc: 0.8420\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/640], Loss: 0.2399, Accuracy: 28.71%\n",
      "Epoch [53/100], Step [200/640], Loss: 0.2379, Accuracy: 29.00%\n",
      "Epoch [53/100], Step [300/640], Loss: 0.2364, Accuracy: 28.14%\n",
      "Epoch [53/100], Step [400/640], Loss: 0.2848, Accuracy: 28.29%\n",
      "Epoch [53/100], Step [500/640], Loss: 0.2844, Accuracy: 27.71%\n",
      "Epoch [53/100], Step [600/640], Loss: 0.2805, Accuracy: 28.29%\n",
      "train Loss: 0.2837 Acc: 0.8804\n",
      "Epoch [53/100], Step [100/640], Loss: 0.4942, Accuracy: 25.43%\n",
      "val Loss: 0.4379 Acc: 0.8429\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/640], Loss: 0.3571, Accuracy: 27.43%\n",
      "Epoch [54/100], Step [200/640], Loss: 0.2231, Accuracy: 28.86%\n",
      "Epoch [54/100], Step [300/640], Loss: 0.2778, Accuracy: 28.14%\n",
      "Epoch [54/100], Step [400/640], Loss: 0.2745, Accuracy: 28.43%\n",
      "Epoch [54/100], Step [500/640], Loss: 0.3475, Accuracy: 26.71%\n",
      "Epoch [54/100], Step [600/640], Loss: 0.2098, Accuracy: 28.71%\n",
      "train Loss: 0.2820 Acc: 0.8811\n",
      "Epoch [54/100], Step [100/640], Loss: 0.4869, Accuracy: 26.00%\n",
      "val Loss: 0.4306 Acc: 0.8425\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/640], Loss: 0.3020, Accuracy: 27.71%\n",
      "Epoch [55/100], Step [200/640], Loss: 0.2581, Accuracy: 28.14%\n",
      "Epoch [55/100], Step [300/640], Loss: 0.2795, Accuracy: 27.71%\n",
      "Epoch [55/100], Step [400/640], Loss: 0.3181, Accuracy: 27.43%\n",
      "Epoch [55/100], Step [500/640], Loss: 0.2658, Accuracy: 27.86%\n",
      "Epoch [55/100], Step [600/640], Loss: 0.2644, Accuracy: 27.71%\n",
      "train Loss: 0.2768 Acc: 0.8826\n",
      "Epoch [55/100], Step [100/640], Loss: 0.3957, Accuracy: 27.00%\n",
      "val Loss: 0.4267 Acc: 0.8406\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/640], Loss: 0.2712, Accuracy: 28.14%\n",
      "Epoch [56/100], Step [200/640], Loss: 0.2659, Accuracy: 28.29%\n",
      "Epoch [56/100], Step [300/640], Loss: 0.2375, Accuracy: 29.14%\n",
      "Epoch [56/100], Step [400/640], Loss: 0.4116, Accuracy: 26.57%\n",
      "Epoch [56/100], Step [500/640], Loss: 0.2735, Accuracy: 28.43%\n",
      "Epoch [56/100], Step [600/640], Loss: 0.2108, Accuracy: 28.57%\n",
      "train Loss: 0.2728 Acc: 0.8849\n",
      "Epoch [56/100], Step [100/640], Loss: 0.4911, Accuracy: 25.43%\n",
      "val Loss: 0.4703 Acc: 0.8407\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/640], Loss: 0.2056, Accuracy: 28.29%\n",
      "Epoch [57/100], Step [200/640], Loss: 0.2777, Accuracy: 28.43%\n",
      "Epoch [57/100], Step [300/640], Loss: 0.2377, Accuracy: 28.86%\n",
      "Epoch [57/100], Step [400/640], Loss: 0.3055, Accuracy: 28.29%\n",
      "Epoch [57/100], Step [500/640], Loss: 0.2811, Accuracy: 28.29%\n",
      "Epoch [57/100], Step [600/640], Loss: 0.2994, Accuracy: 28.00%\n",
      "train Loss: 0.2694 Acc: 0.8868\n",
      "Epoch [57/100], Step [100/640], Loss: 0.5007, Accuracy: 26.29%\n",
      "val Loss: 0.4467 Acc: 0.8420\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/640], Loss: 0.2755, Accuracy: 28.71%\n",
      "Epoch [58/100], Step [200/640], Loss: 0.2330, Accuracy: 28.00%\n",
      "Epoch [58/100], Step [300/640], Loss: 0.2270, Accuracy: 28.86%\n",
      "Epoch [58/100], Step [400/640], Loss: 0.2401, Accuracy: 28.14%\n",
      "Epoch [58/100], Step [500/640], Loss: 0.2297, Accuracy: 28.86%\n",
      "Epoch [58/100], Step [600/640], Loss: 0.2849, Accuracy: 27.57%\n",
      "train Loss: 0.2652 Acc: 0.8881\n",
      "Epoch [58/100], Step [100/640], Loss: 0.4582, Accuracy: 26.71%\n",
      "val Loss: 0.4420 Acc: 0.8403\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/640], Loss: 0.2561, Accuracy: 28.86%\n",
      "Epoch [59/100], Step [200/640], Loss: 0.2387, Accuracy: 29.00%\n",
      "Epoch [59/100], Step [300/640], Loss: 0.2283, Accuracy: 28.71%\n",
      "Epoch [59/100], Step [400/640], Loss: 0.2403, Accuracy: 28.57%\n",
      "Epoch [59/100], Step [500/640], Loss: 0.3075, Accuracy: 27.71%\n",
      "Epoch [59/100], Step [600/640], Loss: 0.2770, Accuracy: 28.57%\n",
      "train Loss: 0.2601 Acc: 0.8905\n",
      "Epoch [59/100], Step [100/640], Loss: 0.4751, Accuracy: 26.71%\n",
      "val Loss: 0.4484 Acc: 0.8380\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/640], Loss: 0.2864, Accuracy: 28.14%\n",
      "Epoch [60/100], Step [200/640], Loss: 0.2900, Accuracy: 28.29%\n",
      "Epoch [60/100], Step [300/640], Loss: 0.1841, Accuracy: 29.43%\n",
      "Epoch [60/100], Step [400/640], Loss: 0.2392, Accuracy: 28.43%\n",
      "Epoch [60/100], Step [500/640], Loss: 0.3228, Accuracy: 27.43%\n",
      "Epoch [60/100], Step [600/640], Loss: 0.1853, Accuracy: 29.43%\n",
      "train Loss: 0.2572 Acc: 0.8915\n",
      "Epoch [60/100], Step [100/640], Loss: 0.5210, Accuracy: 25.86%\n",
      "val Loss: 0.4658 Acc: 0.8369\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/640], Loss: 0.1829, Accuracy: 30.00%\n",
      "Epoch [61/100], Step [200/640], Loss: 0.1857, Accuracy: 28.71%\n",
      "Epoch [61/100], Step [300/640], Loss: 0.2762, Accuracy: 27.86%\n",
      "Epoch [61/100], Step [400/640], Loss: 0.2262, Accuracy: 28.57%\n",
      "Epoch [61/100], Step [500/640], Loss: 0.2490, Accuracy: 28.43%\n",
      "Epoch [61/100], Step [600/640], Loss: 0.2701, Accuracy: 28.57%\n",
      "train Loss: 0.2515 Acc: 0.8936\n",
      "Epoch [61/100], Step [100/640], Loss: 0.5127, Accuracy: 26.57%\n",
      "val Loss: 0.4791 Acc: 0.8396\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/640], Loss: 0.2352, Accuracy: 29.43%\n",
      "Epoch [62/100], Step [200/640], Loss: 0.2050, Accuracy: 29.29%\n",
      "Epoch [62/100], Step [300/640], Loss: 0.2254, Accuracy: 29.14%\n",
      "Epoch [62/100], Step [400/640], Loss: 0.2112, Accuracy: 28.43%\n",
      "Epoch [62/100], Step [500/640], Loss: 0.2407, Accuracy: 28.71%\n",
      "Epoch [62/100], Step [600/640], Loss: 0.2622, Accuracy: 28.71%\n",
      "train Loss: 0.2489 Acc: 0.8958\n",
      "Epoch [62/100], Step [100/640], Loss: 0.5266, Accuracy: 26.29%\n",
      "val Loss: 0.4681 Acc: 0.8379\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/640], Loss: 0.2629, Accuracy: 29.00%\n",
      "Epoch [63/100], Step [200/640], Loss: 0.2273, Accuracy: 29.57%\n",
      "Epoch [63/100], Step [300/640], Loss: 0.2550, Accuracy: 28.29%\n",
      "Epoch [63/100], Step [400/640], Loss: 0.3033, Accuracy: 28.14%\n",
      "Epoch [63/100], Step [500/640], Loss: 0.2477, Accuracy: 28.57%\n",
      "Epoch [63/100], Step [600/640], Loss: 0.2381, Accuracy: 28.57%\n",
      "train Loss: 0.2436 Acc: 0.8984\n",
      "Epoch [63/100], Step [100/640], Loss: 0.4828, Accuracy: 26.29%\n",
      "val Loss: 0.4800 Acc: 0.8389\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/640], Loss: 0.2766, Accuracy: 28.71%\n",
      "Epoch [64/100], Step [200/640], Loss: 0.2634, Accuracy: 28.29%\n",
      "Epoch [64/100], Step [300/640], Loss: 0.3065, Accuracy: 28.00%\n",
      "Epoch [64/100], Step [400/640], Loss: 0.2451, Accuracy: 29.14%\n",
      "Epoch [64/100], Step [500/640], Loss: 0.2224, Accuracy: 29.14%\n",
      "Epoch [64/100], Step [600/640], Loss: 0.1272, Accuracy: 30.43%\n",
      "train Loss: 0.2394 Acc: 0.8990\n",
      "Epoch [64/100], Step [100/640], Loss: 0.5280, Accuracy: 26.43%\n",
      "val Loss: 0.4943 Acc: 0.8365\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/640], Loss: 0.2663, Accuracy: 28.43%\n",
      "Epoch [65/100], Step [200/640], Loss: 0.2418, Accuracy: 28.86%\n",
      "Epoch [65/100], Step [300/640], Loss: 0.3056, Accuracy: 27.71%\n",
      "Epoch [65/100], Step [400/640], Loss: 0.1803, Accuracy: 29.71%\n",
      "Epoch [65/100], Step [500/640], Loss: 0.2035, Accuracy: 29.14%\n",
      "Epoch [65/100], Step [600/640], Loss: 0.2266, Accuracy: 28.29%\n",
      "train Loss: 0.2344 Acc: 0.9016\n",
      "Epoch [65/100], Step [100/640], Loss: 0.6308, Accuracy: 25.86%\n",
      "val Loss: 0.5098 Acc: 0.8347\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/640], Loss: 0.2396, Accuracy: 28.43%\n",
      "Epoch [66/100], Step [200/640], Loss: 0.2801, Accuracy: 28.71%\n",
      "Epoch [66/100], Step [300/640], Loss: 0.2903, Accuracy: 28.00%\n",
      "Epoch [66/100], Step [400/640], Loss: 0.3453, Accuracy: 28.00%\n",
      "Epoch [66/100], Step [500/640], Loss: 0.2404, Accuracy: 28.71%\n",
      "Epoch [66/100], Step [600/640], Loss: 0.1983, Accuracy: 28.86%\n",
      "train Loss: 0.2311 Acc: 0.9031\n",
      "Epoch [66/100], Step [100/640], Loss: 0.5588, Accuracy: 26.29%\n",
      "val Loss: 0.5169 Acc: 0.8369\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/640], Loss: 0.1942, Accuracy: 28.86%\n",
      "Epoch [67/100], Step [200/640], Loss: 0.2443, Accuracy: 28.86%\n",
      "Epoch [67/100], Step [300/640], Loss: 0.2182, Accuracy: 29.00%\n",
      "Epoch [67/100], Step [400/640], Loss: 0.2116, Accuracy: 29.57%\n",
      "Epoch [67/100], Step [500/640], Loss: 0.2150, Accuracy: 28.57%\n",
      "Epoch [67/100], Step [600/640], Loss: 0.2745, Accuracy: 28.71%\n",
      "train Loss: 0.2265 Acc: 0.9056\n",
      "Epoch [67/100], Step [100/640], Loss: 0.5538, Accuracy: 26.43%\n",
      "val Loss: 0.5165 Acc: 0.8346\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/640], Loss: 0.1804, Accuracy: 29.71%\n",
      "Epoch [68/100], Step [200/640], Loss: 0.2216, Accuracy: 29.29%\n",
      "Epoch [68/100], Step [300/640], Loss: 0.2430, Accuracy: 28.57%\n",
      "Epoch [68/100], Step [400/640], Loss: 0.1860, Accuracy: 29.14%\n",
      "Epoch [68/100], Step [500/640], Loss: 0.2447, Accuracy: 28.86%\n",
      "Epoch [68/100], Step [600/640], Loss: 0.2179, Accuracy: 29.14%\n",
      "train Loss: 0.2234 Acc: 0.9069\n",
      "Epoch [68/100], Step [100/640], Loss: 0.5686, Accuracy: 26.00%\n",
      "val Loss: 0.5182 Acc: 0.8331\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/640], Loss: 0.2557, Accuracy: 28.86%\n",
      "Epoch [69/100], Step [200/640], Loss: 0.2260, Accuracy: 28.86%\n",
      "Epoch [69/100], Step [300/640], Loss: 0.2138, Accuracy: 30.00%\n",
      "Epoch [69/100], Step [400/640], Loss: 0.2911, Accuracy: 27.57%\n",
      "Epoch [69/100], Step [500/640], Loss: 0.2422, Accuracy: 29.14%\n",
      "Epoch [69/100], Step [600/640], Loss: 0.1953, Accuracy: 28.71%\n",
      "train Loss: 0.2175 Acc: 0.9093\n",
      "Epoch [69/100], Step [100/640], Loss: 0.5877, Accuracy: 26.14%\n",
      "val Loss: 0.5356 Acc: 0.8305\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/640], Loss: 0.1872, Accuracy: 29.86%\n",
      "Epoch [70/100], Step [200/640], Loss: 0.2759, Accuracy: 28.29%\n",
      "Epoch [70/100], Step [300/640], Loss: 0.2647, Accuracy: 28.57%\n",
      "Epoch [70/100], Step [400/640], Loss: 0.1757, Accuracy: 30.00%\n",
      "Epoch [70/100], Step [500/640], Loss: 0.2043, Accuracy: 29.29%\n",
      "Epoch [70/100], Step [600/640], Loss: 0.2133, Accuracy: 29.14%\n",
      "train Loss: 0.2141 Acc: 0.9111\n",
      "Epoch [70/100], Step [100/640], Loss: 0.5555, Accuracy: 25.43%\n",
      "val Loss: 0.5354 Acc: 0.8328\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/640], Loss: 0.1301, Accuracy: 30.71%\n",
      "Epoch [71/100], Step [200/640], Loss: 0.2225, Accuracy: 28.86%\n",
      "Epoch [71/100], Step [300/640], Loss: 0.2136, Accuracy: 29.29%\n",
      "Epoch [71/100], Step [400/640], Loss: 0.1673, Accuracy: 30.00%\n",
      "Epoch [71/100], Step [500/640], Loss: 0.2148, Accuracy: 29.14%\n",
      "Epoch [71/100], Step [600/640], Loss: 0.2367, Accuracy: 28.29%\n",
      "train Loss: 0.2105 Acc: 0.9130\n",
      "Epoch [71/100], Step [100/640], Loss: 0.5819, Accuracy: 26.29%\n",
      "val Loss: 0.5457 Acc: 0.8308\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/640], Loss: 0.1751, Accuracy: 29.43%\n",
      "Epoch [72/100], Step [200/640], Loss: 0.2559, Accuracy: 29.57%\n",
      "Epoch [72/100], Step [300/640], Loss: 0.1906, Accuracy: 29.29%\n",
      "Epoch [72/100], Step [400/640], Loss: 0.2084, Accuracy: 29.43%\n",
      "Epoch [72/100], Step [500/640], Loss: 0.2028, Accuracy: 29.57%\n",
      "Epoch [72/100], Step [600/640], Loss: 0.1581, Accuracy: 30.00%\n",
      "train Loss: 0.2078 Acc: 0.9142\n",
      "Epoch [72/100], Step [100/640], Loss: 0.6320, Accuracy: 26.00%\n",
      "val Loss: 0.5673 Acc: 0.8305\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/640], Loss: 0.1515, Accuracy: 30.29%\n",
      "Epoch [73/100], Step [200/640], Loss: 0.2080, Accuracy: 29.14%\n",
      "Epoch [73/100], Step [300/640], Loss: 0.1984, Accuracy: 29.00%\n",
      "Epoch [73/100], Step [400/640], Loss: 0.1478, Accuracy: 30.00%\n",
      "Epoch [73/100], Step [500/640], Loss: 0.2551, Accuracy: 29.14%\n",
      "Epoch [73/100], Step [600/640], Loss: 0.2264, Accuracy: 28.86%\n",
      "train Loss: 0.2049 Acc: 0.9145\n",
      "Epoch [73/100], Step [100/640], Loss: 0.5679, Accuracy: 26.29%\n",
      "val Loss: 0.5517 Acc: 0.8306\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/640], Loss: 0.1956, Accuracy: 29.43%\n",
      "Epoch [74/100], Step [200/640], Loss: 0.1142, Accuracy: 30.43%\n",
      "Epoch [74/100], Step [300/640], Loss: 0.2113, Accuracy: 29.43%\n",
      "Epoch [74/100], Step [400/640], Loss: 0.2826, Accuracy: 28.43%\n",
      "Epoch [74/100], Step [500/640], Loss: 0.1455, Accuracy: 29.86%\n",
      "Epoch [74/100], Step [600/640], Loss: 0.1906, Accuracy: 29.57%\n",
      "train Loss: 0.1995 Acc: 0.9171\n",
      "Epoch [74/100], Step [100/640], Loss: 0.6435, Accuracy: 25.43%\n",
      "val Loss: 0.5790 Acc: 0.8287\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/640], Loss: 0.1634, Accuracy: 29.29%\n",
      "Epoch [75/100], Step [200/640], Loss: 0.1787, Accuracy: 29.29%\n",
      "Epoch [75/100], Step [300/640], Loss: 0.1737, Accuracy: 29.57%\n",
      "Epoch [75/100], Step [400/640], Loss: 0.2787, Accuracy: 28.00%\n",
      "Epoch [75/100], Step [500/640], Loss: 0.1654, Accuracy: 29.86%\n",
      "Epoch [75/100], Step [600/640], Loss: 0.1790, Accuracy: 29.00%\n",
      "train Loss: 0.1951 Acc: 0.9194\n",
      "Epoch [75/100], Step [100/640], Loss: 0.5259, Accuracy: 25.71%\n",
      "val Loss: 0.5618 Acc: 0.8277\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/640], Loss: 0.1696, Accuracy: 29.57%\n",
      "Epoch [76/100], Step [200/640], Loss: 0.2294, Accuracy: 28.71%\n",
      "Epoch [76/100], Step [300/640], Loss: 0.1435, Accuracy: 30.29%\n",
      "Epoch [76/100], Step [400/640], Loss: 0.1819, Accuracy: 29.86%\n",
      "Epoch [76/100], Step [500/640], Loss: 0.2450, Accuracy: 29.00%\n",
      "Epoch [76/100], Step [600/640], Loss: 0.1594, Accuracy: 29.57%\n",
      "train Loss: 0.1908 Acc: 0.9210\n",
      "Epoch [76/100], Step [100/640], Loss: 0.6356, Accuracy: 25.57%\n",
      "val Loss: 0.5890 Acc: 0.8286\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/640], Loss: 0.1478, Accuracy: 29.86%\n",
      "Epoch [77/100], Step [200/640], Loss: 0.1748, Accuracy: 30.29%\n",
      "Epoch [77/100], Step [300/640], Loss: 0.1804, Accuracy: 30.14%\n",
      "Epoch [77/100], Step [400/640], Loss: 0.2321, Accuracy: 28.86%\n",
      "Epoch [77/100], Step [500/640], Loss: 0.2218, Accuracy: 29.14%\n",
      "Epoch [77/100], Step [600/640], Loss: 0.1627, Accuracy: 29.57%\n",
      "train Loss: 0.1888 Acc: 0.9218\n",
      "Epoch [77/100], Step [100/640], Loss: 0.6489, Accuracy: 26.00%\n",
      "val Loss: 0.5893 Acc: 0.8281\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/640], Loss: 0.1599, Accuracy: 29.86%\n",
      "Epoch [78/100], Step [200/640], Loss: 0.2099, Accuracy: 29.29%\n",
      "Epoch [78/100], Step [300/640], Loss: 0.1359, Accuracy: 30.43%\n",
      "Epoch [78/100], Step [400/640], Loss: 0.1292, Accuracy: 30.43%\n",
      "Epoch [78/100], Step [500/640], Loss: 0.1994, Accuracy: 29.14%\n",
      "Epoch [78/100], Step [600/640], Loss: 0.1923, Accuracy: 29.43%\n",
      "train Loss: 0.1841 Acc: 0.9240\n",
      "Epoch [78/100], Step [100/640], Loss: 0.6597, Accuracy: 26.14%\n",
      "val Loss: 0.6207 Acc: 0.8253\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/640], Loss: 0.1400, Accuracy: 29.57%\n",
      "Epoch [79/100], Step [200/640], Loss: 0.1788, Accuracy: 29.57%\n",
      "Epoch [79/100], Step [300/640], Loss: 0.3135, Accuracy: 28.71%\n",
      "Epoch [79/100], Step [400/640], Loss: 0.2016, Accuracy: 29.71%\n",
      "Epoch [79/100], Step [500/640], Loss: 0.1788, Accuracy: 29.43%\n",
      "Epoch [79/100], Step [600/640], Loss: 0.1310, Accuracy: 30.00%\n",
      "train Loss: 0.1813 Acc: 0.9256\n",
      "Epoch [79/100], Step [100/640], Loss: 0.6840, Accuracy: 25.71%\n",
      "val Loss: 0.6058 Acc: 0.8289\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/640], Loss: 0.1985, Accuracy: 28.71%\n",
      "Epoch [80/100], Step [200/640], Loss: 0.2197, Accuracy: 29.43%\n",
      "Epoch [80/100], Step [300/640], Loss: 0.1302, Accuracy: 30.57%\n",
      "Epoch [80/100], Step [400/640], Loss: 0.1598, Accuracy: 29.71%\n",
      "Epoch [80/100], Step [500/640], Loss: 0.2882, Accuracy: 28.00%\n",
      "Epoch [80/100], Step [600/640], Loss: 0.1370, Accuracy: 29.57%\n",
      "train Loss: 0.1796 Acc: 0.9262\n",
      "Epoch [80/100], Step [100/640], Loss: 0.6368, Accuracy: 25.86%\n",
      "val Loss: 0.6133 Acc: 0.8278\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/640], Loss: 0.1306, Accuracy: 30.71%\n",
      "Epoch [81/100], Step [200/640], Loss: 0.2416, Accuracy: 29.00%\n",
      "Epoch [81/100], Step [300/640], Loss: 0.2130, Accuracy: 29.71%\n",
      "Epoch [81/100], Step [400/640], Loss: 0.2107, Accuracy: 29.86%\n",
      "Epoch [81/100], Step [500/640], Loss: 0.1795, Accuracy: 29.57%\n",
      "Epoch [81/100], Step [600/640], Loss: 0.1142, Accuracy: 30.57%\n",
      "train Loss: 0.1759 Acc: 0.9279\n",
      "Epoch [81/100], Step [100/640], Loss: 0.6274, Accuracy: 25.71%\n",
      "val Loss: 0.6151 Acc: 0.8246\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/640], Loss: 0.1111, Accuracy: 31.00%\n",
      "Epoch [82/100], Step [200/640], Loss: 0.1135, Accuracy: 30.86%\n",
      "Epoch [82/100], Step [300/640], Loss: 0.2234, Accuracy: 29.29%\n",
      "Epoch [82/100], Step [400/640], Loss: 0.1734, Accuracy: 29.57%\n",
      "Epoch [82/100], Step [500/640], Loss: 0.2320, Accuracy: 28.43%\n",
      "Epoch [82/100], Step [600/640], Loss: 0.1493, Accuracy: 30.43%\n",
      "train Loss: 0.1705 Acc: 0.9304\n",
      "Epoch [82/100], Step [100/640], Loss: 0.6065, Accuracy: 26.14%\n",
      "val Loss: 0.6349 Acc: 0.8229\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/640], Loss: 0.1752, Accuracy: 29.57%\n",
      "Epoch [83/100], Step [200/640], Loss: 0.3011, Accuracy: 28.86%\n",
      "Epoch [83/100], Step [300/640], Loss: 0.1392, Accuracy: 29.86%\n",
      "Epoch [83/100], Step [400/640], Loss: 0.2130, Accuracy: 29.57%\n",
      "Epoch [83/100], Step [500/640], Loss: 0.1315, Accuracy: 30.43%\n",
      "Epoch [83/100], Step [600/640], Loss: 0.1839, Accuracy: 29.71%\n",
      "train Loss: 0.1684 Acc: 0.9309\n",
      "Epoch [83/100], Step [100/640], Loss: 0.6665, Accuracy: 25.71%\n",
      "val Loss: 0.6480 Acc: 0.8244\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/640], Loss: 0.1980, Accuracy: 29.14%\n",
      "Epoch [84/100], Step [200/640], Loss: 0.1384, Accuracy: 30.00%\n",
      "Epoch [84/100], Step [300/640], Loss: 0.2005, Accuracy: 29.57%\n",
      "Epoch [84/100], Step [400/640], Loss: 0.1723, Accuracy: 29.71%\n",
      "Epoch [84/100], Step [500/640], Loss: 0.1619, Accuracy: 29.86%\n",
      "Epoch [84/100], Step [600/640], Loss: 0.1436, Accuracy: 30.14%\n",
      "train Loss: 0.1672 Acc: 0.9328\n",
      "Epoch [84/100], Step [100/640], Loss: 0.6513, Accuracy: 25.57%\n",
      "val Loss: 0.6467 Acc: 0.8200\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/640], Loss: 0.1972, Accuracy: 29.43%\n",
      "Epoch [85/100], Step [200/640], Loss: 0.2164, Accuracy: 29.29%\n",
      "Epoch [85/100], Step [300/640], Loss: 0.1557, Accuracy: 29.29%\n",
      "Epoch [85/100], Step [400/640], Loss: 0.1041, Accuracy: 30.43%\n",
      "Epoch [85/100], Step [500/640], Loss: 0.1418, Accuracy: 30.29%\n",
      "Epoch [85/100], Step [600/640], Loss: 0.1448, Accuracy: 30.00%\n",
      "train Loss: 0.1613 Acc: 0.9340\n",
      "Epoch [85/100], Step [100/640], Loss: 0.6533, Accuracy: 26.14%\n",
      "val Loss: 0.6570 Acc: 0.8231\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/640], Loss: 0.2088, Accuracy: 29.43%\n",
      "Epoch [86/100], Step [200/640], Loss: 0.1461, Accuracy: 29.86%\n",
      "Epoch [86/100], Step [300/640], Loss: 0.1565, Accuracy: 29.57%\n",
      "Epoch [86/100], Step [400/640], Loss: 0.1251, Accuracy: 30.14%\n",
      "Epoch [86/100], Step [500/640], Loss: 0.2351, Accuracy: 29.00%\n",
      "Epoch [86/100], Step [600/640], Loss: 0.1277, Accuracy: 30.43%\n",
      "train Loss: 0.1628 Acc: 0.9344\n",
      "Epoch [86/100], Step [100/640], Loss: 0.7167, Accuracy: 25.43%\n",
      "val Loss: 0.6787 Acc: 0.8240\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/640], Loss: 0.1275, Accuracy: 31.14%\n",
      "Epoch [87/100], Step [200/640], Loss: 0.1082, Accuracy: 30.71%\n",
      "Epoch [87/100], Step [300/640], Loss: 0.0958, Accuracy: 30.71%\n",
      "Epoch [87/100], Step [400/640], Loss: 0.1584, Accuracy: 30.14%\n",
      "Epoch [87/100], Step [500/640], Loss: 0.1641, Accuracy: 30.29%\n",
      "Epoch [87/100], Step [600/640], Loss: 0.1772, Accuracy: 30.00%\n",
      "train Loss: 0.1586 Acc: 0.9356\n",
      "Epoch [87/100], Step [100/640], Loss: 0.6635, Accuracy: 25.86%\n",
      "val Loss: 0.6589 Acc: 0.8259\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/640], Loss: 0.1189, Accuracy: 30.29%\n",
      "Epoch [88/100], Step [200/640], Loss: 0.1684, Accuracy: 29.86%\n",
      "Epoch [88/100], Step [300/640], Loss: 0.2303, Accuracy: 28.57%\n",
      "Epoch [88/100], Step [400/640], Loss: 0.1662, Accuracy: 30.14%\n",
      "Epoch [88/100], Step [500/640], Loss: 0.1361, Accuracy: 30.00%\n",
      "Epoch [88/100], Step [600/640], Loss: 0.2270, Accuracy: 29.43%\n",
      "train Loss: 0.1580 Acc: 0.9358\n",
      "Epoch [88/100], Step [100/640], Loss: 0.6603, Accuracy: 25.57%\n",
      "val Loss: 0.6550 Acc: 0.8228\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/640], Loss: 0.1274, Accuracy: 29.71%\n",
      "Epoch [89/100], Step [200/640], Loss: 0.1512, Accuracy: 29.86%\n",
      "Epoch [89/100], Step [300/640], Loss: 0.1432, Accuracy: 30.00%\n",
      "Epoch [89/100], Step [400/640], Loss: 0.1767, Accuracy: 29.57%\n",
      "Epoch [89/100], Step [500/640], Loss: 0.1389, Accuracy: 30.00%\n",
      "Epoch [89/100], Step [600/640], Loss: 0.2023, Accuracy: 29.86%\n",
      "train Loss: 0.1552 Acc: 0.9371\n",
      "Epoch [89/100], Step [100/640], Loss: 0.6729, Accuracy: 25.86%\n",
      "val Loss: 0.6658 Acc: 0.8234\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/640], Loss: 0.1140, Accuracy: 30.57%\n",
      "Epoch [90/100], Step [200/640], Loss: 0.1229, Accuracy: 30.71%\n",
      "Epoch [90/100], Step [300/640], Loss: 0.2665, Accuracy: 28.86%\n",
      "Epoch [90/100], Step [400/640], Loss: 0.1529, Accuracy: 30.29%\n",
      "Epoch [90/100], Step [500/640], Loss: 0.1116, Accuracy: 30.57%\n",
      "Epoch [90/100], Step [600/640], Loss: 0.1424, Accuracy: 30.43%\n",
      "train Loss: 0.1525 Acc: 0.9386\n",
      "Epoch [90/100], Step [100/640], Loss: 0.6432, Accuracy: 25.57%\n",
      "val Loss: 0.6720 Acc: 0.8226\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/640], Loss: 0.2099, Accuracy: 29.57%\n",
      "Epoch [91/100], Step [200/640], Loss: 0.1398, Accuracy: 30.43%\n",
      "Epoch [91/100], Step [300/640], Loss: 0.1694, Accuracy: 30.29%\n",
      "Epoch [91/100], Step [400/640], Loss: 0.1863, Accuracy: 29.57%\n",
      "Epoch [91/100], Step [500/640], Loss: 0.1486, Accuracy: 29.71%\n",
      "Epoch [91/100], Step [600/640], Loss: 0.1899, Accuracy: 29.29%\n",
      "train Loss: 0.1515 Acc: 0.9387\n",
      "Epoch [91/100], Step [100/640], Loss: 0.5994, Accuracy: 26.14%\n",
      "val Loss: 0.6721 Acc: 0.8215\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/640], Loss: 0.1479, Accuracy: 30.43%\n",
      "Epoch [92/100], Step [200/640], Loss: 0.1316, Accuracy: 30.71%\n",
      "Epoch [92/100], Step [300/640], Loss: 0.1830, Accuracy: 29.43%\n",
      "Epoch [92/100], Step [400/640], Loss: 0.1042, Accuracy: 30.86%\n",
      "Epoch [92/100], Step [500/640], Loss: 0.2331, Accuracy: 28.71%\n",
      "Epoch [92/100], Step [600/640], Loss: 0.0995, Accuracy: 30.86%\n",
      "train Loss: 0.1469 Acc: 0.9417\n",
      "Epoch [92/100], Step [100/640], Loss: 0.6905, Accuracy: 25.43%\n",
      "val Loss: 0.6756 Acc: 0.8208\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/640], Loss: 0.1310, Accuracy: 30.57%\n",
      "Epoch [93/100], Step [200/640], Loss: 0.1520, Accuracy: 30.29%\n",
      "Epoch [93/100], Step [300/640], Loss: 0.1022, Accuracy: 30.71%\n",
      "Epoch [93/100], Step [400/640], Loss: 0.1178, Accuracy: 30.29%\n",
      "Epoch [93/100], Step [500/640], Loss: 0.1285, Accuracy: 30.14%\n",
      "Epoch [93/100], Step [600/640], Loss: 0.1281, Accuracy: 30.43%\n",
      "train Loss: 0.1451 Acc: 0.9424\n",
      "Epoch [93/100], Step [100/640], Loss: 0.6858, Accuracy: 25.71%\n",
      "val Loss: 0.7001 Acc: 0.8201\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/640], Loss: 0.1260, Accuracy: 30.71%\n",
      "Epoch [94/100], Step [200/640], Loss: 0.1387, Accuracy: 30.43%\n",
      "Epoch [94/100], Step [300/640], Loss: 0.1771, Accuracy: 29.71%\n",
      "Epoch [94/100], Step [400/640], Loss: 0.1311, Accuracy: 29.86%\n",
      "Epoch [94/100], Step [500/640], Loss: 0.0910, Accuracy: 30.71%\n",
      "Epoch [94/100], Step [600/640], Loss: 0.0881, Accuracy: 30.71%\n",
      "train Loss: 0.1414 Acc: 0.9436\n",
      "Epoch [94/100], Step [100/640], Loss: 0.6898, Accuracy: 25.57%\n",
      "val Loss: 0.7006 Acc: 0.8195\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/640], Loss: 0.1697, Accuracy: 29.43%\n",
      "Epoch [95/100], Step [200/640], Loss: 0.0984, Accuracy: 30.57%\n",
      "Epoch [95/100], Step [300/640], Loss: 0.1086, Accuracy: 30.57%\n",
      "Epoch [95/100], Step [400/640], Loss: 0.1043, Accuracy: 30.86%\n",
      "Epoch [95/100], Step [500/640], Loss: 0.0894, Accuracy: 31.00%\n",
      "Epoch [95/100], Step [600/640], Loss: 0.1735, Accuracy: 29.14%\n",
      "train Loss: 0.1422 Acc: 0.9434\n",
      "Epoch [95/100], Step [100/640], Loss: 0.6463, Accuracy: 25.43%\n",
      "val Loss: 0.6939 Acc: 0.8193\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/640], Loss: 0.1372, Accuracy: 30.57%\n",
      "Epoch [96/100], Step [200/640], Loss: 0.1099, Accuracy: 30.71%\n",
      "Epoch [96/100], Step [300/640], Loss: 0.0835, Accuracy: 31.29%\n",
      "Epoch [96/100], Step [400/640], Loss: 0.0819, Accuracy: 30.86%\n",
      "Epoch [96/100], Step [500/640], Loss: 0.1667, Accuracy: 30.00%\n",
      "Epoch [96/100], Step [600/640], Loss: 0.1903, Accuracy: 29.71%\n",
      "train Loss: 0.1405 Acc: 0.9437\n",
      "Epoch [96/100], Step [100/640], Loss: 0.7741, Accuracy: 25.43%\n",
      "val Loss: 0.7184 Acc: 0.8211\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/640], Loss: 0.1831, Accuracy: 30.29%\n",
      "Epoch [97/100], Step [200/640], Loss: 0.0986, Accuracy: 30.71%\n",
      "Epoch [97/100], Step [300/640], Loss: 0.2245, Accuracy: 30.00%\n",
      "Epoch [97/100], Step [400/640], Loss: 0.1236, Accuracy: 30.00%\n",
      "Epoch [97/100], Step [500/640], Loss: 0.0582, Accuracy: 30.86%\n",
      "Epoch [97/100], Step [600/640], Loss: 0.2306, Accuracy: 28.71%\n",
      "train Loss: 0.1394 Acc: 0.9446\n",
      "Epoch [97/100], Step [100/640], Loss: 0.6922, Accuracy: 25.57%\n",
      "val Loss: 0.7145 Acc: 0.8178\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/640], Loss: 0.1032, Accuracy: 30.71%\n",
      "Epoch [98/100], Step [200/640], Loss: 0.1588, Accuracy: 30.14%\n",
      "Epoch [98/100], Step [300/640], Loss: 0.1052, Accuracy: 30.71%\n",
      "Epoch [98/100], Step [400/640], Loss: 0.1055, Accuracy: 30.43%\n",
      "Epoch [98/100], Step [500/640], Loss: 0.1289, Accuracy: 29.71%\n",
      "Epoch [98/100], Step [600/640], Loss: 0.1424, Accuracy: 30.57%\n",
      "train Loss: 0.1374 Acc: 0.9448\n",
      "Epoch [98/100], Step [100/640], Loss: 0.7245, Accuracy: 24.86%\n",
      "val Loss: 0.7289 Acc: 0.8168\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/640], Loss: 0.1011, Accuracy: 31.00%\n",
      "Epoch [99/100], Step [200/640], Loss: 0.1234, Accuracy: 31.00%\n",
      "Epoch [99/100], Step [300/640], Loss: 0.1341, Accuracy: 30.71%\n",
      "Epoch [99/100], Step [400/640], Loss: 0.1314, Accuracy: 30.14%\n",
      "Epoch [99/100], Step [500/640], Loss: 0.1556, Accuracy: 29.86%\n",
      "Epoch [99/100], Step [600/640], Loss: 0.0995, Accuracy: 30.71%\n",
      "train Loss: 0.1369 Acc: 0.9455\n",
      "Epoch [99/100], Step [100/640], Loss: 0.7531, Accuracy: 25.57%\n",
      "val Loss: 0.7311 Acc: 0.8224\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/640], Loss: 0.0999, Accuracy: 30.43%\n",
      "Epoch [100/100], Step [200/640], Loss: 0.1472, Accuracy: 30.00%\n",
      "Epoch [100/100], Step [300/640], Loss: 0.1274, Accuracy: 30.57%\n",
      "Epoch [100/100], Step [400/640], Loss: 0.1067, Accuracy: 30.29%\n",
      "Epoch [100/100], Step [500/640], Loss: 0.0941, Accuracy: 30.86%\n",
      "Epoch [100/100], Step [600/640], Loss: 0.1191, Accuracy: 30.29%\n",
      "train Loss: 0.1333 Acc: 0.9467\n",
      "Epoch [100/100], Step [100/640], Loss: 0.7570, Accuracy: 25.71%\n",
      "val Loss: 0.7429 Acc: 0.8186\n",
      "\n",
      "Training complete in 229m 40s\n",
      "Best val Acc: 0.847713\n",
      "Best loss: 0.372782\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'chest_xray_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.84513332892212\n",
      "f1: 0.2247612782557678\n",
      "cm: [[[3079  194]\n",
      "  [ 626  419]]\n",
      "\n",
      " [[3079  194]\n",
      "  [ 611  434]]\n",
      "\n",
      " [[3731   28]\n",
      "  [ 495   64]]\n",
      "\n",
      " [[3663    0]\n",
      "  [ 655    0]]\n",
      "\n",
      " [[3212   59]\n",
      "  [ 908  139]]\n",
      "\n",
      " [[3840   33]\n",
      "  [ 412   33]]\n",
      "\n",
      " [[3852    0]\n",
      "  [ 466    0]]]\n",
      "outputs: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "targets: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
