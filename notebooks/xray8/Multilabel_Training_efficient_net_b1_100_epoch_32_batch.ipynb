{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/xray8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"efficient_net_b1\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 7\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4955, 0.4955, 0.4955], [0.2892, 0.2892, 0.2892])\n",
    "\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([2., 3., 6., 6., 3., 7., 9.], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Effusion',\n",
       " 'No Finding',\n",
       " 'Mass',\n",
       " 'Nodule',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Consolidation']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/640], Loss: 1.0877, Accuracy: 25.14%\n",
      "Epoch [1/100], Step [200/640], Loss: 0.9958, Accuracy: 26.29%\n",
      "Epoch [1/100], Step [300/640], Loss: 1.1401, Accuracy: 25.57%\n",
      "Epoch [1/100], Step [400/640], Loss: 1.1978, Accuracy: 24.29%\n",
      "Epoch [1/100], Step [500/640], Loss: 1.0651, Accuracy: 25.29%\n",
      "Epoch [1/100], Step [600/640], Loss: 1.0809, Accuracy: 24.14%\n",
      "train Loss: 1.0979 Acc: 0.7887\n",
      "Epoch [1/100], Step [100/640], Loss: 1.2238, Accuracy: 21.57%\n",
      "val Loss: 1.1170 Acc: 0.7693\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/640], Loss: 1.3742, Accuracy: 23.86%\n",
      "Epoch [2/100], Step [200/640], Loss: 1.1014, Accuracy: 26.43%\n",
      "Epoch [2/100], Step [300/640], Loss: 1.1858, Accuracy: 25.00%\n",
      "Epoch [2/100], Step [400/640], Loss: 1.0149, Accuracy: 26.00%\n",
      "Epoch [2/100], Step [500/640], Loss: 1.0808, Accuracy: 25.57%\n",
      "Epoch [2/100], Step [600/640], Loss: 0.9726, Accuracy: 26.29%\n",
      "train Loss: 1.0563 Acc: 0.7909\n",
      "Epoch [2/100], Step [100/640], Loss: 1.2086, Accuracy: 24.29%\n",
      "val Loss: 1.0316 Acc: 0.7832\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/640], Loss: 1.0304, Accuracy: 25.00%\n",
      "Epoch [3/100], Step [200/640], Loss: 1.0968, Accuracy: 25.57%\n",
      "Epoch [3/100], Step [300/640], Loss: 1.0100, Accuracy: 26.00%\n",
      "Epoch [3/100], Step [400/640], Loss: 1.0273, Accuracy: 25.29%\n",
      "Epoch [3/100], Step [500/640], Loss: 1.0038, Accuracy: 23.86%\n",
      "Epoch [3/100], Step [600/640], Loss: 0.9532, Accuracy: 26.43%\n",
      "train Loss: 1.0452 Acc: 0.7908\n",
      "Epoch [3/100], Step [100/640], Loss: 1.2192, Accuracy: 23.00%\n",
      "val Loss: 1.0301 Acc: 0.7588\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/640], Loss: 1.1194, Accuracy: 25.43%\n",
      "Epoch [4/100], Step [200/640], Loss: 0.9922, Accuracy: 26.00%\n",
      "Epoch [4/100], Step [300/640], Loss: 1.0001, Accuracy: 25.57%\n",
      "Epoch [4/100], Step [400/640], Loss: 0.9819, Accuracy: 26.43%\n",
      "Epoch [4/100], Step [500/640], Loss: 0.9639, Accuracy: 24.29%\n",
      "Epoch [4/100], Step [600/640], Loss: 1.0400, Accuracy: 25.29%\n",
      "train Loss: 1.0392 Acc: 0.7840\n",
      "Epoch [4/100], Step [100/640], Loss: 1.3394, Accuracy: 23.29%\n",
      "val Loss: 1.0904 Acc: 0.7607\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/640], Loss: 1.1665, Accuracy: 23.29%\n",
      "Epoch [5/100], Step [200/640], Loss: 0.9815, Accuracy: 25.14%\n",
      "Epoch [5/100], Step [300/640], Loss: 0.8667, Accuracy: 27.57%\n",
      "Epoch [5/100], Step [400/640], Loss: 0.9858, Accuracy: 24.86%\n",
      "Epoch [5/100], Step [500/640], Loss: 1.0721, Accuracy: 24.57%\n",
      "Epoch [5/100], Step [600/640], Loss: 1.0256, Accuracy: 24.29%\n",
      "train Loss: 1.0261 Acc: 0.7804\n",
      "Epoch [5/100], Step [100/640], Loss: 1.0497, Accuracy: 25.00%\n",
      "val Loss: 1.0042 Acc: 0.7855\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/640], Loss: 0.9648, Accuracy: 25.71%\n",
      "Epoch [6/100], Step [200/640], Loss: 1.0004, Accuracy: 23.43%\n",
      "Epoch [6/100], Step [300/640], Loss: 1.0006, Accuracy: 25.43%\n",
      "Epoch [6/100], Step [400/640], Loss: 0.9795, Accuracy: 24.71%\n",
      "Epoch [6/100], Step [500/640], Loss: 1.0318, Accuracy: 26.71%\n",
      "Epoch [6/100], Step [600/640], Loss: 0.9603, Accuracy: 25.71%\n",
      "train Loss: 1.0197 Acc: 0.7759\n",
      "Epoch [6/100], Step [100/640], Loss: 1.1934, Accuracy: 23.14%\n",
      "val Loss: 1.0396 Acc: 0.7491\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/640], Loss: 0.8887, Accuracy: 24.86%\n",
      "Epoch [7/100], Step [200/640], Loss: 0.9828, Accuracy: 23.43%\n",
      "Epoch [7/100], Step [300/640], Loss: 1.0064, Accuracy: 26.29%\n",
      "Epoch [7/100], Step [400/640], Loss: 1.1593, Accuracy: 23.71%\n",
      "Epoch [7/100], Step [500/640], Loss: 1.0998, Accuracy: 23.57%\n",
      "Epoch [7/100], Step [600/640], Loss: 1.0362, Accuracy: 25.43%\n",
      "train Loss: 1.0137 Acc: 0.7757\n",
      "Epoch [7/100], Step [100/640], Loss: 1.1708, Accuracy: 22.71%\n",
      "val Loss: 1.0391 Acc: 0.7891\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/640], Loss: 1.2124, Accuracy: 23.71%\n",
      "Epoch [8/100], Step [200/640], Loss: 0.9820, Accuracy: 24.86%\n",
      "Epoch [8/100], Step [300/640], Loss: 0.8235, Accuracy: 26.86%\n",
      "Epoch [8/100], Step [400/640], Loss: 0.9910, Accuracy: 25.86%\n",
      "Epoch [8/100], Step [500/640], Loss: 1.0589, Accuracy: 23.00%\n",
      "Epoch [8/100], Step [600/640], Loss: 0.9602, Accuracy: 25.71%\n",
      "train Loss: 1.0106 Acc: 0.7768\n",
      "Epoch [8/100], Step [100/640], Loss: 1.3429, Accuracy: 17.14%\n",
      "val Loss: 1.2094 Acc: 0.6138\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/640], Loss: 0.9388, Accuracy: 25.86%\n",
      "Epoch [9/100], Step [200/640], Loss: 1.1677, Accuracy: 24.14%\n",
      "Epoch [9/100], Step [300/640], Loss: 0.9457, Accuracy: 24.29%\n",
      "Epoch [9/100], Step [400/640], Loss: 0.9904, Accuracy: 25.14%\n",
      "Epoch [9/100], Step [500/640], Loss: 0.9312, Accuracy: 25.43%\n",
      "Epoch [9/100], Step [600/640], Loss: 1.0235, Accuracy: 25.00%\n",
      "train Loss: 1.0034 Acc: 0.7743\n",
      "Epoch [9/100], Step [100/640], Loss: 1.1856, Accuracy: 22.00%\n",
      "val Loss: 0.9978 Acc: 0.7704\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/640], Loss: 0.9675, Accuracy: 23.57%\n",
      "Epoch [10/100], Step [200/640], Loss: 1.1010, Accuracy: 25.57%\n",
      "Epoch [10/100], Step [300/640], Loss: 0.9793, Accuracy: 26.14%\n",
      "Epoch [10/100], Step [400/640], Loss: 1.0953, Accuracy: 23.43%\n",
      "Epoch [10/100], Step [500/640], Loss: 1.0338, Accuracy: 24.43%\n",
      "Epoch [10/100], Step [600/640], Loss: 0.9647, Accuracy: 24.57%\n",
      "train Loss: 0.9971 Acc: 0.7768\n",
      "Epoch [10/100], Step [100/640], Loss: 1.1563, Accuracy: 23.71%\n",
      "val Loss: 1.0167 Acc: 0.7881\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/640], Loss: 1.0094, Accuracy: 25.29%\n",
      "Epoch [11/100], Step [200/640], Loss: 1.0614, Accuracy: 24.86%\n",
      "Epoch [11/100], Step [300/640], Loss: 1.0187, Accuracy: 24.29%\n",
      "Epoch [11/100], Step [400/640], Loss: 1.0104, Accuracy: 24.57%\n",
      "Epoch [11/100], Step [500/640], Loss: 0.9956, Accuracy: 24.57%\n",
      "Epoch [11/100], Step [600/640], Loss: 0.9236, Accuracy: 26.43%\n",
      "train Loss: 0.9938 Acc: 0.7776\n",
      "Epoch [11/100], Step [100/640], Loss: 1.2341, Accuracy: 21.86%\n",
      "val Loss: 1.0195 Acc: 0.7442\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/640], Loss: 1.0145, Accuracy: 26.00%\n",
      "Epoch [12/100], Step [200/640], Loss: 1.0019, Accuracy: 24.71%\n",
      "Epoch [12/100], Step [300/640], Loss: 0.9375, Accuracy: 24.00%\n",
      "Epoch [12/100], Step [400/640], Loss: 1.0667, Accuracy: 24.43%\n",
      "Epoch [12/100], Step [500/640], Loss: 0.9959, Accuracy: 23.86%\n",
      "Epoch [12/100], Step [600/640], Loss: 1.0490, Accuracy: 25.00%\n",
      "train Loss: 0.9933 Acc: 0.7770\n",
      "Epoch [12/100], Step [100/640], Loss: 1.0514, Accuracy: 23.14%\n",
      "val Loss: 0.9803 Acc: 0.7690\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/640], Loss: 1.0082, Accuracy: 24.57%\n",
      "Epoch [13/100], Step [200/640], Loss: 1.1119, Accuracy: 22.43%\n",
      "Epoch [13/100], Step [300/640], Loss: 1.0618, Accuracy: 24.71%\n",
      "Epoch [13/100], Step [400/640], Loss: 1.0853, Accuracy: 24.57%\n",
      "Epoch [13/100], Step [500/640], Loss: 0.9280, Accuracy: 25.57%\n",
      "Epoch [13/100], Step [600/640], Loss: 0.9504, Accuracy: 24.86%\n",
      "train Loss: 0.9828 Acc: 0.7773\n",
      "Epoch [13/100], Step [100/640], Loss: 1.1859, Accuracy: 23.43%\n",
      "val Loss: 0.9751 Acc: 0.7908\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/640], Loss: 0.9832, Accuracy: 24.57%\n",
      "Epoch [14/100], Step [200/640], Loss: 0.7867, Accuracy: 25.29%\n",
      "Epoch [14/100], Step [300/640], Loss: 0.9361, Accuracy: 24.57%\n",
      "Epoch [14/100], Step [400/640], Loss: 0.7335, Accuracy: 27.57%\n",
      "Epoch [14/100], Step [500/640], Loss: 0.9021, Accuracy: 26.14%\n",
      "Epoch [14/100], Step [600/640], Loss: 1.0940, Accuracy: 24.00%\n",
      "train Loss: 0.9788 Acc: 0.7759\n",
      "Epoch [14/100], Step [100/640], Loss: 1.1415, Accuracy: 22.86%\n",
      "val Loss: 0.9719 Acc: 0.7877\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/640], Loss: 0.8785, Accuracy: 24.86%\n",
      "Epoch [15/100], Step [200/640], Loss: 0.9988, Accuracy: 24.43%\n",
      "Epoch [15/100], Step [300/640], Loss: 1.0838, Accuracy: 24.43%\n",
      "Epoch [15/100], Step [400/640], Loss: 0.9457, Accuracy: 25.57%\n",
      "Epoch [15/100], Step [500/640], Loss: 0.9643, Accuracy: 26.86%\n",
      "Epoch [15/100], Step [600/640], Loss: 0.9041, Accuracy: 24.43%\n",
      "train Loss: 0.9686 Acc: 0.7779\n",
      "Epoch [15/100], Step [100/640], Loss: 1.0907, Accuracy: 22.71%\n",
      "val Loss: 0.9639 Acc: 0.7556\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/640], Loss: 0.9889, Accuracy: 24.57%\n",
      "Epoch [16/100], Step [200/640], Loss: 0.9959, Accuracy: 25.57%\n",
      "Epoch [16/100], Step [300/640], Loss: 0.8778, Accuracy: 24.29%\n",
      "Epoch [16/100], Step [400/640], Loss: 0.8808, Accuracy: 25.86%\n",
      "Epoch [16/100], Step [500/640], Loss: 0.8734, Accuracy: 24.29%\n",
      "Epoch [16/100], Step [600/640], Loss: 0.9214, Accuracy: 25.14%\n",
      "train Loss: 0.9627 Acc: 0.7777\n",
      "Epoch [16/100], Step [100/640], Loss: 1.0707, Accuracy: 23.86%\n",
      "val Loss: 0.9575 Acc: 0.7809\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/640], Loss: 1.1217, Accuracy: 23.57%\n",
      "Epoch [17/100], Step [200/640], Loss: 1.0255, Accuracy: 24.29%\n",
      "Epoch [17/100], Step [300/640], Loss: 0.9093, Accuracy: 25.57%\n",
      "Epoch [17/100], Step [400/640], Loss: 0.8963, Accuracy: 24.29%\n",
      "Epoch [17/100], Step [500/640], Loss: 0.9425, Accuracy: 25.43%\n",
      "Epoch [17/100], Step [600/640], Loss: 0.9653, Accuracy: 26.43%\n",
      "train Loss: 0.9561 Acc: 0.7807\n",
      "Epoch [17/100], Step [100/640], Loss: 1.0472, Accuracy: 22.43%\n",
      "val Loss: 0.9625 Acc: 0.7371\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/640], Loss: 0.9721, Accuracy: 24.86%\n",
      "Epoch [18/100], Step [200/640], Loss: 0.9063, Accuracy: 25.57%\n",
      "Epoch [18/100], Step [300/640], Loss: 0.8723, Accuracy: 24.14%\n",
      "Epoch [18/100], Step [400/640], Loss: 0.8848, Accuracy: 24.29%\n",
      "Epoch [18/100], Step [500/640], Loss: 1.0393, Accuracy: 23.29%\n",
      "Epoch [18/100], Step [600/640], Loss: 0.9202, Accuracy: 24.71%\n",
      "train Loss: 0.9495 Acc: 0.7794\n",
      "Epoch [18/100], Step [100/640], Loss: 1.1206, Accuracy: 22.86%\n",
      "val Loss: 0.9431 Acc: 0.7590\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/640], Loss: 0.9170, Accuracy: 25.86%\n",
      "Epoch [19/100], Step [200/640], Loss: 0.9113, Accuracy: 25.86%\n",
      "Epoch [19/100], Step [300/640], Loss: 0.8184, Accuracy: 27.00%\n",
      "Epoch [19/100], Step [400/640], Loss: 1.0937, Accuracy: 24.57%\n",
      "Epoch [19/100], Step [500/640], Loss: 0.9479, Accuracy: 24.29%\n",
      "Epoch [19/100], Step [600/640], Loss: 1.0329, Accuracy: 24.86%\n",
      "train Loss: 0.9460 Acc: 0.7803\n",
      "Epoch [19/100], Step [100/640], Loss: 1.1715, Accuracy: 22.71%\n",
      "val Loss: 1.0483 Acc: 0.7168\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/640], Loss: 0.9759, Accuracy: 24.29%\n",
      "Epoch [20/100], Step [200/640], Loss: 0.9395, Accuracy: 25.43%\n",
      "Epoch [20/100], Step [300/640], Loss: 0.9152, Accuracy: 25.29%\n",
      "Epoch [20/100], Step [400/640], Loss: 1.0288, Accuracy: 23.86%\n",
      "Epoch [20/100], Step [500/640], Loss: 1.1246, Accuracy: 22.71%\n",
      "Epoch [20/100], Step [600/640], Loss: 0.8935, Accuracy: 25.57%\n",
      "train Loss: 0.9410 Acc: 0.7810\n",
      "Epoch [20/100], Step [100/640], Loss: 1.1084, Accuracy: 24.86%\n",
      "val Loss: 0.9323 Acc: 0.7781\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/640], Loss: 0.9103, Accuracy: 25.71%\n",
      "Epoch [21/100], Step [200/640], Loss: 1.1095, Accuracy: 24.71%\n",
      "Epoch [21/100], Step [300/640], Loss: 0.9484, Accuracy: 26.43%\n",
      "Epoch [21/100], Step [400/640], Loss: 0.8178, Accuracy: 26.00%\n",
      "Epoch [21/100], Step [500/640], Loss: 0.9556, Accuracy: 25.29%\n",
      "Epoch [21/100], Step [600/640], Loss: 0.9152, Accuracy: 24.86%\n",
      "train Loss: 0.9336 Acc: 0.7865\n",
      "Epoch [21/100], Step [100/640], Loss: 1.0767, Accuracy: 23.43%\n",
      "val Loss: 0.9468 Acc: 0.7654\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/640], Loss: 0.7920, Accuracy: 28.14%\n",
      "Epoch [22/100], Step [200/640], Loss: 1.0088, Accuracy: 24.29%\n",
      "Epoch [22/100], Step [300/640], Loss: 0.8622, Accuracy: 25.86%\n",
      "Epoch [22/100], Step [400/640], Loss: 1.0366, Accuracy: 24.14%\n",
      "Epoch [22/100], Step [500/640], Loss: 0.9192, Accuracy: 25.29%\n",
      "Epoch [22/100], Step [600/640], Loss: 0.7311, Accuracy: 24.71%\n",
      "train Loss: 0.9263 Acc: 0.7864\n",
      "Epoch [22/100], Step [100/640], Loss: 1.0975, Accuracy: 24.14%\n",
      "val Loss: 0.9273 Acc: 0.7805\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/640], Loss: 0.8858, Accuracy: 25.00%\n",
      "Epoch [23/100], Step [200/640], Loss: 0.9712, Accuracy: 25.00%\n",
      "Epoch [23/100], Step [300/640], Loss: 0.9476, Accuracy: 25.29%\n",
      "Epoch [23/100], Step [400/640], Loss: 1.0753, Accuracy: 23.29%\n",
      "Epoch [23/100], Step [500/640], Loss: 0.8745, Accuracy: 26.43%\n",
      "Epoch [23/100], Step [600/640], Loss: 0.7434, Accuracy: 26.71%\n",
      "train Loss: 0.9228 Acc: 0.7888\n",
      "Epoch [23/100], Step [100/640], Loss: 1.1999, Accuracy: 23.29%\n",
      "val Loss: 0.9808 Acc: 0.7737\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/640], Loss: 0.9225, Accuracy: 25.57%\n",
      "Epoch [24/100], Step [200/640], Loss: 0.8152, Accuracy: 25.43%\n",
      "Epoch [24/100], Step [300/640], Loss: 1.1142, Accuracy: 24.14%\n",
      "Epoch [24/100], Step [400/640], Loss: 0.9057, Accuracy: 25.43%\n",
      "Epoch [24/100], Step [500/640], Loss: 0.8582, Accuracy: 26.14%\n",
      "Epoch [24/100], Step [600/640], Loss: 0.9133, Accuracy: 25.57%\n",
      "train Loss: 0.9203 Acc: 0.7876\n",
      "Epoch [24/100], Step [100/640], Loss: 0.9297, Accuracy: 25.29%\n",
      "val Loss: 0.9506 Acc: 0.7608\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/640], Loss: 0.7818, Accuracy: 26.00%\n",
      "Epoch [25/100], Step [200/640], Loss: 0.8208, Accuracy: 25.14%\n",
      "Epoch [25/100], Step [300/640], Loss: 0.8309, Accuracy: 26.29%\n",
      "Epoch [25/100], Step [400/640], Loss: 1.0588, Accuracy: 24.00%\n",
      "Epoch [25/100], Step [500/640], Loss: 0.9087, Accuracy: 26.86%\n",
      "Epoch [25/100], Step [600/640], Loss: 0.9197, Accuracy: 26.00%\n",
      "train Loss: 0.9134 Acc: 0.7898\n",
      "Epoch [25/100], Step [100/640], Loss: 1.0651, Accuracy: 24.57%\n",
      "val Loss: 0.9474 Acc: 0.7922\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/640], Loss: 1.0303, Accuracy: 24.71%\n",
      "Epoch [26/100], Step [200/640], Loss: 0.9163, Accuracy: 25.14%\n",
      "Epoch [26/100], Step [300/640], Loss: 0.8613, Accuracy: 24.71%\n",
      "Epoch [26/100], Step [400/640], Loss: 1.0001, Accuracy: 23.43%\n",
      "Epoch [26/100], Step [500/640], Loss: 0.8962, Accuracy: 26.14%\n",
      "Epoch [26/100], Step [600/640], Loss: 0.9141, Accuracy: 24.86%\n",
      "train Loss: 0.9074 Acc: 0.7904\n",
      "Epoch [26/100], Step [100/640], Loss: 1.0333, Accuracy: 25.00%\n",
      "val Loss: 0.9183 Acc: 0.7990\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/640], Loss: 0.8093, Accuracy: 26.29%\n",
      "Epoch [27/100], Step [200/640], Loss: 0.8212, Accuracy: 26.43%\n",
      "Epoch [27/100], Step [300/640], Loss: 0.9619, Accuracy: 24.57%\n",
      "Epoch [27/100], Step [400/640], Loss: 0.6902, Accuracy: 26.14%\n",
      "Epoch [27/100], Step [500/640], Loss: 0.9948, Accuracy: 24.14%\n",
      "Epoch [27/100], Step [600/640], Loss: 0.8642, Accuracy: 25.86%\n",
      "train Loss: 0.9030 Acc: 0.7911\n",
      "Epoch [27/100], Step [100/640], Loss: 1.1355, Accuracy: 24.14%\n",
      "val Loss: 0.9222 Acc: 0.7860\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/640], Loss: 0.8288, Accuracy: 26.00%\n",
      "Epoch [28/100], Step [200/640], Loss: 0.9475, Accuracy: 25.14%\n",
      "Epoch [28/100], Step [300/640], Loss: 1.0202, Accuracy: 23.71%\n",
      "Epoch [28/100], Step [400/640], Loss: 1.0438, Accuracy: 23.57%\n",
      "Epoch [28/100], Step [500/640], Loss: 0.9362, Accuracy: 25.86%\n",
      "Epoch [28/100], Step [600/640], Loss: 0.8664, Accuracy: 26.00%\n",
      "train Loss: 0.8977 Acc: 0.7933\n",
      "Epoch [28/100], Step [100/640], Loss: 1.0425, Accuracy: 25.00%\n",
      "val Loss: 0.9285 Acc: 0.7795\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/640], Loss: 0.7471, Accuracy: 27.71%\n",
      "Epoch [29/100], Step [200/640], Loss: 0.8459, Accuracy: 25.86%\n",
      "Epoch [29/100], Step [300/640], Loss: 1.0908, Accuracy: 23.71%\n",
      "Epoch [29/100], Step [400/640], Loss: 0.8735, Accuracy: 25.71%\n",
      "Epoch [29/100], Step [500/640], Loss: 0.8937, Accuracy: 25.71%\n",
      "Epoch [29/100], Step [600/640], Loss: 0.9212, Accuracy: 24.86%\n",
      "train Loss: 0.8921 Acc: 0.7938\n",
      "Epoch [29/100], Step [100/640], Loss: 0.9955, Accuracy: 24.14%\n",
      "val Loss: 0.9169 Acc: 0.7771\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/640], Loss: 1.0368, Accuracy: 24.86%\n",
      "Epoch [30/100], Step [200/640], Loss: 0.9119, Accuracy: 25.00%\n",
      "Epoch [30/100], Step [300/640], Loss: 0.7810, Accuracy: 25.57%\n",
      "Epoch [30/100], Step [400/640], Loss: 0.7743, Accuracy: 24.71%\n",
      "Epoch [30/100], Step [500/640], Loss: 0.8799, Accuracy: 25.00%\n",
      "Epoch [30/100], Step [600/640], Loss: 0.9549, Accuracy: 25.00%\n",
      "train Loss: 0.8874 Acc: 0.7941\n",
      "Epoch [30/100], Step [100/640], Loss: 0.9149, Accuracy: 25.57%\n",
      "val Loss: 0.9135 Acc: 0.7827\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/640], Loss: 0.8244, Accuracy: 24.71%\n",
      "Epoch [31/100], Step [200/640], Loss: 0.8889, Accuracy: 26.14%\n",
      "Epoch [31/100], Step [300/640], Loss: 0.8438, Accuracy: 25.71%\n",
      "Epoch [31/100], Step [400/640], Loss: 0.8034, Accuracy: 25.57%\n",
      "Epoch [31/100], Step [500/640], Loss: 0.7750, Accuracy: 25.86%\n",
      "Epoch [31/100], Step [600/640], Loss: 0.7889, Accuracy: 26.00%\n",
      "train Loss: 0.8822 Acc: 0.7952\n",
      "Epoch [31/100], Step [100/640], Loss: 0.9516, Accuracy: 25.14%\n",
      "val Loss: 0.9108 Acc: 0.7747\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/640], Loss: 0.9532, Accuracy: 24.29%\n",
      "Epoch [32/100], Step [200/640], Loss: 0.9798, Accuracy: 25.00%\n",
      "Epoch [32/100], Step [300/640], Loss: 0.8853, Accuracy: 24.71%\n",
      "Epoch [32/100], Step [400/640], Loss: 0.9491, Accuracy: 27.00%\n",
      "Epoch [32/100], Step [500/640], Loss: 0.7256, Accuracy: 26.43%\n",
      "Epoch [32/100], Step [600/640], Loss: 0.9024, Accuracy: 25.14%\n",
      "train Loss: 0.8742 Acc: 0.7987\n",
      "Epoch [32/100], Step [100/640], Loss: 0.9728, Accuracy: 24.57%\n",
      "val Loss: 0.9408 Acc: 0.7795\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/640], Loss: 0.8594, Accuracy: 26.43%\n",
      "Epoch [33/100], Step [200/640], Loss: 0.8360, Accuracy: 26.14%\n",
      "Epoch [33/100], Step [300/640], Loss: 0.8871, Accuracy: 25.57%\n",
      "Epoch [33/100], Step [400/640], Loss: 0.8154, Accuracy: 26.71%\n",
      "Epoch [33/100], Step [500/640], Loss: 0.6521, Accuracy: 26.71%\n",
      "Epoch [33/100], Step [600/640], Loss: 0.7526, Accuracy: 27.29%\n",
      "train Loss: 0.8716 Acc: 0.7988\n",
      "Epoch [33/100], Step [100/640], Loss: 1.0853, Accuracy: 23.43%\n",
      "val Loss: 0.9158 Acc: 0.7872\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/640], Loss: 0.7443, Accuracy: 26.29%\n",
      "Epoch [34/100], Step [200/640], Loss: 0.9050, Accuracy: 26.00%\n",
      "Epoch [34/100], Step [300/640], Loss: 0.9049, Accuracy: 25.57%\n",
      "Epoch [34/100], Step [400/640], Loss: 0.8660, Accuracy: 24.57%\n",
      "Epoch [34/100], Step [500/640], Loss: 0.8635, Accuracy: 24.29%\n",
      "Epoch [34/100], Step [600/640], Loss: 0.9946, Accuracy: 25.00%\n",
      "train Loss: 0.8647 Acc: 0.7989\n",
      "Epoch [34/100], Step [100/640], Loss: 1.0271, Accuracy: 25.71%\n",
      "val Loss: 0.9321 Acc: 0.7878\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/640], Loss: 1.0325, Accuracy: 25.00%\n",
      "Epoch [35/100], Step [200/640], Loss: 0.7367, Accuracy: 26.00%\n",
      "Epoch [35/100], Step [300/640], Loss: 0.9760, Accuracy: 24.43%\n",
      "Epoch [35/100], Step [400/640], Loss: 0.8204, Accuracy: 25.29%\n",
      "Epoch [35/100], Step [500/640], Loss: 0.8076, Accuracy: 26.29%\n",
      "Epoch [35/100], Step [600/640], Loss: 0.8711, Accuracy: 25.00%\n",
      "train Loss: 0.8606 Acc: 0.8003\n",
      "Epoch [35/100], Step [100/640], Loss: 1.3324, Accuracy: 24.86%\n",
      "val Loss: 0.9567 Acc: 0.7933\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/640], Loss: 0.7873, Accuracy: 26.57%\n",
      "Epoch [36/100], Step [200/640], Loss: 0.7469, Accuracy: 25.71%\n",
      "Epoch [36/100], Step [300/640], Loss: 0.9078, Accuracy: 25.86%\n",
      "Epoch [36/100], Step [400/640], Loss: 0.8978, Accuracy: 25.43%\n",
      "Epoch [36/100], Step [500/640], Loss: 0.8426, Accuracy: 25.57%\n",
      "Epoch [36/100], Step [600/640], Loss: 0.6822, Accuracy: 27.43%\n",
      "train Loss: 0.8558 Acc: 0.8002\n",
      "Epoch [36/100], Step [100/640], Loss: 1.1913, Accuracy: 23.86%\n",
      "val Loss: 0.9487 Acc: 0.7949\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/640], Loss: 0.8482, Accuracy: 25.86%\n",
      "Epoch [37/100], Step [200/640], Loss: 0.8284, Accuracy: 26.00%\n",
      "Epoch [37/100], Step [300/640], Loss: 0.7331, Accuracy: 27.43%\n",
      "Epoch [37/100], Step [400/640], Loss: 0.8626, Accuracy: 24.43%\n",
      "Epoch [37/100], Step [500/640], Loss: 0.7898, Accuracy: 26.14%\n",
      "Epoch [37/100], Step [600/640], Loss: 0.8133, Accuracy: 26.00%\n",
      "train Loss: 0.8493 Acc: 0.8015\n",
      "Epoch [37/100], Step [100/640], Loss: 1.2597, Accuracy: 24.57%\n",
      "val Loss: 0.9484 Acc: 0.8023\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/640], Loss: 1.1858, Accuracy: 24.86%\n",
      "Epoch [38/100], Step [200/640], Loss: 0.8126, Accuracy: 25.86%\n",
      "Epoch [38/100], Step [300/640], Loss: 0.9691, Accuracy: 24.43%\n",
      "Epoch [38/100], Step [400/640], Loss: 0.8421, Accuracy: 25.43%\n",
      "Epoch [38/100], Step [500/640], Loss: 0.7769, Accuracy: 26.57%\n",
      "Epoch [38/100], Step [600/640], Loss: 1.1431, Accuracy: 24.00%\n",
      "train Loss: 0.8416 Acc: 0.8027\n",
      "Epoch [38/100], Step [100/640], Loss: 1.2414, Accuracy: 24.14%\n",
      "val Loss: 0.9265 Acc: 0.7891\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/640], Loss: 0.8186, Accuracy: 25.29%\n",
      "Epoch [39/100], Step [200/640], Loss: 0.8218, Accuracy: 25.57%\n",
      "Epoch [39/100], Step [300/640], Loss: 0.8649, Accuracy: 25.71%\n",
      "Epoch [39/100], Step [400/640], Loss: 0.8852, Accuracy: 24.71%\n",
      "Epoch [39/100], Step [500/640], Loss: 0.8317, Accuracy: 25.43%\n",
      "Epoch [39/100], Step [600/640], Loss: 0.7772, Accuracy: 26.00%\n",
      "train Loss: 0.8368 Acc: 0.8041\n",
      "Epoch [39/100], Step [100/640], Loss: 1.0211, Accuracy: 24.71%\n",
      "val Loss: 0.9687 Acc: 0.7756\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/640], Loss: 0.7833, Accuracy: 26.57%\n",
      "Epoch [40/100], Step [200/640], Loss: 0.9659, Accuracy: 25.71%\n",
      "Epoch [40/100], Step [300/640], Loss: 0.8517, Accuracy: 26.71%\n",
      "Epoch [40/100], Step [400/640], Loss: 0.8477, Accuracy: 24.43%\n",
      "Epoch [40/100], Step [500/640], Loss: 0.8564, Accuracy: 26.86%\n",
      "Epoch [40/100], Step [600/640], Loss: 1.0169, Accuracy: 24.00%\n",
      "train Loss: 0.8276 Acc: 0.8038\n",
      "Epoch [40/100], Step [100/640], Loss: 1.4945, Accuracy: 24.14%\n",
      "val Loss: 1.0140 Acc: 0.7945\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/640], Loss: 0.8366, Accuracy: 25.71%\n",
      "Epoch [41/100], Step [200/640], Loss: 0.9906, Accuracy: 25.29%\n",
      "Epoch [41/100], Step [300/640], Loss: 0.8165, Accuracy: 26.29%\n",
      "Epoch [41/100], Step [400/640], Loss: 0.8979, Accuracy: 25.71%\n",
      "Epoch [41/100], Step [500/640], Loss: 0.8378, Accuracy: 26.43%\n",
      "Epoch [41/100], Step [600/640], Loss: 0.8014, Accuracy: 25.57%\n",
      "train Loss: 0.8200 Acc: 0.8058\n",
      "Epoch [41/100], Step [100/640], Loss: 1.2807, Accuracy: 24.71%\n",
      "val Loss: 0.9477 Acc: 0.7895\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/640], Loss: 0.7698, Accuracy: 26.00%\n",
      "Epoch [42/100], Step [200/640], Loss: 0.7811, Accuracy: 26.86%\n",
      "Epoch [42/100], Step [300/640], Loss: 0.7781, Accuracy: 25.86%\n",
      "Epoch [42/100], Step [400/640], Loss: 0.7326, Accuracy: 25.86%\n",
      "Epoch [42/100], Step [500/640], Loss: 0.9029, Accuracy: 24.57%\n",
      "Epoch [42/100], Step [600/640], Loss: 0.9021, Accuracy: 26.14%\n",
      "train Loss: 0.8146 Acc: 0.8079\n",
      "Epoch [42/100], Step [100/640], Loss: 1.0840, Accuracy: 25.14%\n",
      "val Loss: 0.9510 Acc: 0.7588\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/640], Loss: 0.9638, Accuracy: 25.14%\n",
      "Epoch [43/100], Step [200/640], Loss: 0.8288, Accuracy: 26.43%\n",
      "Epoch [43/100], Step [300/640], Loss: 0.9034, Accuracy: 25.71%\n",
      "Epoch [43/100], Step [400/640], Loss: 0.8703, Accuracy: 25.86%\n",
      "Epoch [43/100], Step [500/640], Loss: 0.6726, Accuracy: 26.14%\n",
      "Epoch [43/100], Step [600/640], Loss: 0.6420, Accuracy: 27.14%\n",
      "train Loss: 0.8070 Acc: 0.8082\n",
      "Epoch [43/100], Step [100/640], Loss: 1.2867, Accuracy: 23.57%\n",
      "val Loss: 0.9574 Acc: 0.7899\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/640], Loss: 0.7784, Accuracy: 26.57%\n",
      "Epoch [44/100], Step [200/640], Loss: 0.6749, Accuracy: 26.86%\n",
      "Epoch [44/100], Step [300/640], Loss: 0.8620, Accuracy: 27.14%\n",
      "Epoch [44/100], Step [400/640], Loss: 0.6169, Accuracy: 27.00%\n",
      "Epoch [44/100], Step [500/640], Loss: 0.7433, Accuracy: 27.29%\n",
      "Epoch [44/100], Step [600/640], Loss: 0.7429, Accuracy: 26.00%\n",
      "train Loss: 0.7958 Acc: 0.8105\n",
      "Epoch [44/100], Step [100/640], Loss: 1.2880, Accuracy: 24.57%\n",
      "val Loss: 0.9728 Acc: 0.7905\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/640], Loss: 0.7647, Accuracy: 25.57%\n",
      "Epoch [45/100], Step [200/640], Loss: 0.6970, Accuracy: 25.14%\n",
      "Epoch [45/100], Step [300/640], Loss: 0.6433, Accuracy: 26.71%\n",
      "Epoch [45/100], Step [400/640], Loss: 0.8768, Accuracy: 24.43%\n",
      "Epoch [45/100], Step [500/640], Loss: 0.9084, Accuracy: 25.71%\n",
      "Epoch [45/100], Step [600/640], Loss: 0.6224, Accuracy: 27.29%\n",
      "train Loss: 0.7926 Acc: 0.8113\n",
      "Epoch [45/100], Step [100/640], Loss: 1.2701, Accuracy: 24.00%\n",
      "val Loss: 0.9877 Acc: 0.7912\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/640], Loss: 1.0793, Accuracy: 25.14%\n",
      "Epoch [46/100], Step [200/640], Loss: 0.6901, Accuracy: 27.71%\n",
      "Epoch [46/100], Step [300/640], Loss: 0.8103, Accuracy: 26.14%\n",
      "Epoch [46/100], Step [400/640], Loss: 0.7597, Accuracy: 26.43%\n",
      "Epoch [46/100], Step [500/640], Loss: 0.8424, Accuracy: 25.00%\n",
      "Epoch [46/100], Step [600/640], Loss: 0.7493, Accuracy: 26.71%\n",
      "train Loss: 0.7820 Acc: 0.8114\n",
      "Epoch [46/100], Step [100/640], Loss: 1.1197, Accuracy: 25.14%\n",
      "val Loss: 0.9528 Acc: 0.7777\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/640], Loss: 0.7573, Accuracy: 25.43%\n",
      "Epoch [47/100], Step [200/640], Loss: 0.8957, Accuracy: 26.00%\n",
      "Epoch [47/100], Step [300/640], Loss: 0.8169, Accuracy: 25.29%\n",
      "Epoch [47/100], Step [400/640], Loss: 0.7265, Accuracy: 26.57%\n",
      "Epoch [47/100], Step [500/640], Loss: 0.8131, Accuracy: 25.14%\n",
      "Epoch [47/100], Step [600/640], Loss: 0.8361, Accuracy: 25.00%\n",
      "train Loss: 0.7747 Acc: 0.8138\n",
      "Epoch [47/100], Step [100/640], Loss: 1.4747, Accuracy: 23.57%\n",
      "val Loss: 0.9962 Acc: 0.7839\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/640], Loss: 0.7789, Accuracy: 26.00%\n",
      "Epoch [48/100], Step [200/640], Loss: 0.7142, Accuracy: 25.14%\n",
      "Epoch [48/100], Step [300/640], Loss: 0.6696, Accuracy: 26.14%\n",
      "Epoch [48/100], Step [400/640], Loss: 0.9803, Accuracy: 25.29%\n",
      "Epoch [48/100], Step [500/640], Loss: 0.9435, Accuracy: 25.29%\n",
      "Epoch [48/100], Step [600/640], Loss: 0.9571, Accuracy: 24.71%\n",
      "train Loss: 0.7673 Acc: 0.8150\n",
      "Epoch [48/100], Step [100/640], Loss: 1.3550, Accuracy: 24.57%\n",
      "val Loss: 1.0175 Acc: 0.7941\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/640], Loss: 0.8759, Accuracy: 25.43%\n",
      "Epoch [49/100], Step [200/640], Loss: 0.7904, Accuracy: 25.57%\n",
      "Epoch [49/100], Step [300/640], Loss: 0.7903, Accuracy: 25.43%\n",
      "Epoch [49/100], Step [400/640], Loss: 0.7462, Accuracy: 27.00%\n",
      "Epoch [49/100], Step [500/640], Loss: 0.6162, Accuracy: 26.57%\n",
      "Epoch [49/100], Step [600/640], Loss: 0.7655, Accuracy: 25.86%\n",
      "train Loss: 0.7611 Acc: 0.8166\n",
      "Epoch [49/100], Step [100/640], Loss: 1.5227, Accuracy: 24.00%\n",
      "val Loss: 1.0014 Acc: 0.7731\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/640], Loss: 0.6556, Accuracy: 27.14%\n",
      "Epoch [50/100], Step [200/640], Loss: 0.7752, Accuracy: 26.00%\n",
      "Epoch [50/100], Step [300/640], Loss: 0.7161, Accuracy: 26.43%\n",
      "Epoch [50/100], Step [400/640], Loss: 0.8647, Accuracy: 25.86%\n",
      "Epoch [50/100], Step [500/640], Loss: 0.6002, Accuracy: 27.71%\n",
      "Epoch [50/100], Step [600/640], Loss: 0.8157, Accuracy: 25.29%\n",
      "train Loss: 0.7486 Acc: 0.8179\n",
      "Epoch [50/100], Step [100/640], Loss: 1.2478, Accuracy: 25.00%\n",
      "val Loss: 1.0024 Acc: 0.7790\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/640], Loss: 0.7575, Accuracy: 26.29%\n",
      "Epoch [51/100], Step [200/640], Loss: 0.7208, Accuracy: 25.57%\n",
      "Epoch [51/100], Step [300/640], Loss: 0.6239, Accuracy: 27.57%\n",
      "Epoch [51/100], Step [400/640], Loss: 0.8225, Accuracy: 24.86%\n",
      "Epoch [51/100], Step [500/640], Loss: 0.7559, Accuracy: 26.14%\n",
      "Epoch [51/100], Step [600/640], Loss: 0.6403, Accuracy: 27.14%\n",
      "train Loss: 0.7383 Acc: 0.8207\n",
      "Epoch [51/100], Step [100/640], Loss: 1.2891, Accuracy: 24.14%\n",
      "val Loss: 1.0091 Acc: 0.7639\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/640], Loss: 0.6631, Accuracy: 27.14%\n",
      "Epoch [52/100], Step [200/640], Loss: 0.7435, Accuracy: 25.43%\n",
      "Epoch [52/100], Step [300/640], Loss: 0.8153, Accuracy: 26.86%\n",
      "Epoch [52/100], Step [400/640], Loss: 0.8885, Accuracy: 25.43%\n",
      "Epoch [52/100], Step [500/640], Loss: 0.7503, Accuracy: 26.00%\n",
      "Epoch [52/100], Step [600/640], Loss: 0.7872, Accuracy: 26.71%\n",
      "train Loss: 0.7330 Acc: 0.8217\n",
      "Epoch [52/100], Step [100/640], Loss: 1.1259, Accuracy: 24.43%\n",
      "val Loss: 0.9939 Acc: 0.7542\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/640], Loss: 0.7641, Accuracy: 26.29%\n",
      "Epoch [53/100], Step [200/640], Loss: 0.7657, Accuracy: 25.57%\n",
      "Epoch [53/100], Step [300/640], Loss: 0.6443, Accuracy: 26.57%\n",
      "Epoch [53/100], Step [400/640], Loss: 0.8646, Accuracy: 25.43%\n",
      "Epoch [53/100], Step [500/640], Loss: 0.7101, Accuracy: 26.57%\n",
      "Epoch [53/100], Step [600/640], Loss: 0.6760, Accuracy: 26.43%\n",
      "train Loss: 0.7249 Acc: 0.8240\n",
      "Epoch [53/100], Step [100/640], Loss: 1.1524, Accuracy: 23.29%\n",
      "val Loss: 1.0437 Acc: 0.7581\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/640], Loss: 0.9962, Accuracy: 24.57%\n",
      "Epoch [54/100], Step [200/640], Loss: 1.0312, Accuracy: 25.71%\n",
      "Epoch [54/100], Step [300/640], Loss: 0.6262, Accuracy: 26.57%\n",
      "Epoch [54/100], Step [400/640], Loss: 0.7148, Accuracy: 27.00%\n",
      "Epoch [54/100], Step [500/640], Loss: 0.6817, Accuracy: 26.57%\n",
      "Epoch [54/100], Step [600/640], Loss: 0.7048, Accuracy: 27.00%\n",
      "train Loss: 0.7139 Acc: 0.8255\n",
      "Epoch [54/100], Step [100/640], Loss: 1.1183, Accuracy: 24.29%\n",
      "val Loss: 1.0508 Acc: 0.7621\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/640], Loss: 0.7497, Accuracy: 25.71%\n",
      "Epoch [55/100], Step [200/640], Loss: 0.7069, Accuracy: 26.71%\n",
      "Epoch [55/100], Step [300/640], Loss: 0.9117, Accuracy: 25.29%\n",
      "Epoch [55/100], Step [400/640], Loss: 0.8073, Accuracy: 27.71%\n",
      "Epoch [55/100], Step [500/640], Loss: 0.7157, Accuracy: 26.86%\n",
      "Epoch [55/100], Step [600/640], Loss: 0.7094, Accuracy: 26.43%\n",
      "train Loss: 0.7075 Acc: 0.8254\n",
      "Epoch [55/100], Step [100/640], Loss: 1.2803, Accuracy: 24.43%\n",
      "val Loss: 1.0640 Acc: 0.7782\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/640], Loss: 0.7825, Accuracy: 26.57%\n",
      "Epoch [56/100], Step [200/640], Loss: 0.7149, Accuracy: 25.29%\n",
      "Epoch [56/100], Step [300/640], Loss: 0.4942, Accuracy: 28.00%\n",
      "Epoch [56/100], Step [400/640], Loss: 0.5267, Accuracy: 29.00%\n",
      "Epoch [56/100], Step [500/640], Loss: 0.6262, Accuracy: 26.14%\n",
      "Epoch [56/100], Step [600/640], Loss: 0.5865, Accuracy: 27.00%\n",
      "train Loss: 0.6894 Acc: 0.8313\n",
      "Epoch [56/100], Step [100/640], Loss: 1.4644, Accuracy: 24.43%\n",
      "val Loss: 1.0844 Acc: 0.7853\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/640], Loss: 0.6266, Accuracy: 26.57%\n",
      "Epoch [57/100], Step [200/640], Loss: 0.5058, Accuracy: 28.29%\n",
      "Epoch [57/100], Step [300/640], Loss: 0.5983, Accuracy: 28.00%\n",
      "Epoch [57/100], Step [400/640], Loss: 0.6906, Accuracy: 26.14%\n",
      "Epoch [57/100], Step [500/640], Loss: 0.7505, Accuracy: 26.00%\n",
      "Epoch [57/100], Step [600/640], Loss: 0.7460, Accuracy: 26.86%\n",
      "train Loss: 0.6836 Acc: 0.8328\n",
      "Epoch [57/100], Step [100/640], Loss: 1.2195, Accuracy: 24.86%\n",
      "val Loss: 1.0859 Acc: 0.7693\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/640], Loss: 0.7740, Accuracy: 26.14%\n",
      "Epoch [58/100], Step [200/640], Loss: 0.7536, Accuracy: 26.14%\n",
      "Epoch [58/100], Step [300/640], Loss: 0.6640, Accuracy: 27.14%\n",
      "Epoch [58/100], Step [400/640], Loss: 0.6905, Accuracy: 26.00%\n",
      "Epoch [58/100], Step [500/640], Loss: 0.7396, Accuracy: 26.57%\n",
      "Epoch [58/100], Step [600/640], Loss: 0.7660, Accuracy: 27.14%\n",
      "train Loss: 0.6743 Acc: 0.8338\n",
      "Epoch [58/100], Step [100/640], Loss: 1.3314, Accuracy: 24.14%\n",
      "val Loss: 1.0909 Acc: 0.7674\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/640], Loss: 0.6569, Accuracy: 27.71%\n",
      "Epoch [59/100], Step [200/640], Loss: 0.6303, Accuracy: 27.57%\n",
      "Epoch [59/100], Step [300/640], Loss: 0.6940, Accuracy: 25.86%\n",
      "Epoch [59/100], Step [400/640], Loss: 0.6619, Accuracy: 27.14%\n",
      "Epoch [59/100], Step [500/640], Loss: 0.6203, Accuracy: 27.57%\n",
      "Epoch [59/100], Step [600/640], Loss: 0.6380, Accuracy: 26.57%\n",
      "train Loss: 0.6650 Acc: 0.8366\n",
      "Epoch [59/100], Step [100/640], Loss: 1.3022, Accuracy: 24.86%\n",
      "val Loss: 1.1848 Acc: 0.7764\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/640], Loss: 0.6472, Accuracy: 27.14%\n",
      "Epoch [60/100], Step [200/640], Loss: 0.5845, Accuracy: 27.14%\n",
      "Epoch [60/100], Step [300/640], Loss: 0.7831, Accuracy: 25.57%\n",
      "Epoch [60/100], Step [400/640], Loss: 0.6662, Accuracy: 27.14%\n",
      "Epoch [60/100], Step [500/640], Loss: 0.5935, Accuracy: 27.71%\n",
      "Epoch [60/100], Step [600/640], Loss: 0.8158, Accuracy: 25.71%\n",
      "train Loss: 0.6661 Acc: 0.8368\n",
      "Epoch [60/100], Step [100/640], Loss: 1.4103, Accuracy: 24.43%\n",
      "val Loss: 1.1534 Acc: 0.7722\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/640], Loss: 0.6407, Accuracy: 27.29%\n",
      "Epoch [61/100], Step [200/640], Loss: 0.6932, Accuracy: 24.71%\n",
      "Epoch [61/100], Step [300/640], Loss: 0.6638, Accuracy: 27.00%\n",
      "Epoch [61/100], Step [400/640], Loss: 0.6725, Accuracy: 26.86%\n",
      "Epoch [61/100], Step [500/640], Loss: 0.6032, Accuracy: 26.86%\n",
      "Epoch [61/100], Step [600/640], Loss: 0.6710, Accuracy: 26.86%\n",
      "train Loss: 0.6516 Acc: 0.8386\n",
      "Epoch [61/100], Step [100/640], Loss: 1.4186, Accuracy: 24.57%\n",
      "val Loss: 1.1920 Acc: 0.7820\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/640], Loss: 0.6150, Accuracy: 26.57%\n",
      "Epoch [62/100], Step [200/640], Loss: 0.8639, Accuracy: 26.43%\n",
      "Epoch [62/100], Step [300/640], Loss: 0.7709, Accuracy: 26.14%\n",
      "Epoch [62/100], Step [400/640], Loss: 0.6643, Accuracy: 26.71%\n",
      "Epoch [62/100], Step [500/640], Loss: 0.6345, Accuracy: 27.00%\n",
      "Epoch [62/100], Step [600/640], Loss: 0.5459, Accuracy: 27.57%\n",
      "train Loss: 0.6362 Acc: 0.8428\n",
      "Epoch [62/100], Step [100/640], Loss: 1.5960, Accuracy: 24.43%\n",
      "val Loss: 1.2882 Acc: 0.7807\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/640], Loss: 0.5987, Accuracy: 27.14%\n",
      "Epoch [63/100], Step [200/640], Loss: 0.5699, Accuracy: 27.14%\n",
      "Epoch [63/100], Step [300/640], Loss: 0.6030, Accuracy: 28.00%\n",
      "Epoch [63/100], Step [400/640], Loss: 0.6153, Accuracy: 26.71%\n",
      "Epoch [63/100], Step [500/640], Loss: 0.6348, Accuracy: 26.00%\n",
      "Epoch [63/100], Step [600/640], Loss: 0.6863, Accuracy: 26.43%\n",
      "train Loss: 0.6320 Acc: 0.8431\n",
      "Epoch [63/100], Step [100/640], Loss: 1.4768, Accuracy: 24.57%\n",
      "val Loss: 1.1810 Acc: 0.7681\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/640], Loss: 0.6470, Accuracy: 26.57%\n",
      "Epoch [64/100], Step [200/640], Loss: 0.5947, Accuracy: 26.71%\n",
      "Epoch [64/100], Step [300/640], Loss: 0.6960, Accuracy: 25.57%\n",
      "Epoch [64/100], Step [400/640], Loss: 0.5884, Accuracy: 28.57%\n",
      "Epoch [64/100], Step [500/640], Loss: 0.6354, Accuracy: 26.00%\n",
      "Epoch [64/100], Step [600/640], Loss: 0.6940, Accuracy: 26.29%\n",
      "train Loss: 0.6203 Acc: 0.8460\n",
      "Epoch [64/100], Step [100/640], Loss: 1.4211, Accuracy: 25.14%\n",
      "val Loss: 1.2647 Acc: 0.7778\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/640], Loss: 0.5563, Accuracy: 27.43%\n",
      "Epoch [65/100], Step [200/640], Loss: 0.5290, Accuracy: 27.14%\n",
      "Epoch [65/100], Step [300/640], Loss: 0.6067, Accuracy: 27.57%\n",
      "Epoch [65/100], Step [400/640], Loss: 0.6484, Accuracy: 27.00%\n",
      "Epoch [65/100], Step [500/640], Loss: 0.6683, Accuracy: 27.86%\n",
      "Epoch [65/100], Step [600/640], Loss: 0.6513, Accuracy: 27.43%\n",
      "train Loss: 0.6203 Acc: 0.8467\n",
      "Epoch [65/100], Step [100/640], Loss: 1.7637, Accuracy: 24.00%\n",
      "val Loss: 1.2885 Acc: 0.7874\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/640], Loss: 0.6682, Accuracy: 26.86%\n",
      "Epoch [66/100], Step [200/640], Loss: 0.7340, Accuracy: 26.00%\n",
      "Epoch [66/100], Step [300/640], Loss: 0.6988, Accuracy: 26.43%\n",
      "Epoch [66/100], Step [400/640], Loss: 0.6916, Accuracy: 27.43%\n",
      "Epoch [66/100], Step [500/640], Loss: 0.6050, Accuracy: 27.14%\n",
      "Epoch [66/100], Step [600/640], Loss: 0.5255, Accuracy: 27.14%\n",
      "train Loss: 0.6064 Acc: 0.8494\n",
      "Epoch [66/100], Step [100/640], Loss: 1.3308, Accuracy: 25.29%\n",
      "val Loss: 1.2508 Acc: 0.7765\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/640], Loss: 0.7203, Accuracy: 27.29%\n",
      "Epoch [67/100], Step [200/640], Loss: 0.6043, Accuracy: 28.29%\n",
      "Epoch [67/100], Step [300/640], Loss: 0.8218, Accuracy: 25.43%\n",
      "Epoch [67/100], Step [400/640], Loss: 0.6895, Accuracy: 27.14%\n",
      "Epoch [67/100], Step [500/640], Loss: 0.5797, Accuracy: 28.14%\n",
      "Epoch [67/100], Step [600/640], Loss: 0.6794, Accuracy: 27.29%\n",
      "train Loss: 0.5934 Acc: 0.8534\n",
      "Epoch [67/100], Step [100/640], Loss: 1.9278, Accuracy: 23.86%\n",
      "val Loss: 1.3397 Acc: 0.7900\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/640], Loss: 0.5339, Accuracy: 27.57%\n",
      "Epoch [68/100], Step [200/640], Loss: 0.5996, Accuracy: 27.14%\n",
      "Epoch [68/100], Step [300/640], Loss: 0.5854, Accuracy: 27.71%\n",
      "Epoch [68/100], Step [400/640], Loss: 0.5963, Accuracy: 28.29%\n",
      "Epoch [68/100], Step [500/640], Loss: 0.6346, Accuracy: 26.57%\n",
      "Epoch [68/100], Step [600/640], Loss: 0.6343, Accuracy: 27.57%\n",
      "train Loss: 0.5919 Acc: 0.8534\n",
      "Epoch [68/100], Step [100/640], Loss: 1.6394, Accuracy: 24.57%\n",
      "val Loss: 1.3041 Acc: 0.7832\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/640], Loss: 0.4682, Accuracy: 27.86%\n",
      "Epoch [69/100], Step [200/640], Loss: 0.5718, Accuracy: 27.57%\n",
      "Epoch [69/100], Step [300/640], Loss: 0.5328, Accuracy: 27.29%\n",
      "Epoch [69/100], Step [400/640], Loss: 0.6218, Accuracy: 27.00%\n",
      "Epoch [69/100], Step [500/640], Loss: 0.5499, Accuracy: 27.71%\n",
      "Epoch [69/100], Step [600/640], Loss: 0.5243, Accuracy: 27.71%\n",
      "train Loss: 0.5775 Acc: 0.8565\n",
      "Epoch [69/100], Step [100/640], Loss: 1.7831, Accuracy: 25.14%\n",
      "val Loss: 1.4108 Acc: 0.7822\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/640], Loss: 0.6363, Accuracy: 27.43%\n",
      "Epoch [70/100], Step [200/640], Loss: 0.5079, Accuracy: 27.43%\n",
      "Epoch [70/100], Step [300/640], Loss: 0.6430, Accuracy: 27.00%\n",
      "Epoch [70/100], Step [400/640], Loss: 0.4229, Accuracy: 28.71%\n",
      "Epoch [70/100], Step [500/640], Loss: 0.6161, Accuracy: 27.00%\n",
      "Epoch [70/100], Step [600/640], Loss: 0.6279, Accuracy: 27.00%\n",
      "train Loss: 0.5696 Acc: 0.8586\n",
      "Epoch [70/100], Step [100/640], Loss: 1.6690, Accuracy: 24.71%\n",
      "val Loss: 1.4007 Acc: 0.7837\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/640], Loss: 0.5696, Accuracy: 27.00%\n",
      "Epoch [71/100], Step [200/640], Loss: 0.5396, Accuracy: 26.71%\n",
      "Epoch [71/100], Step [300/640], Loss: 0.4638, Accuracy: 27.57%\n",
      "Epoch [71/100], Step [400/640], Loss: 0.7070, Accuracy: 27.14%\n",
      "Epoch [71/100], Step [500/640], Loss: 0.5339, Accuracy: 28.14%\n",
      "Epoch [71/100], Step [600/640], Loss: 0.3860, Accuracy: 28.57%\n",
      "train Loss: 0.5611 Acc: 0.8602\n",
      "Epoch [71/100], Step [100/640], Loss: 1.4833, Accuracy: 24.29%\n",
      "val Loss: 1.3488 Acc: 0.7751\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/640], Loss: 0.5074, Accuracy: 27.86%\n",
      "Epoch [72/100], Step [200/640], Loss: 0.6396, Accuracy: 27.00%\n",
      "Epoch [72/100], Step [300/640], Loss: 0.6702, Accuracy: 26.57%\n",
      "Epoch [72/100], Step [400/640], Loss: 0.6079, Accuracy: 28.14%\n",
      "Epoch [72/100], Step [500/640], Loss: 0.6289, Accuracy: 27.29%\n",
      "Epoch [72/100], Step [600/640], Loss: 0.4541, Accuracy: 28.00%\n",
      "train Loss: 0.5597 Acc: 0.8613\n",
      "Epoch [72/100], Step [100/640], Loss: 1.6069, Accuracy: 25.14%\n",
      "val Loss: 1.3661 Acc: 0.7795\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/640], Loss: 0.4998, Accuracy: 28.29%\n",
      "Epoch [73/100], Step [200/640], Loss: 0.5837, Accuracy: 27.71%\n",
      "Epoch [73/100], Step [300/640], Loss: 0.6670, Accuracy: 27.43%\n",
      "Epoch [73/100], Step [400/640], Loss: 0.5283, Accuracy: 27.86%\n",
      "Epoch [73/100], Step [500/640], Loss: 0.4828, Accuracy: 28.71%\n",
      "Epoch [73/100], Step [600/640], Loss: 0.5436, Accuracy: 27.43%\n",
      "train Loss: 0.5457 Acc: 0.8641\n",
      "Epoch [73/100], Step [100/640], Loss: 1.5370, Accuracy: 25.86%\n",
      "val Loss: 1.3992 Acc: 0.7824\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/640], Loss: 0.5032, Accuracy: 28.29%\n",
      "Epoch [74/100], Step [200/640], Loss: 0.4876, Accuracy: 28.00%\n",
      "Epoch [74/100], Step [300/640], Loss: 0.5139, Accuracy: 27.71%\n",
      "Epoch [74/100], Step [400/640], Loss: 0.8318, Accuracy: 25.86%\n",
      "Epoch [74/100], Step [500/640], Loss: 0.6073, Accuracy: 25.57%\n",
      "Epoch [74/100], Step [600/640], Loss: 0.6588, Accuracy: 26.29%\n",
      "train Loss: 0.5329 Acc: 0.8671\n",
      "Epoch [74/100], Step [100/640], Loss: 1.9252, Accuracy: 25.29%\n",
      "val Loss: 1.5171 Acc: 0.7879\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/640], Loss: 0.5175, Accuracy: 28.00%\n",
      "Epoch [75/100], Step [200/640], Loss: 0.5042, Accuracy: 28.00%\n",
      "Epoch [75/100], Step [300/640], Loss: 0.5356, Accuracy: 27.43%\n",
      "Epoch [75/100], Step [400/640], Loss: 0.6247, Accuracy: 26.86%\n",
      "Epoch [75/100], Step [500/640], Loss: 0.5374, Accuracy: 27.43%\n",
      "Epoch [75/100], Step [600/640], Loss: 0.4440, Accuracy: 28.43%\n",
      "train Loss: 0.5323 Acc: 0.8671\n",
      "Epoch [75/100], Step [100/640], Loss: 1.7126, Accuracy: 24.71%\n",
      "val Loss: 1.5018 Acc: 0.7834\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/640], Loss: 0.4433, Accuracy: 28.00%\n",
      "Epoch [76/100], Step [200/640], Loss: 0.4926, Accuracy: 28.86%\n",
      "Epoch [76/100], Step [300/640], Loss: 0.4980, Accuracy: 28.00%\n",
      "Epoch [76/100], Step [400/640], Loss: 0.6023, Accuracy: 27.57%\n",
      "Epoch [76/100], Step [500/640], Loss: 0.5327, Accuracy: 27.14%\n",
      "Epoch [76/100], Step [600/640], Loss: 0.5801, Accuracy: 27.00%\n",
      "train Loss: 0.5206 Acc: 0.8706\n",
      "Epoch [76/100], Step [100/640], Loss: 1.9005, Accuracy: 24.43%\n",
      "val Loss: 1.5158 Acc: 0.7852\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/640], Loss: 0.5034, Accuracy: 26.86%\n",
      "Epoch [77/100], Step [200/640], Loss: 0.4540, Accuracy: 28.43%\n",
      "Epoch [77/100], Step [300/640], Loss: 0.5026, Accuracy: 29.00%\n",
      "Epoch [77/100], Step [400/640], Loss: 0.5124, Accuracy: 28.00%\n",
      "Epoch [77/100], Step [500/640], Loss: 0.4550, Accuracy: 27.86%\n",
      "Epoch [77/100], Step [600/640], Loss: 0.7655, Accuracy: 26.71%\n",
      "train Loss: 0.5154 Acc: 0.8711\n",
      "Epoch [77/100], Step [100/640], Loss: 1.6411, Accuracy: 25.57%\n",
      "val Loss: 1.4710 Acc: 0.7814\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/640], Loss: 0.6109, Accuracy: 27.43%\n",
      "Epoch [78/100], Step [200/640], Loss: 0.5131, Accuracy: 27.14%\n",
      "Epoch [78/100], Step [300/640], Loss: 0.5965, Accuracy: 27.86%\n",
      "Epoch [78/100], Step [400/640], Loss: 0.4386, Accuracy: 28.14%\n",
      "Epoch [78/100], Step [500/640], Loss: 0.4803, Accuracy: 27.29%\n",
      "Epoch [78/100], Step [600/640], Loss: 0.4812, Accuracy: 28.14%\n",
      "train Loss: 0.5066 Acc: 0.8753\n",
      "Epoch [78/100], Step [100/640], Loss: 1.8136, Accuracy: 25.14%\n",
      "val Loss: 1.5828 Acc: 0.7834\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/640], Loss: 0.4775, Accuracy: 28.29%\n",
      "Epoch [79/100], Step [200/640], Loss: 0.6031, Accuracy: 26.29%\n",
      "Epoch [79/100], Step [300/640], Loss: 0.3992, Accuracy: 28.29%\n",
      "Epoch [79/100], Step [400/640], Loss: 0.4489, Accuracy: 27.86%\n",
      "Epoch [79/100], Step [500/640], Loss: 0.3907, Accuracy: 29.00%\n",
      "Epoch [79/100], Step [600/640], Loss: 0.4698, Accuracy: 27.71%\n",
      "train Loss: 0.5025 Acc: 0.8747\n",
      "Epoch [79/100], Step [100/640], Loss: 1.8175, Accuracy: 25.29%\n",
      "val Loss: 1.5358 Acc: 0.7827\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/640], Loss: 0.7682, Accuracy: 26.43%\n",
      "Epoch [80/100], Step [200/640], Loss: 0.5302, Accuracy: 27.43%\n",
      "Epoch [80/100], Step [300/640], Loss: 0.5333, Accuracy: 28.14%\n",
      "Epoch [80/100], Step [400/640], Loss: 0.4968, Accuracy: 27.86%\n",
      "Epoch [80/100], Step [500/640], Loss: 0.4796, Accuracy: 28.00%\n",
      "Epoch [80/100], Step [600/640], Loss: 0.4595, Accuracy: 28.57%\n",
      "train Loss: 0.4959 Acc: 0.8759\n",
      "Epoch [80/100], Step [100/640], Loss: 1.9753, Accuracy: 25.14%\n",
      "val Loss: 1.6125 Acc: 0.7887\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/640], Loss: 0.5691, Accuracy: 26.86%\n",
      "Epoch [81/100], Step [200/640], Loss: 0.4419, Accuracy: 29.00%\n",
      "Epoch [81/100], Step [300/640], Loss: 0.5286, Accuracy: 27.14%\n",
      "Epoch [81/100], Step [400/640], Loss: 0.4907, Accuracy: 28.00%\n",
      "Epoch [81/100], Step [500/640], Loss: 0.5219, Accuracy: 27.71%\n",
      "Epoch [81/100], Step [600/640], Loss: 0.4898, Accuracy: 27.29%\n",
      "train Loss: 0.4852 Acc: 0.8788\n",
      "Epoch [81/100], Step [100/640], Loss: 2.1683, Accuracy: 25.57%\n",
      "val Loss: 1.7167 Acc: 0.7881\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/640], Loss: 0.5117, Accuracy: 27.71%\n",
      "Epoch [82/100], Step [200/640], Loss: 0.5552, Accuracy: 27.14%\n",
      "Epoch [82/100], Step [300/640], Loss: 0.3495, Accuracy: 28.86%\n",
      "Epoch [82/100], Step [400/640], Loss: 0.4540, Accuracy: 28.43%\n",
      "Epoch [82/100], Step [500/640], Loss: 0.5691, Accuracy: 27.86%\n",
      "Epoch [82/100], Step [600/640], Loss: 0.4275, Accuracy: 28.86%\n",
      "train Loss: 0.4810 Acc: 0.8797\n",
      "Epoch [82/100], Step [100/640], Loss: 2.2772, Accuracy: 25.43%\n",
      "val Loss: 1.6232 Acc: 0.7851\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/640], Loss: 0.5443, Accuracy: 28.86%\n",
      "Epoch [83/100], Step [200/640], Loss: 0.4379, Accuracy: 27.57%\n",
      "Epoch [83/100], Step [300/640], Loss: 0.4097, Accuracy: 29.29%\n",
      "Epoch [83/100], Step [400/640], Loss: 0.5140, Accuracy: 27.86%\n",
      "Epoch [83/100], Step [500/640], Loss: 0.3419, Accuracy: 29.29%\n",
      "Epoch [83/100], Step [600/640], Loss: 0.5686, Accuracy: 28.14%\n",
      "train Loss: 0.4750 Acc: 0.8816\n",
      "Epoch [83/100], Step [100/640], Loss: 1.8947, Accuracy: 24.86%\n",
      "val Loss: 1.7073 Acc: 0.7829\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/640], Loss: 0.3807, Accuracy: 29.14%\n",
      "Epoch [84/100], Step [200/640], Loss: 0.5117, Accuracy: 26.86%\n",
      "Epoch [84/100], Step [300/640], Loss: 0.4130, Accuracy: 28.14%\n",
      "Epoch [84/100], Step [400/640], Loss: 0.6018, Accuracy: 27.14%\n",
      "Epoch [84/100], Step [500/640], Loss: 0.5556, Accuracy: 28.43%\n",
      "Epoch [84/100], Step [600/640], Loss: 0.3461, Accuracy: 29.29%\n",
      "train Loss: 0.4718 Acc: 0.8820\n",
      "Epoch [84/100], Step [100/640], Loss: 2.5173, Accuracy: 25.43%\n",
      "val Loss: 1.7627 Acc: 0.7952\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/640], Loss: 0.5940, Accuracy: 27.57%\n",
      "Epoch [85/100], Step [200/640], Loss: 0.5492, Accuracy: 26.57%\n",
      "Epoch [85/100], Step [300/640], Loss: 0.4746, Accuracy: 27.57%\n",
      "Epoch [85/100], Step [400/640], Loss: 0.4076, Accuracy: 29.43%\n",
      "Epoch [85/100], Step [500/640], Loss: 0.5199, Accuracy: 29.00%\n",
      "Epoch [85/100], Step [600/640], Loss: 0.3347, Accuracy: 29.86%\n",
      "train Loss: 0.4631 Acc: 0.8838\n",
      "Epoch [85/100], Step [100/640], Loss: 2.0764, Accuracy: 25.29%\n",
      "val Loss: 1.7336 Acc: 0.7853\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/640], Loss: 0.4875, Accuracy: 27.57%\n",
      "Epoch [86/100], Step [200/640], Loss: 0.3710, Accuracy: 29.29%\n",
      "Epoch [86/100], Step [300/640], Loss: 0.4424, Accuracy: 28.43%\n",
      "Epoch [86/100], Step [400/640], Loss: 0.4712, Accuracy: 28.00%\n",
      "Epoch [86/100], Step [500/640], Loss: 0.4381, Accuracy: 28.29%\n",
      "Epoch [86/100], Step [600/640], Loss: 0.5327, Accuracy: 28.14%\n",
      "train Loss: 0.4546 Acc: 0.8872\n",
      "Epoch [86/100], Step [100/640], Loss: 2.3812, Accuracy: 25.29%\n",
      "val Loss: 1.7302 Acc: 0.7846\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/640], Loss: 0.4453, Accuracy: 28.00%\n",
      "Epoch [87/100], Step [200/640], Loss: 0.6184, Accuracy: 28.14%\n",
      "Epoch [87/100], Step [300/640], Loss: 0.3517, Accuracy: 28.57%\n",
      "Epoch [87/100], Step [400/640], Loss: 0.6137, Accuracy: 29.14%\n",
      "Epoch [87/100], Step [500/640], Loss: 0.4271, Accuracy: 28.00%\n",
      "Epoch [87/100], Step [600/640], Loss: 0.3437, Accuracy: 28.71%\n",
      "train Loss: 0.4527 Acc: 0.8885\n",
      "Epoch [87/100], Step [100/640], Loss: 2.3215, Accuracy: 25.00%\n",
      "val Loss: 1.6641 Acc: 0.7839\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/640], Loss: 0.5034, Accuracy: 28.00%\n",
      "Epoch [88/100], Step [200/640], Loss: 0.3131, Accuracy: 29.29%\n",
      "Epoch [88/100], Step [300/640], Loss: 0.3445, Accuracy: 29.29%\n",
      "Epoch [88/100], Step [400/640], Loss: 0.3795, Accuracy: 28.86%\n",
      "Epoch [88/100], Step [500/640], Loss: 0.4644, Accuracy: 27.86%\n",
      "Epoch [88/100], Step [600/640], Loss: 0.3372, Accuracy: 29.00%\n",
      "train Loss: 0.4468 Acc: 0.8889\n",
      "Epoch [88/100], Step [100/640], Loss: 2.3236, Accuracy: 25.14%\n",
      "val Loss: 1.7596 Acc: 0.7829\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/640], Loss: 0.4294, Accuracy: 28.14%\n",
      "Epoch [89/100], Step [200/640], Loss: 0.4115, Accuracy: 29.00%\n",
      "Epoch [89/100], Step [300/640], Loss: 0.3211, Accuracy: 29.71%\n",
      "Epoch [89/100], Step [400/640], Loss: 0.3281, Accuracy: 28.71%\n",
      "Epoch [89/100], Step [500/640], Loss: 0.3584, Accuracy: 28.86%\n",
      "Epoch [89/100], Step [600/640], Loss: 0.2991, Accuracy: 29.29%\n",
      "train Loss: 0.4402 Acc: 0.8897\n",
      "Epoch [89/100], Step [100/640], Loss: 2.5444, Accuracy: 24.57%\n",
      "val Loss: 1.7986 Acc: 0.7840\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/640], Loss: 0.3274, Accuracy: 28.71%\n",
      "Epoch [90/100], Step [200/640], Loss: 0.4128, Accuracy: 28.14%\n",
      "Epoch [90/100], Step [300/640], Loss: 0.5247, Accuracy: 28.86%\n",
      "Epoch [90/100], Step [400/640], Loss: 0.3098, Accuracy: 29.57%\n",
      "Epoch [90/100], Step [500/640], Loss: 0.3498, Accuracy: 29.86%\n",
      "Epoch [90/100], Step [600/640], Loss: 0.3852, Accuracy: 27.71%\n",
      "train Loss: 0.4355 Acc: 0.8926\n",
      "Epoch [90/100], Step [100/640], Loss: 2.6015, Accuracy: 25.29%\n",
      "val Loss: 1.8610 Acc: 0.7886\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/640], Loss: 0.3541, Accuracy: 29.14%\n",
      "Epoch [91/100], Step [200/640], Loss: 0.5431, Accuracy: 28.29%\n",
      "Epoch [91/100], Step [300/640], Loss: 0.3610, Accuracy: 28.57%\n",
      "Epoch [91/100], Step [400/640], Loss: 0.4410, Accuracy: 28.57%\n",
      "Epoch [91/100], Step [500/640], Loss: 0.4578, Accuracy: 28.14%\n",
      "Epoch [91/100], Step [600/640], Loss: 0.4569, Accuracy: 28.43%\n",
      "train Loss: 0.4294 Acc: 0.8934\n",
      "Epoch [91/100], Step [100/640], Loss: 2.4884, Accuracy: 25.43%\n",
      "val Loss: 1.9268 Acc: 0.7914\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/640], Loss: 0.5313, Accuracy: 27.43%\n",
      "Epoch [92/100], Step [200/640], Loss: 0.4835, Accuracy: 29.14%\n",
      "Epoch [92/100], Step [300/640], Loss: 0.4558, Accuracy: 28.57%\n",
      "Epoch [92/100], Step [400/640], Loss: 0.4253, Accuracy: 28.29%\n",
      "Epoch [92/100], Step [500/640], Loss: 0.5717, Accuracy: 28.43%\n",
      "Epoch [92/100], Step [600/640], Loss: 0.3971, Accuracy: 28.57%\n",
      "train Loss: 0.4271 Acc: 0.8945\n",
      "Epoch [92/100], Step [100/640], Loss: 2.4450, Accuracy: 25.57%\n",
      "val Loss: 1.9410 Acc: 0.7854\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/640], Loss: 0.3194, Accuracy: 29.29%\n",
      "Epoch [93/100], Step [200/640], Loss: 0.2958, Accuracy: 29.29%\n",
      "Epoch [93/100], Step [300/640], Loss: 0.3882, Accuracy: 28.71%\n",
      "Epoch [93/100], Step [400/640], Loss: 0.5078, Accuracy: 28.00%\n",
      "Epoch [93/100], Step [500/640], Loss: 0.4816, Accuracy: 28.86%\n",
      "Epoch [93/100], Step [600/640], Loss: 0.4629, Accuracy: 28.14%\n",
      "train Loss: 0.4197 Acc: 0.8962\n",
      "Epoch [93/100], Step [100/640], Loss: 2.8055, Accuracy: 25.43%\n",
      "val Loss: 1.9396 Acc: 0.7873\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/640], Loss: 0.6283, Accuracy: 28.71%\n",
      "Epoch [94/100], Step [200/640], Loss: 0.4298, Accuracy: 28.43%\n",
      "Epoch [94/100], Step [300/640], Loss: 0.5610, Accuracy: 27.71%\n",
      "Epoch [94/100], Step [400/640], Loss: 0.3414, Accuracy: 29.43%\n",
      "Epoch [94/100], Step [500/640], Loss: 0.3782, Accuracy: 28.14%\n",
      "Epoch [94/100], Step [600/640], Loss: 0.3692, Accuracy: 28.71%\n",
      "train Loss: 0.4183 Acc: 0.8955\n",
      "Epoch [94/100], Step [100/640], Loss: 2.7241, Accuracy: 25.57%\n",
      "val Loss: 1.9556 Acc: 0.7890\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/640], Loss: 0.3422, Accuracy: 29.43%\n",
      "Epoch [95/100], Step [200/640], Loss: 0.2976, Accuracy: 29.29%\n",
      "Epoch [95/100], Step [300/640], Loss: 0.4088, Accuracy: 28.43%\n",
      "Epoch [95/100], Step [400/640], Loss: 0.3784, Accuracy: 28.86%\n",
      "Epoch [95/100], Step [500/640], Loss: 0.4061, Accuracy: 28.57%\n",
      "Epoch [95/100], Step [600/640], Loss: 0.4880, Accuracy: 28.43%\n",
      "train Loss: 0.4169 Acc: 0.8963\n",
      "Epoch [95/100], Step [100/640], Loss: 2.8070, Accuracy: 25.43%\n",
      "val Loss: 2.0257 Acc: 0.7907\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/640], Loss: 0.4801, Accuracy: 27.71%\n",
      "Epoch [96/100], Step [200/640], Loss: 0.3103, Accuracy: 29.29%\n",
      "Epoch [96/100], Step [300/640], Loss: 0.4508, Accuracy: 28.29%\n",
      "Epoch [96/100], Step [400/640], Loss: 0.3694, Accuracy: 29.14%\n",
      "Epoch [96/100], Step [500/640], Loss: 0.4606, Accuracy: 28.86%\n",
      "Epoch [96/100], Step [600/640], Loss: 0.4261, Accuracy: 28.43%\n",
      "train Loss: 0.4103 Acc: 0.8984\n",
      "Epoch [96/100], Step [100/640], Loss: 2.8946, Accuracy: 25.00%\n",
      "val Loss: 1.9045 Acc: 0.7839\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/640], Loss: 0.3902, Accuracy: 28.86%\n",
      "Epoch [97/100], Step [200/640], Loss: 0.3009, Accuracy: 30.14%\n",
      "Epoch [97/100], Step [300/640], Loss: 0.6031, Accuracy: 28.86%\n",
      "Epoch [97/100], Step [400/640], Loss: 0.3238, Accuracy: 29.00%\n",
      "Epoch [97/100], Step [500/640], Loss: 0.2183, Accuracy: 30.57%\n",
      "Epoch [97/100], Step [600/640], Loss: 0.5142, Accuracy: 28.14%\n",
      "train Loss: 0.4090 Acc: 0.8989\n",
      "Epoch [97/100], Step [100/640], Loss: 2.6960, Accuracy: 25.14%\n",
      "val Loss: 1.9331 Acc: 0.7856\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/640], Loss: 0.3076, Accuracy: 30.14%\n",
      "Epoch [98/100], Step [200/640], Loss: 0.4222, Accuracy: 28.00%\n",
      "Epoch [98/100], Step [300/640], Loss: 0.3853, Accuracy: 29.00%\n",
      "Epoch [98/100], Step [400/640], Loss: 0.4103, Accuracy: 28.29%\n",
      "Epoch [98/100], Step [500/640], Loss: 0.4369, Accuracy: 28.86%\n",
      "Epoch [98/100], Step [600/640], Loss: 0.3978, Accuracy: 29.14%\n",
      "train Loss: 0.4094 Acc: 0.8997\n",
      "Epoch [98/100], Step [100/640], Loss: 2.6998, Accuracy: 25.00%\n",
      "val Loss: 1.9820 Acc: 0.7889\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/640], Loss: 0.5140, Accuracy: 28.14%\n",
      "Epoch [99/100], Step [200/640], Loss: 0.4237, Accuracy: 27.57%\n",
      "Epoch [99/100], Step [300/640], Loss: 0.3220, Accuracy: 30.00%\n",
      "Epoch [99/100], Step [400/640], Loss: 0.3598, Accuracy: 28.57%\n",
      "Epoch [99/100], Step [500/640], Loss: 0.3785, Accuracy: 28.86%\n",
      "Epoch [99/100], Step [600/640], Loss: 0.4475, Accuracy: 29.29%\n",
      "train Loss: 0.4043 Acc: 0.8997\n",
      "Epoch [99/100], Step [100/640], Loss: 2.7354, Accuracy: 25.00%\n",
      "val Loss: 1.9930 Acc: 0.7885\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/640], Loss: 0.4250, Accuracy: 29.00%\n",
      "Epoch [100/100], Step [200/640], Loss: 0.3631, Accuracy: 28.71%\n",
      "Epoch [100/100], Step [300/640], Loss: 0.3399, Accuracy: 29.29%\n",
      "Epoch [100/100], Step [400/640], Loss: 0.5111, Accuracy: 28.29%\n",
      "Epoch [100/100], Step [500/640], Loss: 0.3455, Accuracy: 29.57%\n",
      "Epoch [100/100], Step [600/640], Loss: 0.3950, Accuracy: 28.86%\n",
      "train Loss: 0.3962 Acc: 0.9010\n",
      "Epoch [100/100], Step [100/640], Loss: 2.7508, Accuracy: 25.43%\n",
      "val Loss: 2.0668 Acc: 0.7897\n",
      "\n",
      "Training complete in 230m 20s\n",
      "Best val Acc: 0.774724\n",
      "Best loss: 0.910770\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'chest_xray_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.77413485079071\n",
      "f1: 0.4459599730627861\n",
      "cm: [[[2708  565]\n",
      "  [ 326  719]]\n",
      "\n",
      " [[2864  409]\n",
      "  [ 403  642]]\n",
      "\n",
      " [[2946  813]\n",
      "  [ 228  331]]\n",
      "\n",
      " [[2982  681]\n",
      "  [ 387  268]]\n",
      "\n",
      " [[2695  576]\n",
      "  [ 552  495]]\n",
      "\n",
      " [[3250  623]\n",
      "  [ 228  217]]\n",
      "\n",
      " [[2986  866]\n",
      "  [ 170  296]]]\n",
      "outputs: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "targets: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
