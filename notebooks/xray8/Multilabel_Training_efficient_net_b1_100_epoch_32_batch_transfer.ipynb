{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/xray8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"efficient_net_b1\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 7\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=([0.4955, 0.4955, 0.4955], [0.2892, 0.2892, 0.2892])\n",
    "\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = models.EfficientNet_B1_Weights.IMAGENET1K_V2\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([2., 3., 6., 6., 3., 7., 9.], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Effusion',\n",
       " 'No Finding',\n",
       " 'Mass',\n",
       " 'Nodule',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Consolidation']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/640], Loss: 1.0226, Accuracy: 23.86%\n",
      "Epoch [1/100], Step [200/640], Loss: 0.9773, Accuracy: 26.57%\n",
      "Epoch [1/100], Step [300/640], Loss: 1.0589, Accuracy: 25.00%\n",
      "Epoch [1/100], Step [400/640], Loss: 0.9933, Accuracy: 25.00%\n",
      "Epoch [1/100], Step [500/640], Loss: 1.0031, Accuracy: 26.29%\n",
      "Epoch [1/100], Step [600/640], Loss: 0.9915, Accuracy: 26.00%\n",
      "train Loss: 1.0627 Acc: 0.7653\n",
      "Epoch [1/100], Step [100/640], Loss: 1.0960, Accuracy: 23.57%\n",
      "val Loss: 1.0312 Acc: 0.7583\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/640], Loss: 0.9515, Accuracy: 24.71%\n",
      "Epoch [2/100], Step [200/640], Loss: 0.8658, Accuracy: 27.29%\n",
      "Epoch [2/100], Step [300/640], Loss: 1.1604, Accuracy: 24.00%\n",
      "Epoch [2/100], Step [400/640], Loss: 1.0854, Accuracy: 23.57%\n",
      "Epoch [2/100], Step [500/640], Loss: 0.9846, Accuracy: 24.86%\n",
      "Epoch [2/100], Step [600/640], Loss: 0.9398, Accuracy: 24.71%\n",
      "train Loss: 1.0172 Acc: 0.7724\n",
      "Epoch [2/100], Step [100/640], Loss: 1.1210, Accuracy: 22.86%\n",
      "val Loss: 1.0373 Acc: 0.7425\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/640], Loss: 0.9452, Accuracy: 25.43%\n",
      "Epoch [3/100], Step [200/640], Loss: 1.0519, Accuracy: 24.57%\n",
      "Epoch [3/100], Step [300/640], Loss: 1.1101, Accuracy: 25.57%\n",
      "Epoch [3/100], Step [400/640], Loss: 0.9764, Accuracy: 24.71%\n",
      "Epoch [3/100], Step [500/640], Loss: 0.9155, Accuracy: 24.57%\n",
      "Epoch [3/100], Step [600/640], Loss: 0.9491, Accuracy: 24.43%\n",
      "train Loss: 0.9998 Acc: 0.7736\n",
      "Epoch [3/100], Step [100/640], Loss: 1.0777, Accuracy: 25.14%\n",
      "val Loss: 1.0203 Acc: 0.7108\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/640], Loss: 0.9324, Accuracy: 26.14%\n",
      "Epoch [4/100], Step [200/640], Loss: 0.9814, Accuracy: 25.43%\n",
      "Epoch [4/100], Step [300/640], Loss: 0.9260, Accuracy: 24.57%\n",
      "Epoch [4/100], Step [400/640], Loss: 1.0394, Accuracy: 24.00%\n",
      "Epoch [4/100], Step [500/640], Loss: 0.8729, Accuracy: 24.86%\n",
      "Epoch [4/100], Step [600/640], Loss: 0.9676, Accuracy: 24.86%\n",
      "train Loss: 0.9853 Acc: 0.7742\n",
      "Epoch [4/100], Step [100/640], Loss: 1.3050, Accuracy: 23.71%\n",
      "val Loss: 1.0128 Acc: 0.8082\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/640], Loss: 1.0957, Accuracy: 22.86%\n",
      "Epoch [5/100], Step [200/640], Loss: 1.0269, Accuracy: 25.71%\n",
      "Epoch [5/100], Step [300/640], Loss: 0.8185, Accuracy: 25.86%\n",
      "Epoch [5/100], Step [400/640], Loss: 0.9499, Accuracy: 24.86%\n",
      "Epoch [5/100], Step [500/640], Loss: 0.8982, Accuracy: 24.71%\n",
      "Epoch [5/100], Step [600/640], Loss: 0.9193, Accuracy: 25.00%\n",
      "train Loss: 0.9734 Acc: 0.7773\n",
      "Epoch [5/100], Step [100/640], Loss: 1.1982, Accuracy: 25.29%\n",
      "val Loss: 0.9629 Acc: 0.8102\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/640], Loss: 0.8866, Accuracy: 26.57%\n",
      "Epoch [6/100], Step [200/640], Loss: 0.9393, Accuracy: 25.71%\n",
      "Epoch [6/100], Step [300/640], Loss: 0.9560, Accuracy: 23.86%\n",
      "Epoch [6/100], Step [400/640], Loss: 0.9091, Accuracy: 24.86%\n",
      "Epoch [6/100], Step [500/640], Loss: 0.9488, Accuracy: 25.86%\n",
      "Epoch [6/100], Step [600/640], Loss: 0.8654, Accuracy: 25.43%\n",
      "train Loss: 0.9612 Acc: 0.7782\n",
      "Epoch [6/100], Step [100/640], Loss: 1.0627, Accuracy: 23.00%\n",
      "val Loss: 0.9698 Acc: 0.7292\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/640], Loss: 0.9105, Accuracy: 24.86%\n",
      "Epoch [7/100], Step [200/640], Loss: 0.8695, Accuracy: 26.71%\n",
      "Epoch [7/100], Step [300/640], Loss: 0.9201, Accuracy: 25.43%\n",
      "Epoch [7/100], Step [400/640], Loss: 0.9793, Accuracy: 25.14%\n",
      "Epoch [7/100], Step [500/640], Loss: 1.0065, Accuracy: 24.29%\n",
      "Epoch [7/100], Step [600/640], Loss: 0.8053, Accuracy: 26.57%\n",
      "train Loss: 0.9539 Acc: 0.7792\n",
      "Epoch [7/100], Step [100/640], Loss: 1.0894, Accuracy: 25.29%\n",
      "val Loss: 0.9315 Acc: 0.7979\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/640], Loss: 0.8251, Accuracy: 25.86%\n",
      "Epoch [8/100], Step [200/640], Loss: 0.8273, Accuracy: 25.86%\n",
      "Epoch [8/100], Step [300/640], Loss: 0.8382, Accuracy: 26.57%\n",
      "Epoch [8/100], Step [400/640], Loss: 1.2063, Accuracy: 22.71%\n",
      "Epoch [8/100], Step [500/640], Loss: 1.0625, Accuracy: 24.71%\n",
      "Epoch [8/100], Step [600/640], Loss: 0.9438, Accuracy: 25.57%\n",
      "train Loss: 0.9401 Acc: 0.7837\n",
      "Epoch [8/100], Step [100/640], Loss: 1.2341, Accuracy: 24.00%\n",
      "val Loss: 0.9517 Acc: 0.7854\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/640], Loss: 0.9510, Accuracy: 25.29%\n",
      "Epoch [9/100], Step [200/640], Loss: 0.9900, Accuracy: 24.86%\n",
      "Epoch [9/100], Step [300/640], Loss: 0.9879, Accuracy: 24.57%\n",
      "Epoch [9/100], Step [400/640], Loss: 0.9571, Accuracy: 24.71%\n",
      "Epoch [9/100], Step [500/640], Loss: 0.9655, Accuracy: 24.29%\n",
      "Epoch [9/100], Step [600/640], Loss: 0.9739, Accuracy: 25.00%\n",
      "train Loss: 0.9344 Acc: 0.7844\n",
      "Epoch [9/100], Step [100/640], Loss: 0.9966, Accuracy: 25.00%\n",
      "val Loss: 0.9900 Acc: 0.7508\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/640], Loss: 0.9710, Accuracy: 24.57%\n",
      "Epoch [10/100], Step [200/640], Loss: 0.7891, Accuracy: 25.71%\n",
      "Epoch [10/100], Step [300/640], Loss: 0.9162, Accuracy: 25.29%\n",
      "Epoch [10/100], Step [400/640], Loss: 1.0781, Accuracy: 24.71%\n",
      "Epoch [10/100], Step [500/640], Loss: 0.9385, Accuracy: 25.86%\n",
      "Epoch [10/100], Step [600/640], Loss: 1.0025, Accuracy: 24.43%\n",
      "train Loss: 0.9284 Acc: 0.7849\n",
      "Epoch [10/100], Step [100/640], Loss: 1.0637, Accuracy: 26.00%\n",
      "val Loss: 0.9625 Acc: 0.7970\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/640], Loss: 0.9498, Accuracy: 23.57%\n",
      "Epoch [11/100], Step [200/640], Loss: 1.0283, Accuracy: 23.57%\n",
      "Epoch [11/100], Step [300/640], Loss: 1.0893, Accuracy: 24.86%\n",
      "Epoch [11/100], Step [400/640], Loss: 0.9405, Accuracy: 25.00%\n",
      "Epoch [11/100], Step [500/640], Loss: 0.8420, Accuracy: 25.86%\n",
      "Epoch [11/100], Step [600/640], Loss: 0.8790, Accuracy: 25.71%\n",
      "train Loss: 0.9217 Acc: 0.7894\n",
      "Epoch [11/100], Step [100/640], Loss: 1.0562, Accuracy: 24.14%\n",
      "val Loss: 0.9404 Acc: 0.7870\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/640], Loss: 0.7934, Accuracy: 25.29%\n",
      "Epoch [12/100], Step [200/640], Loss: 0.9542, Accuracy: 23.86%\n",
      "Epoch [12/100], Step [300/640], Loss: 1.0534, Accuracy: 24.14%\n",
      "Epoch [12/100], Step [400/640], Loss: 1.0452, Accuracy: 24.71%\n",
      "Epoch [12/100], Step [500/640], Loss: 0.9102, Accuracy: 25.71%\n",
      "Epoch [12/100], Step [600/640], Loss: 0.8517, Accuracy: 26.43%\n",
      "train Loss: 0.9113 Acc: 0.7923\n",
      "Epoch [12/100], Step [100/640], Loss: 1.0017, Accuracy: 25.14%\n",
      "val Loss: 0.9277 Acc: 0.7807\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/640], Loss: 0.8299, Accuracy: 25.29%\n",
      "Epoch [13/100], Step [200/640], Loss: 0.8021, Accuracy: 24.86%\n",
      "Epoch [13/100], Step [300/640], Loss: 0.8251, Accuracy: 25.29%\n",
      "Epoch [13/100], Step [400/640], Loss: 0.7990, Accuracy: 26.71%\n",
      "Epoch [13/100], Step [500/640], Loss: 0.9964, Accuracy: 24.14%\n",
      "Epoch [13/100], Step [600/640], Loss: 0.9543, Accuracy: 25.00%\n",
      "train Loss: 0.9073 Acc: 0.7908\n",
      "Epoch [13/100], Step [100/640], Loss: 0.9422, Accuracy: 24.86%\n",
      "val Loss: 0.9123 Acc: 0.7945\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/640], Loss: 0.9644, Accuracy: 25.57%\n",
      "Epoch [14/100], Step [200/640], Loss: 0.9692, Accuracy: 25.71%\n",
      "Epoch [14/100], Step [300/640], Loss: 0.9842, Accuracy: 24.14%\n",
      "Epoch [14/100], Step [400/640], Loss: 0.7691, Accuracy: 25.29%\n",
      "Epoch [14/100], Step [500/640], Loss: 0.7417, Accuracy: 26.29%\n",
      "Epoch [14/100], Step [600/640], Loss: 0.8835, Accuracy: 25.71%\n",
      "train Loss: 0.8946 Acc: 0.7953\n",
      "Epoch [14/100], Step [100/640], Loss: 0.8311, Accuracy: 26.43%\n",
      "val Loss: 0.9439 Acc: 0.7827\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/640], Loss: 0.7889, Accuracy: 25.86%\n",
      "Epoch [15/100], Step [200/640], Loss: 0.8309, Accuracy: 25.00%\n",
      "Epoch [15/100], Step [300/640], Loss: 0.8797, Accuracy: 25.43%\n",
      "Epoch [15/100], Step [400/640], Loss: 0.8532, Accuracy: 25.43%\n",
      "Epoch [15/100], Step [500/640], Loss: 0.8162, Accuracy: 26.00%\n",
      "Epoch [15/100], Step [600/640], Loss: 0.8733, Accuracy: 24.14%\n",
      "train Loss: 0.8883 Acc: 0.7967\n",
      "Epoch [15/100], Step [100/640], Loss: 1.0776, Accuracy: 25.29%\n",
      "val Loss: 0.9088 Acc: 0.8003\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/640], Loss: 1.0123, Accuracy: 25.43%\n",
      "Epoch [16/100], Step [200/640], Loss: 0.8721, Accuracy: 26.57%\n",
      "Epoch [16/100], Step [300/640], Loss: 0.8179, Accuracy: 26.14%\n",
      "Epoch [16/100], Step [400/640], Loss: 0.7685, Accuracy: 26.71%\n",
      "Epoch [16/100], Step [500/640], Loss: 0.9408, Accuracy: 24.71%\n",
      "Epoch [16/100], Step [600/640], Loss: 0.8377, Accuracy: 26.43%\n",
      "train Loss: 0.8812 Acc: 0.7975\n",
      "Epoch [16/100], Step [100/640], Loss: 1.0494, Accuracy: 26.00%\n",
      "val Loss: 0.9046 Acc: 0.8054\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/640], Loss: 0.8837, Accuracy: 25.00%\n",
      "Epoch [17/100], Step [200/640], Loss: 0.8200, Accuracy: 25.71%\n",
      "Epoch [17/100], Step [300/640], Loss: 0.8925, Accuracy: 27.14%\n",
      "Epoch [17/100], Step [400/640], Loss: 0.9618, Accuracy: 25.29%\n",
      "Epoch [17/100], Step [500/640], Loss: 0.8051, Accuracy: 26.00%\n",
      "Epoch [17/100], Step [600/640], Loss: 0.9173, Accuracy: 24.71%\n",
      "train Loss: 0.8805 Acc: 0.7976\n",
      "Epoch [17/100], Step [100/640], Loss: 1.1234, Accuracy: 25.29%\n",
      "val Loss: 0.9172 Acc: 0.7891\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/640], Loss: 0.9142, Accuracy: 25.43%\n",
      "Epoch [18/100], Step [200/640], Loss: 0.9222, Accuracy: 25.29%\n",
      "Epoch [18/100], Step [300/640], Loss: 0.8568, Accuracy: 25.86%\n",
      "Epoch [18/100], Step [400/640], Loss: 1.0004, Accuracy: 25.86%\n",
      "Epoch [18/100], Step [500/640], Loss: 0.8593, Accuracy: 25.14%\n",
      "Epoch [18/100], Step [600/640], Loss: 0.9323, Accuracy: 25.86%\n",
      "train Loss: 0.8720 Acc: 0.7992\n",
      "Epoch [18/100], Step [100/640], Loss: 1.0674, Accuracy: 24.57%\n",
      "val Loss: 0.9349 Acc: 0.7840\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/640], Loss: 0.9568, Accuracy: 24.43%\n",
      "Epoch [19/100], Step [200/640], Loss: 0.7256, Accuracy: 26.43%\n",
      "Epoch [19/100], Step [300/640], Loss: 0.7448, Accuracy: 26.29%\n",
      "Epoch [19/100], Step [400/640], Loss: 0.8299, Accuracy: 24.86%\n",
      "Epoch [19/100], Step [500/640], Loss: 0.7672, Accuracy: 26.00%\n",
      "Epoch [19/100], Step [600/640], Loss: 0.8022, Accuracy: 26.14%\n",
      "train Loss: 0.8643 Acc: 0.7997\n",
      "Epoch [19/100], Step [100/640], Loss: 0.9109, Accuracy: 25.71%\n",
      "val Loss: 0.9074 Acc: 0.8151\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/640], Loss: 0.9649, Accuracy: 25.29%\n",
      "Epoch [20/100], Step [200/640], Loss: 0.8237, Accuracy: 27.00%\n",
      "Epoch [20/100], Step [300/640], Loss: 0.8794, Accuracy: 25.14%\n",
      "Epoch [20/100], Step [400/640], Loss: 0.7830, Accuracy: 25.57%\n",
      "Epoch [20/100], Step [500/640], Loss: 0.8102, Accuracy: 26.14%\n",
      "Epoch [20/100], Step [600/640], Loss: 0.7318, Accuracy: 26.43%\n",
      "train Loss: 0.8534 Acc: 0.8032\n",
      "Epoch [20/100], Step [100/640], Loss: 1.1414, Accuracy: 24.29%\n",
      "val Loss: 0.9424 Acc: 0.7813\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/640], Loss: 0.7347, Accuracy: 25.86%\n",
      "Epoch [21/100], Step [200/640], Loss: 0.8064, Accuracy: 26.14%\n",
      "Epoch [21/100], Step [300/640], Loss: 0.8162, Accuracy: 25.86%\n",
      "Epoch [21/100], Step [400/640], Loss: 0.7880, Accuracy: 26.00%\n",
      "Epoch [21/100], Step [500/640], Loss: 1.0873, Accuracy: 24.29%\n",
      "Epoch [21/100], Step [600/640], Loss: 0.8204, Accuracy: 25.29%\n",
      "train Loss: 0.8463 Acc: 0.8059\n",
      "Epoch [21/100], Step [100/640], Loss: 1.0983, Accuracy: 25.43%\n",
      "val Loss: 0.8926 Acc: 0.7955\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/640], Loss: 0.9576, Accuracy: 25.43%\n",
      "Epoch [22/100], Step [200/640], Loss: 0.7728, Accuracy: 25.57%\n",
      "Epoch [22/100], Step [300/640], Loss: 1.0909, Accuracy: 23.86%\n",
      "Epoch [22/100], Step [400/640], Loss: 0.7790, Accuracy: 26.14%\n",
      "Epoch [22/100], Step [500/640], Loss: 0.7224, Accuracy: 27.57%\n",
      "Epoch [22/100], Step [600/640], Loss: 0.7901, Accuracy: 27.00%\n",
      "train Loss: 0.8402 Acc: 0.8066\n",
      "Epoch [22/100], Step [100/640], Loss: 0.9121, Accuracy: 22.71%\n",
      "val Loss: 1.0073 Acc: 0.6901\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/640], Loss: 0.8094, Accuracy: 26.00%\n",
      "Epoch [23/100], Step [200/640], Loss: 0.7481, Accuracy: 26.71%\n",
      "Epoch [23/100], Step [300/640], Loss: 0.9086, Accuracy: 24.29%\n",
      "Epoch [23/100], Step [400/640], Loss: 0.7397, Accuracy: 27.14%\n",
      "Epoch [23/100], Step [500/640], Loss: 0.9136, Accuracy: 26.29%\n",
      "Epoch [23/100], Step [600/640], Loss: 0.8613, Accuracy: 24.00%\n",
      "train Loss: 0.8336 Acc: 0.8069\n",
      "Epoch [23/100], Step [100/640], Loss: 1.0786, Accuracy: 26.00%\n",
      "val Loss: 0.9127 Acc: 0.8043\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/640], Loss: 0.8865, Accuracy: 25.57%\n",
      "Epoch [24/100], Step [200/640], Loss: 0.8862, Accuracy: 25.14%\n",
      "Epoch [24/100], Step [300/640], Loss: 0.7987, Accuracy: 25.71%\n",
      "Epoch [24/100], Step [400/640], Loss: 0.9812, Accuracy: 25.00%\n",
      "Epoch [24/100], Step [500/640], Loss: 0.7588, Accuracy: 25.14%\n",
      "Epoch [24/100], Step [600/640], Loss: 0.9889, Accuracy: 25.14%\n",
      "train Loss: 0.8225 Acc: 0.8082\n",
      "Epoch [24/100], Step [100/640], Loss: 0.9408, Accuracy: 25.57%\n",
      "val Loss: 0.9136 Acc: 0.7938\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/640], Loss: 0.8399, Accuracy: 26.43%\n",
      "Epoch [25/100], Step [200/640], Loss: 0.8547, Accuracy: 24.29%\n",
      "Epoch [25/100], Step [300/640], Loss: 0.7825, Accuracy: 26.43%\n",
      "Epoch [25/100], Step [400/640], Loss: 0.7410, Accuracy: 26.14%\n",
      "Epoch [25/100], Step [500/640], Loss: 0.7772, Accuracy: 26.14%\n",
      "Epoch [25/100], Step [600/640], Loss: 0.9175, Accuracy: 26.86%\n",
      "train Loss: 0.8180 Acc: 0.8103\n",
      "Epoch [25/100], Step [100/640], Loss: 0.9220, Accuracy: 25.86%\n",
      "val Loss: 0.9116 Acc: 0.7969\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/640], Loss: 0.7527, Accuracy: 26.57%\n",
      "Epoch [26/100], Step [200/640], Loss: 0.8581, Accuracy: 25.86%\n",
      "Epoch [26/100], Step [300/640], Loss: 0.9832, Accuracy: 25.57%\n",
      "Epoch [26/100], Step [400/640], Loss: 0.9638, Accuracy: 25.43%\n",
      "Epoch [26/100], Step [500/640], Loss: 0.9053, Accuracy: 25.14%\n",
      "Epoch [26/100], Step [600/640], Loss: 0.7024, Accuracy: 27.71%\n",
      "train Loss: 0.8052 Acc: 0.8119\n",
      "Epoch [26/100], Step [100/640], Loss: 0.8638, Accuracy: 26.14%\n",
      "val Loss: 0.9191 Acc: 0.7761\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/640], Loss: 0.6999, Accuracy: 26.43%\n",
      "Epoch [27/100], Step [200/640], Loss: 0.6521, Accuracy: 27.29%\n",
      "Epoch [27/100], Step [300/640], Loss: 0.7847, Accuracy: 24.86%\n",
      "Epoch [27/100], Step [400/640], Loss: 0.8900, Accuracy: 26.00%\n",
      "Epoch [27/100], Step [500/640], Loss: 0.9388, Accuracy: 24.29%\n",
      "Epoch [27/100], Step [600/640], Loss: 0.8721, Accuracy: 26.14%\n",
      "train Loss: 0.7980 Acc: 0.8142\n",
      "Epoch [27/100], Step [100/640], Loss: 1.1092, Accuracy: 25.43%\n",
      "val Loss: 0.9167 Acc: 0.7946\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/640], Loss: 0.9869, Accuracy: 25.43%\n",
      "Epoch [28/100], Step [200/640], Loss: 0.7093, Accuracy: 26.57%\n",
      "Epoch [28/100], Step [300/640], Loss: 0.7056, Accuracy: 26.14%\n",
      "Epoch [28/100], Step [400/640], Loss: 0.6494, Accuracy: 26.86%\n",
      "Epoch [28/100], Step [500/640], Loss: 0.8672, Accuracy: 24.71%\n",
      "Epoch [28/100], Step [600/640], Loss: 0.8735, Accuracy: 25.86%\n",
      "train Loss: 0.7837 Acc: 0.8156\n",
      "Epoch [28/100], Step [100/640], Loss: 0.9612, Accuracy: 25.29%\n",
      "val Loss: 0.9455 Acc: 0.7895\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/640], Loss: 0.5493, Accuracy: 27.86%\n",
      "Epoch [29/100], Step [200/640], Loss: 0.7574, Accuracy: 26.57%\n",
      "Epoch [29/100], Step [300/640], Loss: 0.7832, Accuracy: 26.14%\n",
      "Epoch [29/100], Step [400/640], Loss: 0.8617, Accuracy: 26.00%\n",
      "Epoch [29/100], Step [500/640], Loss: 0.8030, Accuracy: 26.14%\n",
      "Epoch [29/100], Step [600/640], Loss: 0.8545, Accuracy: 26.14%\n",
      "train Loss: 0.7804 Acc: 0.8178\n",
      "Epoch [29/100], Step [100/640], Loss: 1.0325, Accuracy: 25.43%\n",
      "val Loss: 0.9269 Acc: 0.7954\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/640], Loss: 0.7810, Accuracy: 26.57%\n",
      "Epoch [30/100], Step [200/640], Loss: 0.8214, Accuracy: 25.71%\n",
      "Epoch [30/100], Step [300/640], Loss: 0.6623, Accuracy: 26.86%\n",
      "Epoch [30/100], Step [400/640], Loss: 0.7114, Accuracy: 26.43%\n",
      "Epoch [30/100], Step [500/640], Loss: 0.9507, Accuracy: 24.71%\n",
      "Epoch [30/100], Step [600/640], Loss: 0.7952, Accuracy: 25.43%\n",
      "train Loss: 0.7656 Acc: 0.8193\n",
      "Epoch [30/100], Step [100/640], Loss: 1.1689, Accuracy: 25.86%\n",
      "val Loss: 0.9585 Acc: 0.7987\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/640], Loss: 0.6997, Accuracy: 26.71%\n",
      "Epoch [31/100], Step [200/640], Loss: 0.7414, Accuracy: 25.43%\n",
      "Epoch [31/100], Step [300/640], Loss: 0.7223, Accuracy: 25.29%\n",
      "Epoch [31/100], Step [400/640], Loss: 0.6580, Accuracy: 26.29%\n",
      "Epoch [31/100], Step [500/640], Loss: 0.9019, Accuracy: 25.86%\n",
      "Epoch [31/100], Step [600/640], Loss: 0.9380, Accuracy: 24.57%\n",
      "train Loss: 0.7574 Acc: 0.8210\n",
      "Epoch [31/100], Step [100/640], Loss: 1.1760, Accuracy: 25.43%\n",
      "val Loss: 0.9296 Acc: 0.7924\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/640], Loss: 0.7457, Accuracy: 26.86%\n",
      "Epoch [32/100], Step [200/640], Loss: 0.7154, Accuracy: 27.29%\n",
      "Epoch [32/100], Step [300/640], Loss: 0.6330, Accuracy: 26.00%\n",
      "Epoch [32/100], Step [400/640], Loss: 0.7233, Accuracy: 26.43%\n",
      "Epoch [32/100], Step [500/640], Loss: 0.6623, Accuracy: 27.00%\n",
      "Epoch [32/100], Step [600/640], Loss: 0.8220, Accuracy: 26.43%\n",
      "train Loss: 0.7481 Acc: 0.8231\n",
      "Epoch [32/100], Step [100/640], Loss: 0.9809, Accuracy: 25.71%\n",
      "val Loss: 0.9372 Acc: 0.7798\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/640], Loss: 0.8001, Accuracy: 24.86%\n",
      "Epoch [33/100], Step [200/640], Loss: 0.6566, Accuracy: 26.57%\n",
      "Epoch [33/100], Step [300/640], Loss: 0.7326, Accuracy: 26.14%\n",
      "Epoch [33/100], Step [400/640], Loss: 0.8171, Accuracy: 26.43%\n",
      "Epoch [33/100], Step [500/640], Loss: 0.8152, Accuracy: 26.00%\n",
      "Epoch [33/100], Step [600/640], Loss: 0.6598, Accuracy: 27.29%\n",
      "train Loss: 0.7373 Acc: 0.8257\n",
      "Epoch [33/100], Step [100/640], Loss: 0.8261, Accuracy: 26.86%\n",
      "val Loss: 0.9669 Acc: 0.7876\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/640], Loss: 0.7480, Accuracy: 27.29%\n",
      "Epoch [34/100], Step [200/640], Loss: 0.6167, Accuracy: 27.14%\n",
      "Epoch [34/100], Step [300/640], Loss: 0.5433, Accuracy: 28.71%\n",
      "Epoch [34/100], Step [400/640], Loss: 0.7850, Accuracy: 25.71%\n",
      "Epoch [34/100], Step [500/640], Loss: 0.6758, Accuracy: 27.00%\n",
      "Epoch [34/100], Step [600/640], Loss: 0.7018, Accuracy: 26.57%\n",
      "train Loss: 0.7274 Acc: 0.8277\n",
      "Epoch [34/100], Step [100/640], Loss: 1.0051, Accuracy: 25.86%\n",
      "val Loss: 0.9923 Acc: 0.7968\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/640], Loss: 0.6451, Accuracy: 27.29%\n",
      "Epoch [35/100], Step [200/640], Loss: 0.7392, Accuracy: 26.29%\n",
      "Epoch [35/100], Step [300/640], Loss: 0.6737, Accuracy: 26.29%\n",
      "Epoch [35/100], Step [400/640], Loss: 0.9018, Accuracy: 25.57%\n",
      "Epoch [35/100], Step [500/640], Loss: 0.5953, Accuracy: 27.14%\n",
      "Epoch [35/100], Step [600/640], Loss: 0.6883, Accuracy: 26.71%\n",
      "train Loss: 0.7152 Acc: 0.8303\n",
      "Epoch [35/100], Step [100/640], Loss: 0.8663, Accuracy: 25.86%\n",
      "val Loss: 0.9962 Acc: 0.7799\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/640], Loss: 0.9150, Accuracy: 25.43%\n",
      "Epoch [36/100], Step [200/640], Loss: 0.7458, Accuracy: 25.71%\n",
      "Epoch [36/100], Step [300/640], Loss: 0.7211, Accuracy: 27.00%\n",
      "Epoch [36/100], Step [400/640], Loss: 0.7437, Accuracy: 26.43%\n",
      "Epoch [36/100], Step [500/640], Loss: 0.6306, Accuracy: 26.71%\n",
      "Epoch [36/100], Step [600/640], Loss: 0.8523, Accuracy: 24.14%\n",
      "train Loss: 0.7055 Acc: 0.8312\n",
      "Epoch [36/100], Step [100/640], Loss: 0.7864, Accuracy: 26.29%\n",
      "val Loss: 0.9809 Acc: 0.7627\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/640], Loss: 0.5814, Accuracy: 27.57%\n",
      "Epoch [37/100], Step [200/640], Loss: 0.8968, Accuracy: 25.86%\n",
      "Epoch [37/100], Step [300/640], Loss: 0.5773, Accuracy: 27.57%\n",
      "Epoch [37/100], Step [400/640], Loss: 0.6616, Accuracy: 27.86%\n",
      "Epoch [37/100], Step [500/640], Loss: 0.7852, Accuracy: 25.00%\n",
      "Epoch [37/100], Step [600/640], Loss: 0.9141, Accuracy: 26.14%\n",
      "train Loss: 0.6915 Acc: 0.8338\n",
      "Epoch [37/100], Step [100/640], Loss: 1.0223, Accuracy: 26.14%\n",
      "val Loss: 1.0238 Acc: 0.7966\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/640], Loss: 0.4971, Accuracy: 28.14%\n",
      "Epoch [38/100], Step [200/640], Loss: 0.5935, Accuracy: 27.29%\n",
      "Epoch [38/100], Step [300/640], Loss: 0.6909, Accuracy: 26.29%\n",
      "Epoch [38/100], Step [400/640], Loss: 0.6625, Accuracy: 26.14%\n",
      "Epoch [38/100], Step [500/640], Loss: 0.6739, Accuracy: 26.43%\n",
      "Epoch [38/100], Step [600/640], Loss: 0.6019, Accuracy: 27.29%\n",
      "train Loss: 0.6762 Acc: 0.8377\n",
      "Epoch [38/100], Step [100/640], Loss: 1.0538, Accuracy: 25.43%\n",
      "val Loss: 1.0109 Acc: 0.7791\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/640], Loss: 0.5705, Accuracy: 28.00%\n",
      "Epoch [39/100], Step [200/640], Loss: 0.5201, Accuracy: 27.29%\n",
      "Epoch [39/100], Step [300/640], Loss: 0.5642, Accuracy: 27.57%\n",
      "Epoch [39/100], Step [400/640], Loss: 0.5540, Accuracy: 28.00%\n",
      "Epoch [39/100], Step [500/640], Loss: 0.6636, Accuracy: 27.86%\n",
      "Epoch [39/100], Step [600/640], Loss: 0.7900, Accuracy: 26.29%\n",
      "train Loss: 0.6677 Acc: 0.8398\n",
      "Epoch [39/100], Step [100/640], Loss: 1.2639, Accuracy: 25.14%\n",
      "val Loss: 1.0358 Acc: 0.7923\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/640], Loss: 0.6351, Accuracy: 27.14%\n",
      "Epoch [40/100], Step [200/640], Loss: 0.5469, Accuracy: 28.00%\n",
      "Epoch [40/100], Step [300/640], Loss: 0.6297, Accuracy: 27.57%\n",
      "Epoch [40/100], Step [400/640], Loss: 0.6909, Accuracy: 26.86%\n",
      "Epoch [40/100], Step [500/640], Loss: 0.5848, Accuracy: 27.29%\n",
      "Epoch [40/100], Step [600/640], Loss: 0.5696, Accuracy: 27.57%\n",
      "train Loss: 0.6584 Acc: 0.8424\n",
      "Epoch [40/100], Step [100/640], Loss: 1.1759, Accuracy: 24.86%\n",
      "val Loss: 1.0682 Acc: 0.7839\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/640], Loss: 0.7205, Accuracy: 26.43%\n",
      "Epoch [41/100], Step [200/640], Loss: 0.6503, Accuracy: 27.57%\n",
      "Epoch [41/100], Step [300/640], Loss: 0.4669, Accuracy: 28.71%\n",
      "Epoch [41/100], Step [400/640], Loss: 0.6984, Accuracy: 27.29%\n",
      "Epoch [41/100], Step [500/640], Loss: 0.6522, Accuracy: 25.86%\n",
      "Epoch [41/100], Step [600/640], Loss: 0.6722, Accuracy: 27.14%\n",
      "train Loss: 0.6478 Acc: 0.8451\n",
      "Epoch [41/100], Step [100/640], Loss: 1.2540, Accuracy: 25.43%\n",
      "val Loss: 1.0695 Acc: 0.8006\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/640], Loss: 0.7114, Accuracy: 27.29%\n",
      "Epoch [42/100], Step [200/640], Loss: 0.8625, Accuracy: 25.86%\n",
      "Epoch [42/100], Step [300/640], Loss: 0.6177, Accuracy: 27.57%\n",
      "Epoch [42/100], Step [400/640], Loss: 0.5417, Accuracy: 28.00%\n",
      "Epoch [42/100], Step [500/640], Loss: 0.6954, Accuracy: 27.71%\n",
      "Epoch [42/100], Step [600/640], Loss: 0.7669, Accuracy: 24.86%\n",
      "train Loss: 0.6325 Acc: 0.8474\n",
      "Epoch [42/100], Step [100/640], Loss: 1.2348, Accuracy: 25.43%\n",
      "val Loss: 1.1300 Acc: 0.7968\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/640], Loss: 0.6566, Accuracy: 27.43%\n",
      "Epoch [43/100], Step [200/640], Loss: 0.4871, Accuracy: 28.29%\n",
      "Epoch [43/100], Step [300/640], Loss: 0.6446, Accuracy: 27.57%\n",
      "Epoch [43/100], Step [400/640], Loss: 0.6035, Accuracy: 28.00%\n",
      "Epoch [43/100], Step [500/640], Loss: 0.4316, Accuracy: 29.43%\n",
      "Epoch [43/100], Step [600/640], Loss: 0.6189, Accuracy: 27.29%\n",
      "train Loss: 0.6191 Acc: 0.8513\n",
      "Epoch [43/100], Step [100/640], Loss: 1.2283, Accuracy: 25.71%\n",
      "val Loss: 1.2138 Acc: 0.7950\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/640], Loss: 0.5644, Accuracy: 27.86%\n",
      "Epoch [44/100], Step [200/640], Loss: 0.5431, Accuracy: 26.86%\n",
      "Epoch [44/100], Step [300/640], Loss: 0.6975, Accuracy: 26.14%\n",
      "Epoch [44/100], Step [400/640], Loss: 0.5822, Accuracy: 27.71%\n",
      "Epoch [44/100], Step [500/640], Loss: 0.6622, Accuracy: 26.29%\n",
      "Epoch [44/100], Step [600/640], Loss: 0.6461, Accuracy: 27.14%\n",
      "train Loss: 0.6060 Acc: 0.8526\n",
      "Epoch [44/100], Step [100/640], Loss: 1.2236, Accuracy: 25.57%\n",
      "val Loss: 1.1927 Acc: 0.7839\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/640], Loss: 0.4755, Accuracy: 28.57%\n",
      "Epoch [45/100], Step [200/640], Loss: 0.4646, Accuracy: 28.00%\n",
      "Epoch [45/100], Step [300/640], Loss: 0.4930, Accuracy: 29.57%\n",
      "Epoch [45/100], Step [400/640], Loss: 0.5019, Accuracy: 28.14%\n",
      "Epoch [45/100], Step [500/640], Loss: 0.5156, Accuracy: 27.71%\n",
      "Epoch [45/100], Step [600/640], Loss: 0.6046, Accuracy: 27.00%\n",
      "train Loss: 0.5967 Acc: 0.8566\n",
      "Epoch [45/100], Step [100/640], Loss: 1.1984, Accuracy: 25.86%\n",
      "val Loss: 1.1483 Acc: 0.7937\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/640], Loss: 0.5921, Accuracy: 27.00%\n",
      "Epoch [46/100], Step [200/640], Loss: 0.7147, Accuracy: 26.57%\n",
      "Epoch [46/100], Step [300/640], Loss: 0.5815, Accuracy: 27.00%\n",
      "Epoch [46/100], Step [400/640], Loss: 0.6725, Accuracy: 26.86%\n",
      "Epoch [46/100], Step [500/640], Loss: 0.5790, Accuracy: 27.29%\n",
      "Epoch [46/100], Step [600/640], Loss: 0.6190, Accuracy: 28.57%\n",
      "train Loss: 0.5854 Acc: 0.8580\n",
      "Epoch [46/100], Step [100/640], Loss: 1.2035, Accuracy: 26.43%\n",
      "val Loss: 1.1817 Acc: 0.7981\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/640], Loss: 0.6568, Accuracy: 27.71%\n",
      "Epoch [47/100], Step [200/640], Loss: 0.4699, Accuracy: 28.29%\n",
      "Epoch [47/100], Step [300/640], Loss: 0.5418, Accuracy: 28.29%\n",
      "Epoch [47/100], Step [400/640], Loss: 0.5991, Accuracy: 27.57%\n",
      "Epoch [47/100], Step [500/640], Loss: 0.4487, Accuracy: 27.57%\n",
      "Epoch [47/100], Step [600/640], Loss: 0.5685, Accuracy: 28.00%\n",
      "train Loss: 0.5706 Acc: 0.8617\n",
      "Epoch [47/100], Step [100/640], Loss: 1.3785, Accuracy: 26.00%\n",
      "val Loss: 1.2770 Acc: 0.8007\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/640], Loss: 0.5567, Accuracy: 28.00%\n",
      "Epoch [48/100], Step [200/640], Loss: 0.5719, Accuracy: 28.29%\n",
      "Epoch [48/100], Step [300/640], Loss: 0.5932, Accuracy: 27.29%\n",
      "Epoch [48/100], Step [400/640], Loss: 0.4125, Accuracy: 28.29%\n",
      "Epoch [48/100], Step [500/640], Loss: 0.7794, Accuracy: 26.43%\n",
      "Epoch [48/100], Step [600/640], Loss: 0.5924, Accuracy: 28.29%\n",
      "train Loss: 0.5634 Acc: 0.8638\n",
      "Epoch [48/100], Step [100/640], Loss: 1.3082, Accuracy: 25.43%\n",
      "val Loss: 1.2843 Acc: 0.7875\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/640], Loss: 0.5543, Accuracy: 28.14%\n",
      "Epoch [49/100], Step [200/640], Loss: 0.6787, Accuracy: 26.71%\n",
      "Epoch [49/100], Step [300/640], Loss: 0.6811, Accuracy: 28.14%\n",
      "Epoch [49/100], Step [400/640], Loss: 0.4143, Accuracy: 28.29%\n",
      "Epoch [49/100], Step [500/640], Loss: 0.4759, Accuracy: 28.00%\n",
      "Epoch [49/100], Step [600/640], Loss: 0.6183, Accuracy: 27.00%\n",
      "train Loss: 0.5514 Acc: 0.8670\n",
      "Epoch [49/100], Step [100/640], Loss: 1.4142, Accuracy: 25.29%\n",
      "val Loss: 1.2971 Acc: 0.7957\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/640], Loss: 0.4775, Accuracy: 28.00%\n",
      "Epoch [50/100], Step [200/640], Loss: 0.4794, Accuracy: 27.71%\n",
      "Epoch [50/100], Step [300/640], Loss: 0.5485, Accuracy: 27.29%\n",
      "Epoch [50/100], Step [400/640], Loss: 0.4610, Accuracy: 28.86%\n",
      "Epoch [50/100], Step [500/640], Loss: 0.6935, Accuracy: 26.57%\n",
      "Epoch [50/100], Step [600/640], Loss: 0.4764, Accuracy: 28.57%\n",
      "train Loss: 0.5446 Acc: 0.8677\n",
      "Epoch [50/100], Step [100/640], Loss: 1.4396, Accuracy: 25.71%\n",
      "val Loss: 1.2445 Acc: 0.7846\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/640], Loss: 0.7304, Accuracy: 27.43%\n",
      "Epoch [51/100], Step [200/640], Loss: 0.5940, Accuracy: 26.57%\n",
      "Epoch [51/100], Step [300/640], Loss: 0.4085, Accuracy: 28.86%\n",
      "Epoch [51/100], Step [400/640], Loss: 0.6249, Accuracy: 26.57%\n",
      "Epoch [51/100], Step [500/640], Loss: 0.4700, Accuracy: 29.29%\n",
      "Epoch [51/100], Step [600/640], Loss: 0.4041, Accuracy: 28.57%\n",
      "train Loss: 0.5254 Acc: 0.8722\n",
      "Epoch [51/100], Step [100/640], Loss: 1.6558, Accuracy: 24.86%\n",
      "val Loss: 1.3587 Acc: 0.7972\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/640], Loss: 0.5746, Accuracy: 27.43%\n",
      "Epoch [52/100], Step [200/640], Loss: 0.4323, Accuracy: 28.29%\n",
      "Epoch [52/100], Step [300/640], Loss: 0.6382, Accuracy: 27.57%\n",
      "Epoch [52/100], Step [400/640], Loss: 0.5065, Accuracy: 27.29%\n",
      "Epoch [52/100], Step [500/640], Loss: 0.7179, Accuracy: 26.71%\n",
      "Epoch [52/100], Step [600/640], Loss: 0.4265, Accuracy: 28.29%\n",
      "train Loss: 0.5198 Acc: 0.8746\n",
      "Epoch [52/100], Step [100/640], Loss: 1.6145, Accuracy: 24.86%\n",
      "val Loss: 1.3453 Acc: 0.7889\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/640], Loss: 0.3883, Accuracy: 29.14%\n",
      "Epoch [53/100], Step [200/640], Loss: 0.5098, Accuracy: 27.57%\n",
      "Epoch [53/100], Step [300/640], Loss: 0.6124, Accuracy: 26.71%\n",
      "Epoch [53/100], Step [400/640], Loss: 0.4529, Accuracy: 28.43%\n",
      "Epoch [53/100], Step [500/640], Loss: 0.5647, Accuracy: 28.00%\n",
      "Epoch [53/100], Step [600/640], Loss: 0.5676, Accuracy: 26.71%\n",
      "train Loss: 0.5076 Acc: 0.8768\n",
      "Epoch [53/100], Step [100/640], Loss: 1.5683, Accuracy: 24.86%\n",
      "val Loss: 1.3784 Acc: 0.7978\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/640], Loss: 0.5344, Accuracy: 27.57%\n",
      "Epoch [54/100], Step [200/640], Loss: 0.3859, Accuracy: 28.71%\n",
      "Epoch [54/100], Step [300/640], Loss: 0.6750, Accuracy: 27.00%\n",
      "Epoch [54/100], Step [400/640], Loss: 0.5776, Accuracy: 27.14%\n",
      "Epoch [54/100], Step [500/640], Loss: 0.6914, Accuracy: 26.71%\n",
      "Epoch [54/100], Step [600/640], Loss: 0.4950, Accuracy: 27.57%\n",
      "train Loss: 0.4962 Acc: 0.8783\n",
      "Epoch [54/100], Step [100/640], Loss: 1.8087, Accuracy: 25.00%\n",
      "val Loss: 1.4230 Acc: 0.7963\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/640], Loss: 0.5926, Accuracy: 28.29%\n",
      "Epoch [55/100], Step [200/640], Loss: 0.4305, Accuracy: 29.00%\n",
      "Epoch [55/100], Step [300/640], Loss: 0.4712, Accuracy: 28.71%\n",
      "Epoch [55/100], Step [400/640], Loss: 0.4811, Accuracy: 27.43%\n",
      "Epoch [55/100], Step [500/640], Loss: 0.4273, Accuracy: 28.57%\n",
      "Epoch [55/100], Step [600/640], Loss: 0.4788, Accuracy: 28.43%\n",
      "train Loss: 0.4825 Acc: 0.8818\n",
      "Epoch [55/100], Step [100/640], Loss: 1.5825, Accuracy: 24.57%\n",
      "val Loss: 1.3364 Acc: 0.7861\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/640], Loss: 0.6242, Accuracy: 27.86%\n",
      "Epoch [56/100], Step [200/640], Loss: 0.4378, Accuracy: 28.57%\n",
      "Epoch [56/100], Step [300/640], Loss: 0.3688, Accuracy: 29.00%\n",
      "Epoch [56/100], Step [400/640], Loss: 0.6453, Accuracy: 27.14%\n",
      "Epoch [56/100], Step [500/640], Loss: 0.4517, Accuracy: 28.14%\n",
      "Epoch [56/100], Step [600/640], Loss: 0.3880, Accuracy: 28.43%\n",
      "train Loss: 0.4822 Acc: 0.8822\n",
      "Epoch [56/100], Step [100/640], Loss: 1.6278, Accuracy: 25.71%\n",
      "val Loss: 1.4483 Acc: 0.7955\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/640], Loss: 0.4345, Accuracy: 28.71%\n",
      "Epoch [57/100], Step [200/640], Loss: 0.5821, Accuracy: 28.57%\n",
      "Epoch [57/100], Step [300/640], Loss: 0.4636, Accuracy: 28.71%\n",
      "Epoch [57/100], Step [400/640], Loss: 0.4026, Accuracy: 29.14%\n",
      "Epoch [57/100], Step [500/640], Loss: 0.5277, Accuracy: 28.29%\n",
      "Epoch [57/100], Step [600/640], Loss: 0.5548, Accuracy: 26.86%\n",
      "train Loss: 0.4669 Acc: 0.8863\n",
      "Epoch [57/100], Step [100/640], Loss: 1.9672, Accuracy: 25.00%\n",
      "val Loss: 1.5348 Acc: 0.8039\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/640], Loss: 0.4354, Accuracy: 29.00%\n",
      "Epoch [58/100], Step [200/640], Loss: 0.4183, Accuracy: 28.43%\n",
      "Epoch [58/100], Step [300/640], Loss: 0.3982, Accuracy: 28.57%\n",
      "Epoch [58/100], Step [400/640], Loss: 0.3881, Accuracy: 28.43%\n",
      "Epoch [58/100], Step [500/640], Loss: 0.3473, Accuracy: 29.43%\n",
      "Epoch [58/100], Step [600/640], Loss: 0.6559, Accuracy: 27.14%\n",
      "train Loss: 0.4510 Acc: 0.8902\n",
      "Epoch [58/100], Step [100/640], Loss: 1.9009, Accuracy: 25.43%\n",
      "val Loss: 1.6121 Acc: 0.8003\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/640], Loss: 0.4712, Accuracy: 28.14%\n",
      "Epoch [59/100], Step [200/640], Loss: 0.5638, Accuracy: 27.14%\n",
      "Epoch [59/100], Step [300/640], Loss: 0.3853, Accuracy: 28.71%\n",
      "Epoch [59/100], Step [400/640], Loss: 0.5289, Accuracy: 27.86%\n",
      "Epoch [59/100], Step [500/640], Loss: 0.4445, Accuracy: 28.71%\n",
      "Epoch [59/100], Step [600/640], Loss: 0.3611, Accuracy: 29.00%\n",
      "train Loss: 0.4434 Acc: 0.8920\n",
      "Epoch [59/100], Step [100/640], Loss: 1.7927, Accuracy: 24.43%\n",
      "val Loss: 1.4976 Acc: 0.7862\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/640], Loss: 0.4473, Accuracy: 28.71%\n",
      "Epoch [60/100], Step [200/640], Loss: 0.4518, Accuracy: 28.29%\n",
      "Epoch [60/100], Step [300/640], Loss: 0.4237, Accuracy: 29.00%\n",
      "Epoch [60/100], Step [400/640], Loss: 0.4738, Accuracy: 28.43%\n",
      "Epoch [60/100], Step [500/640], Loss: 0.5018, Accuracy: 28.43%\n",
      "Epoch [60/100], Step [600/640], Loss: 0.4047, Accuracy: 28.29%\n",
      "train Loss: 0.4329 Acc: 0.8948\n",
      "Epoch [60/100], Step [100/640], Loss: 1.8979, Accuracy: 25.57%\n",
      "val Loss: 1.5819 Acc: 0.7922\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/640], Loss: 0.2749, Accuracy: 30.29%\n",
      "Epoch [61/100], Step [200/640], Loss: 0.4379, Accuracy: 29.00%\n",
      "Epoch [61/100], Step [300/640], Loss: 0.4921, Accuracy: 28.00%\n",
      "Epoch [61/100], Step [400/640], Loss: 0.4014, Accuracy: 28.57%\n",
      "Epoch [61/100], Step [500/640], Loss: 0.5574, Accuracy: 29.86%\n",
      "Epoch [61/100], Step [600/640], Loss: 0.5071, Accuracy: 28.14%\n",
      "train Loss: 0.4210 Acc: 0.8980\n",
      "Epoch [61/100], Step [100/640], Loss: 2.2700, Accuracy: 25.86%\n",
      "val Loss: 1.8278 Acc: 0.8045\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/640], Loss: 0.4263, Accuracy: 27.71%\n",
      "Epoch [62/100], Step [200/640], Loss: 0.4950, Accuracy: 29.00%\n",
      "Epoch [62/100], Step [300/640], Loss: 0.4452, Accuracy: 28.43%\n",
      "Epoch [62/100], Step [400/640], Loss: 0.4938, Accuracy: 28.14%\n",
      "Epoch [62/100], Step [500/640], Loss: 0.4820, Accuracy: 29.00%\n",
      "Epoch [62/100], Step [600/640], Loss: 0.3677, Accuracy: 29.29%\n",
      "train Loss: 0.4137 Acc: 0.8984\n",
      "Epoch [62/100], Step [100/640], Loss: 2.1218, Accuracy: 25.00%\n",
      "val Loss: 1.7512 Acc: 0.8000\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/640], Loss: 0.4101, Accuracy: 28.43%\n",
      "Epoch [63/100], Step [200/640], Loss: 0.5571, Accuracy: 27.57%\n",
      "Epoch [63/100], Step [300/640], Loss: 0.4877, Accuracy: 28.29%\n",
      "Epoch [63/100], Step [400/640], Loss: 0.4656, Accuracy: 27.86%\n",
      "Epoch [63/100], Step [500/640], Loss: 0.3397, Accuracy: 29.29%\n",
      "Epoch [63/100], Step [600/640], Loss: 0.4536, Accuracy: 29.57%\n",
      "train Loss: 0.4058 Acc: 0.9003\n",
      "Epoch [63/100], Step [100/640], Loss: 2.5089, Accuracy: 25.71%\n",
      "val Loss: 1.7527 Acc: 0.8058\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/640], Loss: 0.4696, Accuracy: 29.29%\n",
      "Epoch [64/100], Step [200/640], Loss: 0.4694, Accuracy: 28.29%\n",
      "Epoch [64/100], Step [300/640], Loss: 0.5068, Accuracy: 27.71%\n",
      "Epoch [64/100], Step [400/640], Loss: 0.3051, Accuracy: 30.14%\n",
      "Epoch [64/100], Step [500/640], Loss: 0.3990, Accuracy: 29.00%\n",
      "Epoch [64/100], Step [600/640], Loss: 0.2535, Accuracy: 30.14%\n",
      "train Loss: 0.3925 Acc: 0.9049\n",
      "Epoch [64/100], Step [100/640], Loss: 2.4626, Accuracy: 24.71%\n",
      "val Loss: 1.7733 Acc: 0.7979\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/640], Loss: 0.3367, Accuracy: 29.86%\n",
      "Epoch [65/100], Step [200/640], Loss: 0.3293, Accuracy: 29.86%\n",
      "Epoch [65/100], Step [300/640], Loss: 0.3612, Accuracy: 28.86%\n",
      "Epoch [65/100], Step [400/640], Loss: 0.4030, Accuracy: 28.43%\n",
      "Epoch [65/100], Step [500/640], Loss: 0.3934, Accuracy: 28.86%\n",
      "Epoch [65/100], Step [600/640], Loss: 0.2958, Accuracy: 29.86%\n",
      "train Loss: 0.3988 Acc: 0.9019\n",
      "Epoch [65/100], Step [100/640], Loss: 2.4073, Accuracy: 25.00%\n",
      "val Loss: 1.8988 Acc: 0.8055\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/640], Loss: 0.3056, Accuracy: 29.86%\n",
      "Epoch [66/100], Step [200/640], Loss: 0.5177, Accuracy: 28.14%\n",
      "Epoch [66/100], Step [300/640], Loss: 0.3767, Accuracy: 29.71%\n",
      "Epoch [66/100], Step [400/640], Loss: 0.6435, Accuracy: 28.29%\n",
      "Epoch [66/100], Step [500/640], Loss: 0.3477, Accuracy: 28.43%\n",
      "Epoch [66/100], Step [600/640], Loss: 0.4024, Accuracy: 28.71%\n",
      "train Loss: 0.3781 Acc: 0.9086\n",
      "Epoch [66/100], Step [100/640], Loss: 2.6928, Accuracy: 24.57%\n",
      "val Loss: 1.8147 Acc: 0.7961\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/640], Loss: 0.3156, Accuracy: 29.43%\n",
      "Epoch [67/100], Step [200/640], Loss: 0.3444, Accuracy: 29.00%\n",
      "Epoch [67/100], Step [300/640], Loss: 0.3573, Accuracy: 29.71%\n",
      "Epoch [67/100], Step [400/640], Loss: 0.2995, Accuracy: 29.29%\n",
      "Epoch [67/100], Step [500/640], Loss: 0.2798, Accuracy: 29.71%\n",
      "Epoch [67/100], Step [600/640], Loss: 0.2545, Accuracy: 29.57%\n",
      "train Loss: 0.3671 Acc: 0.9102\n",
      "Epoch [67/100], Step [100/640], Loss: 2.4140, Accuracy: 25.00%\n",
      "val Loss: 1.9738 Acc: 0.7963\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/640], Loss: 0.3397, Accuracy: 29.14%\n",
      "Epoch [68/100], Step [200/640], Loss: 0.3576, Accuracy: 29.29%\n",
      "Epoch [68/100], Step [300/640], Loss: 0.4104, Accuracy: 29.29%\n",
      "Epoch [68/100], Step [400/640], Loss: 0.2723, Accuracy: 29.43%\n",
      "Epoch [68/100], Step [500/640], Loss: 0.3185, Accuracy: 29.71%\n",
      "Epoch [68/100], Step [600/640], Loss: 0.2759, Accuracy: 30.00%\n",
      "train Loss: 0.3575 Acc: 0.9131\n",
      "Epoch [68/100], Step [100/640], Loss: 2.9788, Accuracy: 25.14%\n",
      "val Loss: 2.0706 Acc: 0.8045\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/640], Loss: 0.4594, Accuracy: 28.14%\n",
      "Epoch [69/100], Step [200/640], Loss: 0.4674, Accuracy: 29.86%\n",
      "Epoch [69/100], Step [300/640], Loss: 0.2401, Accuracy: 30.29%\n",
      "Epoch [69/100], Step [400/640], Loss: 0.3572, Accuracy: 29.43%\n",
      "Epoch [69/100], Step [500/640], Loss: 0.2903, Accuracy: 29.29%\n",
      "Epoch [69/100], Step [600/640], Loss: 0.3665, Accuracy: 28.86%\n",
      "train Loss: 0.3566 Acc: 0.9126\n",
      "Epoch [69/100], Step [100/640], Loss: 2.8319, Accuracy: 24.57%\n",
      "val Loss: 2.0646 Acc: 0.8025\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/640], Loss: 0.3899, Accuracy: 28.57%\n",
      "Epoch [70/100], Step [200/640], Loss: 0.3542, Accuracy: 29.00%\n",
      "Epoch [70/100], Step [300/640], Loss: 0.3067, Accuracy: 29.00%\n",
      "Epoch [70/100], Step [400/640], Loss: 0.3495, Accuracy: 29.71%\n",
      "Epoch [70/100], Step [500/640], Loss: 0.4403, Accuracy: 28.57%\n",
      "Epoch [70/100], Step [600/640], Loss: 0.4692, Accuracy: 28.00%\n",
      "train Loss: 0.3382 Acc: 0.9176\n",
      "Epoch [70/100], Step [100/640], Loss: 2.7162, Accuracy: 24.86%\n",
      "val Loss: 2.0592 Acc: 0.8026\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/640], Loss: 0.2406, Accuracy: 30.14%\n",
      "Epoch [71/100], Step [200/640], Loss: 0.2953, Accuracy: 29.86%\n",
      "Epoch [71/100], Step [300/640], Loss: 0.2606, Accuracy: 30.43%\n",
      "Epoch [71/100], Step [400/640], Loss: 0.2738, Accuracy: 29.29%\n",
      "Epoch [71/100], Step [500/640], Loss: 0.3792, Accuracy: 28.86%\n",
      "Epoch [71/100], Step [600/640], Loss: 0.6232, Accuracy: 28.86%\n",
      "train Loss: 0.3312 Acc: 0.9189\n",
      "Epoch [71/100], Step [100/640], Loss: 2.8496, Accuracy: 25.00%\n",
      "val Loss: 2.1742 Acc: 0.7999\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/640], Loss: 0.2445, Accuracy: 29.86%\n",
      "Epoch [72/100], Step [200/640], Loss: 0.5116, Accuracy: 29.43%\n",
      "Epoch [72/100], Step [300/640], Loss: 0.2995, Accuracy: 29.86%\n",
      "Epoch [72/100], Step [400/640], Loss: 0.3330, Accuracy: 29.29%\n",
      "Epoch [72/100], Step [500/640], Loss: 0.2968, Accuracy: 29.86%\n",
      "Epoch [72/100], Step [600/640], Loss: 0.2571, Accuracy: 30.57%\n",
      "train Loss: 0.3285 Acc: 0.9201\n",
      "Epoch [72/100], Step [100/640], Loss: 2.7398, Accuracy: 24.57%\n",
      "val Loss: 2.0862 Acc: 0.7953\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/640], Loss: 0.2390, Accuracy: 30.14%\n",
      "Epoch [73/100], Step [200/640], Loss: 0.3494, Accuracy: 29.43%\n",
      "Epoch [73/100], Step [300/640], Loss: 0.2567, Accuracy: 30.00%\n",
      "Epoch [73/100], Step [400/640], Loss: 0.3077, Accuracy: 29.29%\n",
      "Epoch [73/100], Step [500/640], Loss: 0.3497, Accuracy: 29.00%\n",
      "Epoch [73/100], Step [600/640], Loss: 0.2768, Accuracy: 29.43%\n",
      "train Loss: 0.3259 Acc: 0.9204\n",
      "Epoch [73/100], Step [100/640], Loss: 3.0901, Accuracy: 24.00%\n",
      "val Loss: 2.0417 Acc: 0.7976\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/640], Loss: 0.2972, Accuracy: 29.29%\n",
      "Epoch [74/100], Step [200/640], Loss: 0.2460, Accuracy: 30.29%\n",
      "Epoch [74/100], Step [300/640], Loss: 0.2654, Accuracy: 29.86%\n",
      "Epoch [74/100], Step [400/640], Loss: 0.4834, Accuracy: 28.86%\n",
      "Epoch [74/100], Step [500/640], Loss: 0.2476, Accuracy: 29.57%\n",
      "Epoch [74/100], Step [600/640], Loss: 0.2510, Accuracy: 30.29%\n",
      "train Loss: 0.3144 Acc: 0.9222\n",
      "Epoch [74/100], Step [100/640], Loss: 2.8545, Accuracy: 24.86%\n",
      "val Loss: 2.0074 Acc: 0.7951\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/640], Loss: 0.3025, Accuracy: 29.43%\n",
      "Epoch [75/100], Step [200/640], Loss: 0.3409, Accuracy: 29.43%\n",
      "Epoch [75/100], Step [300/640], Loss: 0.2644, Accuracy: 29.43%\n",
      "Epoch [75/100], Step [400/640], Loss: 0.4114, Accuracy: 29.57%\n",
      "Epoch [75/100], Step [500/640], Loss: 0.3089, Accuracy: 29.29%\n",
      "Epoch [75/100], Step [600/640], Loss: 0.3692, Accuracy: 29.00%\n",
      "train Loss: 0.3049 Acc: 0.9260\n",
      "Epoch [75/100], Step [100/640], Loss: 3.7175, Accuracy: 24.71%\n",
      "val Loss: 2.3203 Acc: 0.8068\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/640], Loss: 0.2722, Accuracy: 30.14%\n",
      "Epoch [76/100], Step [200/640], Loss: 0.3402, Accuracy: 29.43%\n",
      "Epoch [76/100], Step [300/640], Loss: 0.2525, Accuracy: 30.14%\n",
      "Epoch [76/100], Step [400/640], Loss: 0.3127, Accuracy: 29.71%\n",
      "Epoch [76/100], Step [500/640], Loss: 0.2636, Accuracy: 29.29%\n",
      "Epoch [76/100], Step [600/640], Loss: 0.1490, Accuracy: 31.00%\n",
      "train Loss: 0.2930 Acc: 0.9278\n",
      "Epoch [76/100], Step [100/640], Loss: 3.4177, Accuracy: 24.57%\n",
      "val Loss: 2.3661 Acc: 0.8058\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/640], Loss: 0.1988, Accuracy: 30.43%\n",
      "Epoch [77/100], Step [200/640], Loss: 0.2429, Accuracy: 30.43%\n",
      "Epoch [77/100], Step [300/640], Loss: 0.2593, Accuracy: 29.71%\n",
      "Epoch [77/100], Step [400/640], Loss: 0.2493, Accuracy: 30.14%\n",
      "Epoch [77/100], Step [500/640], Loss: 0.2481, Accuracy: 29.86%\n",
      "Epoch [77/100], Step [600/640], Loss: 0.2209, Accuracy: 30.86%\n",
      "train Loss: 0.2868 Acc: 0.9301\n",
      "Epoch [77/100], Step [100/640], Loss: 3.3091, Accuracy: 24.86%\n",
      "val Loss: 2.3174 Acc: 0.8004\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/640], Loss: 0.3204, Accuracy: 29.00%\n",
      "Epoch [78/100], Step [200/640], Loss: 0.2414, Accuracy: 30.29%\n",
      "Epoch [78/100], Step [300/640], Loss: 0.3107, Accuracy: 29.29%\n",
      "Epoch [78/100], Step [400/640], Loss: 0.2152, Accuracy: 30.14%\n",
      "Epoch [78/100], Step [500/640], Loss: 0.2717, Accuracy: 29.57%\n",
      "Epoch [78/100], Step [600/640], Loss: 0.3267, Accuracy: 29.43%\n",
      "train Loss: 0.2802 Acc: 0.9320\n",
      "Epoch [78/100], Step [100/640], Loss: 3.1017, Accuracy: 24.57%\n",
      "val Loss: 2.2650 Acc: 0.7990\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/640], Loss: 0.2966, Accuracy: 29.57%\n",
      "Epoch [79/100], Step [200/640], Loss: 0.2364, Accuracy: 30.14%\n",
      "Epoch [79/100], Step [300/640], Loss: 0.3518, Accuracy: 29.57%\n",
      "Epoch [79/100], Step [400/640], Loss: 0.2561, Accuracy: 29.71%\n",
      "Epoch [79/100], Step [500/640], Loss: 0.3746, Accuracy: 29.29%\n",
      "Epoch [79/100], Step [600/640], Loss: 0.2660, Accuracy: 29.43%\n",
      "train Loss: 0.2894 Acc: 0.9298\n",
      "Epoch [79/100], Step [100/640], Loss: 3.1816, Accuracy: 24.71%\n",
      "val Loss: 2.3075 Acc: 0.8018\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/640], Loss: 0.2989, Accuracy: 29.57%\n",
      "Epoch [80/100], Step [200/640], Loss: 0.4086, Accuracy: 29.29%\n",
      "Epoch [80/100], Step [300/640], Loss: 0.2398, Accuracy: 29.86%\n",
      "Epoch [80/100], Step [400/640], Loss: 0.2044, Accuracy: 30.14%\n",
      "Epoch [80/100], Step [500/640], Loss: 0.4408, Accuracy: 29.71%\n",
      "Epoch [80/100], Step [600/640], Loss: 0.2399, Accuracy: 29.43%\n",
      "train Loss: 0.2730 Acc: 0.9338\n",
      "Epoch [80/100], Step [100/640], Loss: 3.3327, Accuracy: 24.86%\n",
      "val Loss: 2.3740 Acc: 0.7980\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/640], Loss: 0.3307, Accuracy: 29.71%\n",
      "Epoch [81/100], Step [200/640], Loss: 0.2295, Accuracy: 30.00%\n",
      "Epoch [81/100], Step [300/640], Loss: 0.3581, Accuracy: 29.57%\n",
      "Epoch [81/100], Step [400/640], Loss: 0.2885, Accuracy: 29.71%\n",
      "Epoch [81/100], Step [500/640], Loss: 0.2680, Accuracy: 29.57%\n",
      "Epoch [81/100], Step [600/640], Loss: 0.2240, Accuracy: 29.86%\n",
      "train Loss: 0.2679 Acc: 0.9352\n",
      "Epoch [81/100], Step [100/640], Loss: 3.7610, Accuracy: 24.71%\n",
      "val Loss: 2.4053 Acc: 0.7993\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/640], Loss: 0.2414, Accuracy: 29.86%\n",
      "Epoch [82/100], Step [200/640], Loss: 0.1573, Accuracy: 30.86%\n",
      "Epoch [82/100], Step [300/640], Loss: 0.2780, Accuracy: 29.86%\n",
      "Epoch [82/100], Step [400/640], Loss: 0.4466, Accuracy: 29.00%\n",
      "Epoch [82/100], Step [500/640], Loss: 0.2706, Accuracy: 29.29%\n",
      "Epoch [82/100], Step [600/640], Loss: 0.1907, Accuracy: 30.29%\n",
      "train Loss: 0.2592 Acc: 0.9372\n",
      "Epoch [82/100], Step [100/640], Loss: 3.4780, Accuracy: 24.71%\n",
      "val Loss: 2.4719 Acc: 0.8004\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/640], Loss: 0.3784, Accuracy: 29.14%\n",
      "Epoch [83/100], Step [200/640], Loss: 0.3537, Accuracy: 28.43%\n",
      "Epoch [83/100], Step [300/640], Loss: 0.2293, Accuracy: 30.29%\n",
      "Epoch [83/100], Step [400/640], Loss: 0.2701, Accuracy: 29.86%\n",
      "Epoch [83/100], Step [500/640], Loss: 0.1824, Accuracy: 30.57%\n",
      "Epoch [83/100], Step [600/640], Loss: 0.2848, Accuracy: 29.57%\n",
      "train Loss: 0.2547 Acc: 0.9384\n",
      "Epoch [83/100], Step [100/640], Loss: 4.0086, Accuracy: 24.86%\n",
      "val Loss: 2.7632 Acc: 0.8083\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/640], Loss: 0.2471, Accuracy: 29.71%\n",
      "Epoch [84/100], Step [200/640], Loss: 0.2969, Accuracy: 29.71%\n",
      "Epoch [84/100], Step [300/640], Loss: 0.2388, Accuracy: 30.00%\n",
      "Epoch [84/100], Step [400/640], Loss: 0.2309, Accuracy: 30.29%\n",
      "Epoch [84/100], Step [500/640], Loss: 0.1778, Accuracy: 30.57%\n",
      "Epoch [84/100], Step [600/640], Loss: 0.2279, Accuracy: 30.29%\n",
      "train Loss: 0.2621 Acc: 0.9369\n",
      "Epoch [84/100], Step [100/640], Loss: 3.5602, Accuracy: 24.86%\n",
      "val Loss: 2.5219 Acc: 0.7976\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/640], Loss: 0.1933, Accuracy: 30.43%\n",
      "Epoch [85/100], Step [200/640], Loss: 0.2457, Accuracy: 30.14%\n",
      "Epoch [85/100], Step [300/640], Loss: 0.2061, Accuracy: 30.57%\n",
      "Epoch [85/100], Step [400/640], Loss: 0.1741, Accuracy: 30.57%\n",
      "Epoch [85/100], Step [500/640], Loss: 0.2291, Accuracy: 29.29%\n",
      "Epoch [85/100], Step [600/640], Loss: 0.2653, Accuracy: 30.71%\n",
      "train Loss: 0.2422 Acc: 0.9415\n",
      "Epoch [85/100], Step [100/640], Loss: 3.9387, Accuracy: 24.86%\n",
      "val Loss: 2.7024 Acc: 0.8047\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/640], Loss: 0.2402, Accuracy: 30.43%\n",
      "Epoch [86/100], Step [200/640], Loss: 0.1367, Accuracy: 30.86%\n",
      "Epoch [86/100], Step [300/640], Loss: 0.2617, Accuracy: 30.00%\n",
      "Epoch [86/100], Step [400/640], Loss: 0.3846, Accuracy: 29.14%\n",
      "Epoch [86/100], Step [500/640], Loss: 0.4069, Accuracy: 28.86%\n",
      "Epoch [86/100], Step [600/640], Loss: 0.1448, Accuracy: 31.00%\n",
      "train Loss: 0.2462 Acc: 0.9412\n",
      "Epoch [86/100], Step [100/640], Loss: 3.6526, Accuracy: 25.29%\n",
      "val Loss: 2.5394 Acc: 0.7976\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/640], Loss: 0.2688, Accuracy: 30.00%\n",
      "Epoch [87/100], Step [200/640], Loss: 0.2923, Accuracy: 29.71%\n",
      "Epoch [87/100], Step [300/640], Loss: 0.1362, Accuracy: 30.57%\n",
      "Epoch [87/100], Step [400/640], Loss: 0.2160, Accuracy: 30.71%\n",
      "Epoch [87/100], Step [500/640], Loss: 0.1921, Accuracy: 30.29%\n",
      "Epoch [87/100], Step [600/640], Loss: 0.2119, Accuracy: 29.71%\n",
      "train Loss: 0.2339 Acc: 0.9432\n",
      "Epoch [87/100], Step [100/640], Loss: 3.7731, Accuracy: 24.57%\n",
      "val Loss: 2.7005 Acc: 0.8037\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/640], Loss: 0.1931, Accuracy: 30.14%\n",
      "Epoch [88/100], Step [200/640], Loss: 0.1946, Accuracy: 30.71%\n",
      "Epoch [88/100], Step [300/640], Loss: 0.2754, Accuracy: 29.14%\n",
      "Epoch [88/100], Step [400/640], Loss: 0.1538, Accuracy: 30.86%\n",
      "Epoch [88/100], Step [500/640], Loss: 0.2055, Accuracy: 30.86%\n",
      "Epoch [88/100], Step [600/640], Loss: 0.3640, Accuracy: 28.57%\n",
      "train Loss: 0.2385 Acc: 0.9418\n",
      "Epoch [88/100], Step [100/640], Loss: 3.4805, Accuracy: 25.29%\n",
      "val Loss: 2.5659 Acc: 0.8001\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/640], Loss: 0.2333, Accuracy: 30.71%\n",
      "Epoch [89/100], Step [200/640], Loss: 0.1999, Accuracy: 30.43%\n",
      "Epoch [89/100], Step [300/640], Loss: 0.2642, Accuracy: 30.00%\n",
      "Epoch [89/100], Step [400/640], Loss: 0.2574, Accuracy: 30.43%\n",
      "Epoch [89/100], Step [500/640], Loss: 0.1450, Accuracy: 30.71%\n",
      "Epoch [89/100], Step [600/640], Loss: 0.2376, Accuracy: 30.00%\n",
      "train Loss: 0.2330 Acc: 0.9444\n",
      "Epoch [89/100], Step [100/640], Loss: 4.2245, Accuracy: 25.00%\n",
      "val Loss: 2.6481 Acc: 0.8011\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/640], Loss: 0.2262, Accuracy: 30.29%\n",
      "Epoch [90/100], Step [200/640], Loss: 0.2064, Accuracy: 30.29%\n",
      "Epoch [90/100], Step [300/640], Loss: 0.2666, Accuracy: 30.86%\n",
      "Epoch [90/100], Step [400/640], Loss: 0.1166, Accuracy: 31.00%\n",
      "Epoch [90/100], Step [500/640], Loss: 0.2094, Accuracy: 30.57%\n",
      "Epoch [90/100], Step [600/640], Loss: 0.1605, Accuracy: 30.57%\n",
      "train Loss: 0.2253 Acc: 0.9456\n",
      "Epoch [90/100], Step [100/640], Loss: 3.7835, Accuracy: 25.00%\n",
      "val Loss: 2.6544 Acc: 0.8042\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/640], Loss: 0.2469, Accuracy: 30.57%\n",
      "Epoch [91/100], Step [200/640], Loss: 0.1996, Accuracy: 30.29%\n",
      "Epoch [91/100], Step [300/640], Loss: 0.3412, Accuracy: 29.71%\n",
      "Epoch [91/100], Step [400/640], Loss: 0.2551, Accuracy: 29.86%\n",
      "Epoch [91/100], Step [500/640], Loss: 0.1321, Accuracy: 30.86%\n",
      "Epoch [91/100], Step [600/640], Loss: 0.2126, Accuracy: 30.71%\n",
      "train Loss: 0.2199 Acc: 0.9475\n",
      "Epoch [91/100], Step [100/640], Loss: 3.7017, Accuracy: 24.86%\n",
      "val Loss: 2.5575 Acc: 0.7958\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/640], Loss: 0.1964, Accuracy: 30.29%\n",
      "Epoch [92/100], Step [200/640], Loss: 0.2735, Accuracy: 30.00%\n",
      "Epoch [92/100], Step [300/640], Loss: 0.1808, Accuracy: 30.86%\n",
      "Epoch [92/100], Step [400/640], Loss: 0.1381, Accuracy: 31.14%\n",
      "Epoch [92/100], Step [500/640], Loss: 0.4206, Accuracy: 29.43%\n",
      "Epoch [92/100], Step [600/640], Loss: 0.2056, Accuracy: 30.57%\n",
      "train Loss: 0.2208 Acc: 0.9464\n",
      "Epoch [92/100], Step [100/640], Loss: 3.9023, Accuracy: 24.71%\n",
      "val Loss: 2.7739 Acc: 0.7999\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/640], Loss: 0.2168, Accuracy: 30.14%\n",
      "Epoch [93/100], Step [200/640], Loss: 0.1763, Accuracy: 30.71%\n",
      "Epoch [93/100], Step [300/640], Loss: 0.2304, Accuracy: 30.14%\n",
      "Epoch [93/100], Step [400/640], Loss: 0.1604, Accuracy: 30.43%\n",
      "Epoch [93/100], Step [500/640], Loss: 0.1301, Accuracy: 30.86%\n",
      "Epoch [93/100], Step [600/640], Loss: 0.2058, Accuracy: 30.29%\n",
      "train Loss: 0.2154 Acc: 0.9479\n",
      "Epoch [93/100], Step [100/640], Loss: 3.9818, Accuracy: 24.57%\n",
      "val Loss: 2.7704 Acc: 0.7972\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/640], Loss: 0.1215, Accuracy: 31.29%\n",
      "Epoch [94/100], Step [200/640], Loss: 0.1379, Accuracy: 30.86%\n",
      "Epoch [94/100], Step [300/640], Loss: 0.3069, Accuracy: 30.00%\n",
      "Epoch [94/100], Step [400/640], Loss: 0.2267, Accuracy: 30.14%\n",
      "Epoch [94/100], Step [500/640], Loss: 0.1573, Accuracy: 30.71%\n",
      "Epoch [94/100], Step [600/640], Loss: 0.1602, Accuracy: 30.43%\n",
      "train Loss: 0.2087 Acc: 0.9496\n",
      "Epoch [94/100], Step [100/640], Loss: 4.3073, Accuracy: 24.57%\n",
      "val Loss: 2.9164 Acc: 0.8027\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/640], Loss: 0.2445, Accuracy: 29.57%\n",
      "Epoch [95/100], Step [200/640], Loss: 0.1964, Accuracy: 30.29%\n",
      "Epoch [95/100], Step [300/640], Loss: 0.2058, Accuracy: 30.29%\n",
      "Epoch [95/100], Step [400/640], Loss: 0.1236, Accuracy: 30.71%\n",
      "Epoch [95/100], Step [500/640], Loss: 0.1723, Accuracy: 30.14%\n",
      "Epoch [95/100], Step [600/640], Loss: 0.2506, Accuracy: 29.86%\n",
      "train Loss: 0.2123 Acc: 0.9488\n",
      "Epoch [95/100], Step [100/640], Loss: 3.6664, Accuracy: 24.86%\n",
      "val Loss: 2.7104 Acc: 0.7995\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/640], Loss: 0.1744, Accuracy: 30.43%\n",
      "Epoch [96/100], Step [200/640], Loss: 0.1750, Accuracy: 30.71%\n",
      "Epoch [96/100], Step [300/640], Loss: 0.2137, Accuracy: 30.43%\n",
      "Epoch [96/100], Step [400/640], Loss: 0.1472, Accuracy: 30.57%\n",
      "Epoch [96/100], Step [500/640], Loss: 0.2554, Accuracy: 30.57%\n",
      "Epoch [96/100], Step [600/640], Loss: 0.2717, Accuracy: 29.43%\n",
      "train Loss: 0.2099 Acc: 0.9500\n",
      "Epoch [96/100], Step [100/640], Loss: 4.3358, Accuracy: 25.00%\n",
      "val Loss: 2.9573 Acc: 0.8028\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/640], Loss: 0.2061, Accuracy: 30.43%\n",
      "Epoch [97/100], Step [200/640], Loss: 0.1731, Accuracy: 29.86%\n",
      "Epoch [97/100], Step [300/640], Loss: 0.2174, Accuracy: 30.00%\n",
      "Epoch [97/100], Step [400/640], Loss: 0.2060, Accuracy: 30.57%\n",
      "Epoch [97/100], Step [500/640], Loss: 0.1207, Accuracy: 30.71%\n",
      "Epoch [97/100], Step [600/640], Loss: 0.2334, Accuracy: 29.86%\n",
      "train Loss: 0.2025 Acc: 0.9509\n",
      "Epoch [97/100], Step [100/640], Loss: 3.9362, Accuracy: 25.43%\n",
      "val Loss: 2.9034 Acc: 0.8008\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/640], Loss: 0.1662, Accuracy: 30.57%\n",
      "Epoch [98/100], Step [200/640], Loss: 0.2683, Accuracy: 30.57%\n",
      "Epoch [98/100], Step [300/640], Loss: 0.1622, Accuracy: 30.86%\n",
      "Epoch [98/100], Step [400/640], Loss: 0.3626, Accuracy: 29.86%\n",
      "Epoch [98/100], Step [500/640], Loss: 0.2970, Accuracy: 29.57%\n",
      "Epoch [98/100], Step [600/640], Loss: 0.1503, Accuracy: 31.00%\n",
      "train Loss: 0.2031 Acc: 0.9518\n",
      "Epoch [98/100], Step [100/640], Loss: 4.1763, Accuracy: 25.57%\n",
      "val Loss: 3.0222 Acc: 0.8057\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/640], Loss: 0.2473, Accuracy: 29.71%\n",
      "Epoch [99/100], Step [200/640], Loss: 0.2766, Accuracy: 29.43%\n",
      "Epoch [99/100], Step [300/640], Loss: 0.1139, Accuracy: 31.14%\n",
      "Epoch [99/100], Step [400/640], Loss: 0.2635, Accuracy: 30.00%\n",
      "Epoch [99/100], Step [500/640], Loss: 0.3518, Accuracy: 29.29%\n",
      "Epoch [99/100], Step [600/640], Loss: 0.1236, Accuracy: 31.43%\n",
      "train Loss: 0.2013 Acc: 0.9519\n",
      "Epoch [99/100], Step [100/640], Loss: 4.1923, Accuracy: 24.86%\n",
      "val Loss: 2.9444 Acc: 0.8030\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/640], Loss: 0.1776, Accuracy: 29.71%\n",
      "Epoch [100/100], Step [200/640], Loss: 0.2054, Accuracy: 30.29%\n",
      "Epoch [100/100], Step [300/640], Loss: 0.1746, Accuracy: 30.71%\n",
      "Epoch [100/100], Step [400/640], Loss: 0.1515, Accuracy: 30.71%\n",
      "Epoch [100/100], Step [500/640], Loss: 0.1612, Accuracy: 30.86%\n",
      "Epoch [100/100], Step [600/640], Loss: 0.1858, Accuracy: 30.57%\n",
      "train Loss: 0.1998 Acc: 0.9521\n",
      "Epoch [100/100], Step [100/640], Loss: 4.0054, Accuracy: 24.86%\n",
      "val Loss: 2.8649 Acc: 0.8020\n",
      "\n",
      "Training complete in 230m 13s\n",
      "Best val Acc: 0.795496\n",
      "Best loss: 0.892553\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'chest_xray_8_tl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7944154039568583\n",
      "f1: 0.4568441574214903\n",
      "cm: [[[2901  372]\n",
      "  [ 459  586]]\n",
      "\n",
      " [[2878  395]\n",
      "  [ 399  646]]\n",
      "\n",
      " [[3525  234]\n",
      "  [ 394  165]]\n",
      "\n",
      " [[3158  505]\n",
      "  [ 372  283]]\n",
      "\n",
      " [[2503  768]\n",
      "  [ 449  598]]\n",
      "\n",
      " [[3428  445]\n",
      "  [ 217  228]]\n",
      "\n",
      " [[2784 1068]\n",
      "  [ 137  329]]]\n",
      "outputs: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "targets: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
