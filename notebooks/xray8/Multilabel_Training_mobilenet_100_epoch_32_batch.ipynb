{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Write a script to plot loss + accuracy graph\n",
    "## 3. Get FLOPs - done\n",
    "## 4. Get num layers - done\n",
    "## ----------------------------------------------------\n",
    "## 1. Implement differentiable F1 loss function\n",
    "## 2. Add class weights\n",
    "## 3. Implement transfer learning part - done\n",
    "## 4. Implement T-SNE\n",
    "## 5. Implement gradcam\n",
    "## 6. Ablation study\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "images_dir = \"../../data/xray8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0.\n",
    "model_name = \"mobile_net_v3_large\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 7\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 multilabel training dataset metrics \n",
    "norm_arr=([0.4955, 0.4955, 0.4955], [0.2892, 0.2892, 0.2892])\n",
    "\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = False\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = None\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([2., 3., 6., 6., 3., 7., 9.], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Effusion',\n",
       " 'No Finding',\n",
       " 'Mass',\n",
       " 'Nodule',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Consolidation']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.block.0.0.weight\n",
      "\t features.1.block.0.1.weight\n",
      "\t features.1.block.0.1.bias\n",
      "\t features.1.block.1.0.weight\n",
      "\t features.1.block.1.1.weight\n",
      "\t features.1.block.1.1.bias\n",
      "\t features.2.block.0.0.weight\n",
      "\t features.2.block.0.1.weight\n",
      "\t features.2.block.0.1.bias\n",
      "\t features.2.block.1.0.weight\n",
      "\t features.2.block.1.1.weight\n",
      "\t features.2.block.1.1.bias\n",
      "\t features.2.block.2.0.weight\n",
      "\t features.2.block.2.1.weight\n",
      "\t features.2.block.2.1.bias\n",
      "\t features.3.block.0.0.weight\n",
      "\t features.3.block.0.1.weight\n",
      "\t features.3.block.0.1.bias\n",
      "\t features.3.block.1.0.weight\n",
      "\t features.3.block.1.1.weight\n",
      "\t features.3.block.1.1.bias\n",
      "\t features.3.block.2.0.weight\n",
      "\t features.3.block.2.1.weight\n",
      "\t features.3.block.2.1.bias\n",
      "\t features.4.block.0.0.weight\n",
      "\t features.4.block.0.1.weight\n",
      "\t features.4.block.0.1.bias\n",
      "\t features.4.block.1.0.weight\n",
      "\t features.4.block.1.1.weight\n",
      "\t features.4.block.1.1.bias\n",
      "\t features.4.block.2.fc1.weight\n",
      "\t features.4.block.2.fc1.bias\n",
      "\t features.4.block.2.fc2.weight\n",
      "\t features.4.block.2.fc2.bias\n",
      "\t features.4.block.3.0.weight\n",
      "\t features.4.block.3.1.weight\n",
      "\t features.4.block.3.1.bias\n",
      "\t features.5.block.0.0.weight\n",
      "\t features.5.block.0.1.weight\n",
      "\t features.5.block.0.1.bias\n",
      "\t features.5.block.1.0.weight\n",
      "\t features.5.block.1.1.weight\n",
      "\t features.5.block.1.1.bias\n",
      "\t features.5.block.2.fc1.weight\n",
      "\t features.5.block.2.fc1.bias\n",
      "\t features.5.block.2.fc2.weight\n",
      "\t features.5.block.2.fc2.bias\n",
      "\t features.5.block.3.0.weight\n",
      "\t features.5.block.3.1.weight\n",
      "\t features.5.block.3.1.bias\n",
      "\t features.6.block.0.0.weight\n",
      "\t features.6.block.0.1.weight\n",
      "\t features.6.block.0.1.bias\n",
      "\t features.6.block.1.0.weight\n",
      "\t features.6.block.1.1.weight\n",
      "\t features.6.block.1.1.bias\n",
      "\t features.6.block.2.fc1.weight\n",
      "\t features.6.block.2.fc1.bias\n",
      "\t features.6.block.2.fc2.weight\n",
      "\t features.6.block.2.fc2.bias\n",
      "\t features.6.block.3.0.weight\n",
      "\t features.6.block.3.1.weight\n",
      "\t features.6.block.3.1.bias\n",
      "\t features.7.block.0.0.weight\n",
      "\t features.7.block.0.1.weight\n",
      "\t features.7.block.0.1.bias\n",
      "\t features.7.block.1.0.weight\n",
      "\t features.7.block.1.1.weight\n",
      "\t features.7.block.1.1.bias\n",
      "\t features.7.block.2.0.weight\n",
      "\t features.7.block.2.1.weight\n",
      "\t features.7.block.2.1.bias\n",
      "\t features.8.block.0.0.weight\n",
      "\t features.8.block.0.1.weight\n",
      "\t features.8.block.0.1.bias\n",
      "\t features.8.block.1.0.weight\n",
      "\t features.8.block.1.1.weight\n",
      "\t features.8.block.1.1.bias\n",
      "\t features.8.block.2.0.weight\n",
      "\t features.8.block.2.1.weight\n",
      "\t features.8.block.2.1.bias\n",
      "\t features.9.block.0.0.weight\n",
      "\t features.9.block.0.1.weight\n",
      "\t features.9.block.0.1.bias\n",
      "\t features.9.block.1.0.weight\n",
      "\t features.9.block.1.1.weight\n",
      "\t features.9.block.1.1.bias\n",
      "\t features.9.block.2.0.weight\n",
      "\t features.9.block.2.1.weight\n",
      "\t features.9.block.2.1.bias\n",
      "\t features.10.block.0.0.weight\n",
      "\t features.10.block.0.1.weight\n",
      "\t features.10.block.0.1.bias\n",
      "\t features.10.block.1.0.weight\n",
      "\t features.10.block.1.1.weight\n",
      "\t features.10.block.1.1.bias\n",
      "\t features.10.block.2.0.weight\n",
      "\t features.10.block.2.1.weight\n",
      "\t features.10.block.2.1.bias\n",
      "\t features.11.block.0.0.weight\n",
      "\t features.11.block.0.1.weight\n",
      "\t features.11.block.0.1.bias\n",
      "\t features.11.block.1.0.weight\n",
      "\t features.11.block.1.1.weight\n",
      "\t features.11.block.1.1.bias\n",
      "\t features.11.block.2.fc1.weight\n",
      "\t features.11.block.2.fc1.bias\n",
      "\t features.11.block.2.fc2.weight\n",
      "\t features.11.block.2.fc2.bias\n",
      "\t features.11.block.3.0.weight\n",
      "\t features.11.block.3.1.weight\n",
      "\t features.11.block.3.1.bias\n",
      "\t features.12.block.0.0.weight\n",
      "\t features.12.block.0.1.weight\n",
      "\t features.12.block.0.1.bias\n",
      "\t features.12.block.1.0.weight\n",
      "\t features.12.block.1.1.weight\n",
      "\t features.12.block.1.1.bias\n",
      "\t features.12.block.2.fc1.weight\n",
      "\t features.12.block.2.fc1.bias\n",
      "\t features.12.block.2.fc2.weight\n",
      "\t features.12.block.2.fc2.bias\n",
      "\t features.12.block.3.0.weight\n",
      "\t features.12.block.3.1.weight\n",
      "\t features.12.block.3.1.bias\n",
      "\t features.13.block.0.0.weight\n",
      "\t features.13.block.0.1.weight\n",
      "\t features.13.block.0.1.bias\n",
      "\t features.13.block.1.0.weight\n",
      "\t features.13.block.1.1.weight\n",
      "\t features.13.block.1.1.bias\n",
      "\t features.13.block.2.fc1.weight\n",
      "\t features.13.block.2.fc1.bias\n",
      "\t features.13.block.2.fc2.weight\n",
      "\t features.13.block.2.fc2.bias\n",
      "\t features.13.block.3.0.weight\n",
      "\t features.13.block.3.1.weight\n",
      "\t features.13.block.3.1.bias\n",
      "\t features.14.block.0.0.weight\n",
      "\t features.14.block.0.1.weight\n",
      "\t features.14.block.0.1.bias\n",
      "\t features.14.block.1.0.weight\n",
      "\t features.14.block.1.1.weight\n",
      "\t features.14.block.1.1.bias\n",
      "\t features.14.block.2.fc1.weight\n",
      "\t features.14.block.2.fc1.bias\n",
      "\t features.14.block.2.fc2.weight\n",
      "\t features.14.block.2.fc2.bias\n",
      "\t features.14.block.3.0.weight\n",
      "\t features.14.block.3.1.weight\n",
      "\t features.14.block.3.1.bias\n",
      "\t features.15.block.0.0.weight\n",
      "\t features.15.block.0.1.weight\n",
      "\t features.15.block.0.1.bias\n",
      "\t features.15.block.1.0.weight\n",
      "\t features.15.block.1.1.weight\n",
      "\t features.15.block.1.1.bias\n",
      "\t features.15.block.2.fc1.weight\n",
      "\t features.15.block.2.fc1.bias\n",
      "\t features.15.block.2.fc2.weight\n",
      "\t features.15.block.2.fc2.bias\n",
      "\t features.15.block.3.0.weight\n",
      "\t features.15.block.3.1.weight\n",
      "\t features.15.block.3.1.bias\n",
      "\t features.16.0.weight\n",
      "\t features.16.1.weight\n",
      "\t features.16.1.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/640], Loss: 1.2292, Accuracy: 22.86%\n",
      "Epoch [1/100], Step [200/640], Loss: 1.0658, Accuracy: 25.29%\n",
      "Epoch [1/100], Step [300/640], Loss: 1.0245, Accuracy: 26.00%\n",
      "Epoch [1/100], Step [400/640], Loss: 0.9793, Accuracy: 26.29%\n",
      "Epoch [1/100], Step [500/640], Loss: 0.9893, Accuracy: 25.86%\n",
      "Epoch [1/100], Step [600/640], Loss: 1.2658, Accuracy: 24.29%\n",
      "train Loss: 1.1141 Acc: 0.7683\n",
      "Epoch [1/100], Step [100/640], Loss: 1.4781, Accuracy: 20.57%\n",
      "val Loss: 1.3171 Acc: 0.6782\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/640], Loss: 1.1671, Accuracy: 22.57%\n",
      "Epoch [2/100], Step [200/640], Loss: 1.0959, Accuracy: 24.71%\n",
      "Epoch [2/100], Step [300/640], Loss: 1.1776, Accuracy: 24.86%\n",
      "Epoch [2/100], Step [400/640], Loss: 1.0343, Accuracy: 26.71%\n",
      "Epoch [2/100], Step [500/640], Loss: 0.9758, Accuracy: 25.71%\n",
      "Epoch [2/100], Step [600/640], Loss: 1.0793, Accuracy: 23.86%\n",
      "train Loss: 1.0642 Acc: 0.7803\n",
      "Epoch [2/100], Step [100/640], Loss: 1.1486, Accuracy: 20.86%\n",
      "val Loss: 1.1011 Acc: 0.7132\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/640], Loss: 0.9858, Accuracy: 26.43%\n",
      "Epoch [3/100], Step [200/640], Loss: 1.1394, Accuracy: 24.57%\n",
      "Epoch [3/100], Step [300/640], Loss: 1.0080, Accuracy: 25.14%\n",
      "Epoch [3/100], Step [400/640], Loss: 1.1505, Accuracy: 23.86%\n",
      "Epoch [3/100], Step [500/640], Loss: 0.9542, Accuracy: 25.29%\n",
      "Epoch [3/100], Step [600/640], Loss: 0.9614, Accuracy: 26.43%\n",
      "train Loss: 1.0610 Acc: 0.7756\n",
      "Epoch [3/100], Step [100/640], Loss: 1.1783, Accuracy: 20.71%\n",
      "val Loss: 1.1135 Acc: 0.6728\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/640], Loss: 1.0835, Accuracy: 23.00%\n",
      "Epoch [4/100], Step [200/640], Loss: 1.0009, Accuracy: 24.86%\n",
      "Epoch [4/100], Step [300/640], Loss: 1.0796, Accuracy: 23.86%\n",
      "Epoch [4/100], Step [400/640], Loss: 1.0429, Accuracy: 25.57%\n",
      "Epoch [4/100], Step [500/640], Loss: 1.0266, Accuracy: 24.71%\n",
      "Epoch [4/100], Step [600/640], Loss: 1.1375, Accuracy: 24.86%\n",
      "train Loss: 1.0522 Acc: 0.7685\n",
      "Epoch [4/100], Step [100/640], Loss: 1.3678, Accuracy: 17.29%\n",
      "val Loss: 1.2433 Acc: 0.6267\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/640], Loss: 1.2076, Accuracy: 24.86%\n",
      "Epoch [5/100], Step [200/640], Loss: 1.1278, Accuracy: 23.00%\n",
      "Epoch [5/100], Step [300/640], Loss: 1.1448, Accuracy: 24.29%\n",
      "Epoch [5/100], Step [400/640], Loss: 0.9339, Accuracy: 26.29%\n",
      "Epoch [5/100], Step [500/640], Loss: 0.9697, Accuracy: 24.14%\n",
      "Epoch [5/100], Step [600/640], Loss: 1.1706, Accuracy: 22.14%\n",
      "train Loss: 1.0541 Acc: 0.7658\n",
      "Epoch [5/100], Step [100/640], Loss: 1.2481, Accuracy: 20.14%\n",
      "val Loss: 1.2018 Acc: 0.6829\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/640], Loss: 0.9858, Accuracy: 25.00%\n",
      "Epoch [6/100], Step [200/640], Loss: 1.0714, Accuracy: 24.14%\n",
      "Epoch [6/100], Step [300/640], Loss: 1.1513, Accuracy: 25.71%\n",
      "Epoch [6/100], Step [400/640], Loss: 1.0730, Accuracy: 24.14%\n",
      "Epoch [6/100], Step [500/640], Loss: 1.0483, Accuracy: 23.71%\n",
      "Epoch [6/100], Step [600/640], Loss: 1.2079, Accuracy: 23.71%\n",
      "train Loss: 1.0511 Acc: 0.7651\n",
      "Epoch [6/100], Step [100/640], Loss: 1.1844, Accuracy: 22.43%\n",
      "val Loss: 1.0532 Acc: 0.7403\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/640], Loss: 1.1217, Accuracy: 22.43%\n",
      "Epoch [7/100], Step [200/640], Loss: 0.9739, Accuracy: 23.86%\n",
      "Epoch [7/100], Step [300/640], Loss: 1.0137, Accuracy: 25.29%\n",
      "Epoch [7/100], Step [400/640], Loss: 1.0775, Accuracy: 21.86%\n",
      "Epoch [7/100], Step [500/640], Loss: 0.9751, Accuracy: 24.43%\n",
      "Epoch [7/100], Step [600/640], Loss: 1.1029, Accuracy: 23.71%\n",
      "train Loss: 1.0517 Acc: 0.7568\n",
      "Epoch [7/100], Step [100/640], Loss: 1.1087, Accuracy: 24.14%\n",
      "val Loss: 1.0411 Acc: 0.7629\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/640], Loss: 1.0350, Accuracy: 24.57%\n",
      "Epoch [8/100], Step [200/640], Loss: 1.0793, Accuracy: 25.00%\n",
      "Epoch [8/100], Step [300/640], Loss: 0.9917, Accuracy: 23.43%\n",
      "Epoch [8/100], Step [400/640], Loss: 1.2868, Accuracy: 21.71%\n",
      "Epoch [8/100], Step [500/640], Loss: 1.0586, Accuracy: 22.14%\n",
      "Epoch [8/100], Step [600/640], Loss: 1.0377, Accuracy: 25.29%\n",
      "train Loss: 1.0449 Acc: 0.7615\n",
      "Epoch [8/100], Step [100/640], Loss: 1.0779, Accuracy: 24.14%\n",
      "val Loss: 1.0297 Acc: 0.7591\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/640], Loss: 1.0188, Accuracy: 22.86%\n",
      "Epoch [9/100], Step [200/640], Loss: 1.1683, Accuracy: 23.43%\n",
      "Epoch [9/100], Step [300/640], Loss: 1.0696, Accuracy: 23.71%\n",
      "Epoch [9/100], Step [400/640], Loss: 1.0413, Accuracy: 23.57%\n",
      "Epoch [9/100], Step [500/640], Loss: 0.9547, Accuracy: 24.71%\n",
      "Epoch [9/100], Step [600/640], Loss: 1.0841, Accuracy: 24.43%\n",
      "train Loss: 1.0420 Acc: 0.7567\n",
      "Epoch [9/100], Step [100/640], Loss: 1.2490, Accuracy: 22.29%\n",
      "val Loss: 1.0663 Acc: 0.7371\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/640], Loss: 0.9955, Accuracy: 24.71%\n",
      "Epoch [10/100], Step [200/640], Loss: 1.1533, Accuracy: 23.86%\n",
      "Epoch [10/100], Step [300/640], Loss: 1.1363, Accuracy: 25.00%\n",
      "Epoch [10/100], Step [400/640], Loss: 1.1331, Accuracy: 21.14%\n",
      "Epoch [10/100], Step [500/640], Loss: 1.0633, Accuracy: 23.57%\n",
      "Epoch [10/100], Step [600/640], Loss: 1.0682, Accuracy: 22.71%\n",
      "train Loss: 1.0451 Acc: 0.7573\n",
      "Epoch [10/100], Step [100/640], Loss: 1.6932, Accuracy: 22.43%\n",
      "val Loss: 1.4535 Acc: 0.7149\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/640], Loss: 0.9528, Accuracy: 24.71%\n",
      "Epoch [11/100], Step [200/640], Loss: 0.9522, Accuracy: 23.86%\n",
      "Epoch [11/100], Step [300/640], Loss: 1.0031, Accuracy: 25.14%\n",
      "Epoch [11/100], Step [400/640], Loss: 1.1308, Accuracy: 24.43%\n",
      "Epoch [11/100], Step [500/640], Loss: 1.0069, Accuracy: 24.29%\n",
      "Epoch [11/100], Step [600/640], Loss: 0.9428, Accuracy: 24.43%\n",
      "train Loss: 1.0391 Acc: 0.7575\n",
      "Epoch [11/100], Step [100/640], Loss: 1.6375, Accuracy: 20.86%\n",
      "val Loss: 1.2215 Acc: 0.7044\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/640], Loss: 0.9654, Accuracy: 23.57%\n",
      "Epoch [12/100], Step [200/640], Loss: 0.9973, Accuracy: 24.00%\n",
      "Epoch [12/100], Step [300/640], Loss: 1.0765, Accuracy: 21.14%\n",
      "Epoch [12/100], Step [400/640], Loss: 0.9089, Accuracy: 26.00%\n",
      "Epoch [12/100], Step [500/640], Loss: 0.9281, Accuracy: 25.86%\n",
      "Epoch [12/100], Step [600/640], Loss: 1.0617, Accuracy: 24.00%\n",
      "train Loss: 1.0277 Acc: 0.7606\n",
      "Epoch [12/100], Step [100/640], Loss: 1.1695, Accuracy: 23.57%\n",
      "val Loss: 1.0809 Acc: 0.7549\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/640], Loss: 1.1412, Accuracy: 24.71%\n",
      "Epoch [13/100], Step [200/640], Loss: 1.0858, Accuracy: 24.29%\n",
      "Epoch [13/100], Step [300/640], Loss: 0.9510, Accuracy: 24.43%\n",
      "Epoch [13/100], Step [400/640], Loss: 0.9809, Accuracy: 25.86%\n",
      "Epoch [13/100], Step [500/640], Loss: 1.0173, Accuracy: 24.00%\n",
      "Epoch [13/100], Step [600/640], Loss: 1.2818, Accuracy: 20.57%\n",
      "train Loss: 1.0294 Acc: 0.7563\n",
      "Epoch [13/100], Step [100/640], Loss: 1.1999, Accuracy: 23.29%\n",
      "val Loss: 1.0318 Acc: 0.7729\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/640], Loss: 0.9721, Accuracy: 25.00%\n",
      "Epoch [14/100], Step [200/640], Loss: 0.9453, Accuracy: 23.57%\n",
      "Epoch [14/100], Step [300/640], Loss: 1.3491, Accuracy: 23.14%\n",
      "Epoch [14/100], Step [400/640], Loss: 1.0568, Accuracy: 26.14%\n",
      "Epoch [14/100], Step [500/640], Loss: 0.9143, Accuracy: 25.71%\n",
      "Epoch [14/100], Step [600/640], Loss: 0.9242, Accuracy: 25.14%\n",
      "train Loss: 1.0233 Acc: 0.7559\n",
      "Epoch [14/100], Step [100/640], Loss: 1.1801, Accuracy: 23.14%\n",
      "val Loss: 1.0252 Acc: 0.7724\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/640], Loss: 1.0492, Accuracy: 23.86%\n",
      "Epoch [15/100], Step [200/640], Loss: 0.9563, Accuracy: 23.14%\n",
      "Epoch [15/100], Step [300/640], Loss: 1.0180, Accuracy: 25.00%\n",
      "Epoch [15/100], Step [400/640], Loss: 1.1000, Accuracy: 23.00%\n",
      "Epoch [15/100], Step [500/640], Loss: 0.9200, Accuracy: 25.71%\n",
      "Epoch [15/100], Step [600/640], Loss: 1.0030, Accuracy: 24.86%\n",
      "train Loss: 1.0236 Acc: 0.7571\n",
      "Epoch [15/100], Step [100/640], Loss: 1.3839, Accuracy: 22.00%\n",
      "val Loss: 1.1709 Acc: 0.7298\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/640], Loss: 1.0894, Accuracy: 24.71%\n",
      "Epoch [16/100], Step [200/640], Loss: 1.1783, Accuracy: 24.00%\n",
      "Epoch [16/100], Step [300/640], Loss: 1.2477, Accuracy: 21.71%\n",
      "Epoch [16/100], Step [400/640], Loss: 1.1615, Accuracy: 24.57%\n",
      "Epoch [16/100], Step [500/640], Loss: 0.9917, Accuracy: 24.14%\n",
      "Epoch [16/100], Step [600/640], Loss: 1.0210, Accuracy: 25.57%\n",
      "train Loss: 1.0149 Acc: 0.7596\n",
      "Epoch [16/100], Step [100/640], Loss: 1.0788, Accuracy: 21.14%\n",
      "val Loss: 1.1424 Acc: 0.6208\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/640], Loss: 1.0603, Accuracy: 23.57%\n",
      "Epoch [17/100], Step [200/640], Loss: 0.9713, Accuracy: 25.14%\n",
      "Epoch [17/100], Step [300/640], Loss: 0.9518, Accuracy: 25.57%\n",
      "Epoch [17/100], Step [400/640], Loss: 1.0207, Accuracy: 23.14%\n",
      "Epoch [17/100], Step [500/640], Loss: 0.9119, Accuracy: 25.29%\n",
      "Epoch [17/100], Step [600/640], Loss: 0.9969, Accuracy: 22.43%\n",
      "train Loss: 1.0115 Acc: 0.7586\n",
      "Epoch [17/100], Step [100/640], Loss: 1.2269, Accuracy: 20.86%\n",
      "val Loss: 1.1398 Acc: 0.7243\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/640], Loss: 0.9790, Accuracy: 24.86%\n",
      "Epoch [18/100], Step [200/640], Loss: 0.9731, Accuracy: 25.29%\n",
      "Epoch [18/100], Step [300/640], Loss: 1.0174, Accuracy: 24.71%\n",
      "Epoch [18/100], Step [400/640], Loss: 0.8570, Accuracy: 25.57%\n",
      "Epoch [18/100], Step [500/640], Loss: 0.9214, Accuracy: 24.00%\n",
      "Epoch [18/100], Step [600/640], Loss: 0.9868, Accuracy: 22.43%\n",
      "train Loss: 1.0046 Acc: 0.7601\n",
      "Epoch [18/100], Step [100/640], Loss: 1.1769, Accuracy: 24.29%\n",
      "val Loss: 1.0346 Acc: 0.7973\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/640], Loss: 0.8695, Accuracy: 26.00%\n",
      "Epoch [19/100], Step [200/640], Loss: 0.8184, Accuracy: 26.86%\n",
      "Epoch [19/100], Step [300/640], Loss: 0.9798, Accuracy: 24.29%\n",
      "Epoch [19/100], Step [400/640], Loss: 0.8961, Accuracy: 25.71%\n",
      "Epoch [19/100], Step [500/640], Loss: 0.9146, Accuracy: 25.86%\n",
      "Epoch [19/100], Step [600/640], Loss: 1.0447, Accuracy: 22.43%\n",
      "train Loss: 1.0055 Acc: 0.7590\n",
      "Epoch [19/100], Step [100/640], Loss: 1.0643, Accuracy: 25.14%\n",
      "val Loss: 1.0216 Acc: 0.7682\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/640], Loss: 1.0526, Accuracy: 23.71%\n",
      "Epoch [20/100], Step [200/640], Loss: 0.8659, Accuracy: 25.57%\n",
      "Epoch [20/100], Step [300/640], Loss: 1.0998, Accuracy: 23.43%\n",
      "Epoch [20/100], Step [400/640], Loss: 1.0060, Accuracy: 25.14%\n",
      "Epoch [20/100], Step [500/640], Loss: 0.9296, Accuracy: 23.29%\n",
      "Epoch [20/100], Step [600/640], Loss: 0.9317, Accuracy: 25.43%\n",
      "train Loss: 1.0007 Acc: 0.7608\n",
      "Epoch [20/100], Step [100/640], Loss: 1.2474, Accuracy: 23.29%\n",
      "val Loss: 1.0273 Acc: 0.7635\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/640], Loss: 1.0552, Accuracy: 24.00%\n",
      "Epoch [21/100], Step [200/640], Loss: 0.9945, Accuracy: 24.71%\n",
      "Epoch [21/100], Step [300/640], Loss: 1.1288, Accuracy: 23.57%\n",
      "Epoch [21/100], Step [400/640], Loss: 1.1040, Accuracy: 24.71%\n",
      "Epoch [21/100], Step [500/640], Loss: 1.0914, Accuracy: 23.86%\n",
      "Epoch [21/100], Step [600/640], Loss: 1.0374, Accuracy: 22.57%\n",
      "train Loss: 0.9934 Acc: 0.7639\n",
      "Epoch [21/100], Step [100/640], Loss: 1.2394, Accuracy: 22.14%\n",
      "val Loss: 1.0503 Acc: 0.7499\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/640], Loss: 0.9959, Accuracy: 23.71%\n",
      "Epoch [22/100], Step [200/640], Loss: 0.9016, Accuracy: 26.57%\n",
      "Epoch [22/100], Step [300/640], Loss: 1.1294, Accuracy: 20.86%\n",
      "Epoch [22/100], Step [400/640], Loss: 0.9405, Accuracy: 24.29%\n",
      "Epoch [22/100], Step [500/640], Loss: 1.0294, Accuracy: 24.29%\n",
      "Epoch [22/100], Step [600/640], Loss: 0.9261, Accuracy: 24.57%\n",
      "train Loss: 0.9970 Acc: 0.7577\n",
      "Epoch [22/100], Step [100/640], Loss: 1.1048, Accuracy: 23.29%\n",
      "val Loss: 0.9979 Acc: 0.7767\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/640], Loss: 0.9040, Accuracy: 25.57%\n",
      "Epoch [23/100], Step [200/640], Loss: 0.8738, Accuracy: 24.71%\n",
      "Epoch [23/100], Step [300/640], Loss: 0.8007, Accuracy: 25.43%\n",
      "Epoch [23/100], Step [400/640], Loss: 0.8803, Accuracy: 25.71%\n",
      "Epoch [23/100], Step [500/640], Loss: 1.0994, Accuracy: 23.57%\n",
      "Epoch [23/100], Step [600/640], Loss: 1.0737, Accuracy: 23.71%\n",
      "train Loss: 0.9887 Acc: 0.7625\n",
      "Epoch [23/100], Step [100/640], Loss: 0.9884, Accuracy: 24.43%\n",
      "val Loss: 1.0256 Acc: 0.7149\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/640], Loss: 0.9394, Accuracy: 25.00%\n",
      "Epoch [24/100], Step [200/640], Loss: 0.9672, Accuracy: 24.14%\n",
      "Epoch [24/100], Step [300/640], Loss: 0.9411, Accuracy: 24.86%\n",
      "Epoch [24/100], Step [400/640], Loss: 0.8211, Accuracy: 26.71%\n",
      "Epoch [24/100], Step [500/640], Loss: 1.0887, Accuracy: 23.00%\n",
      "Epoch [24/100], Step [600/640], Loss: 0.9086, Accuracy: 25.57%\n",
      "train Loss: 0.9816 Acc: 0.7646\n",
      "Epoch [24/100], Step [100/640], Loss: 1.0024, Accuracy: 23.86%\n",
      "val Loss: 1.0093 Acc: 0.7327\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/640], Loss: 1.0182, Accuracy: 25.29%\n",
      "Epoch [25/100], Step [200/640], Loss: 1.1108, Accuracy: 23.43%\n",
      "Epoch [25/100], Step [300/640], Loss: 1.0845, Accuracy: 23.00%\n",
      "Epoch [25/100], Step [400/640], Loss: 0.7992, Accuracy: 24.71%\n",
      "Epoch [25/100], Step [500/640], Loss: 1.0272, Accuracy: 25.14%\n",
      "Epoch [25/100], Step [600/640], Loss: 0.9875, Accuracy: 24.29%\n",
      "train Loss: 0.9808 Acc: 0.7628\n",
      "Epoch [25/100], Step [100/640], Loss: 1.0966, Accuracy: 23.86%\n",
      "val Loss: 0.9755 Acc: 0.7602\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/640], Loss: 1.0455, Accuracy: 24.43%\n",
      "Epoch [26/100], Step [200/640], Loss: 0.9616, Accuracy: 25.71%\n",
      "Epoch [26/100], Step [300/640], Loss: 0.9071, Accuracy: 26.00%\n",
      "Epoch [26/100], Step [400/640], Loss: 1.0632, Accuracy: 24.14%\n",
      "Epoch [26/100], Step [500/640], Loss: 0.9443, Accuracy: 26.14%\n",
      "Epoch [26/100], Step [600/640], Loss: 1.0316, Accuracy: 24.71%\n",
      "train Loss: 0.9750 Acc: 0.7671\n",
      "Epoch [26/100], Step [100/640], Loss: 0.9642, Accuracy: 23.00%\n",
      "val Loss: 1.0452 Acc: 0.6788\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/640], Loss: 1.0213, Accuracy: 24.86%\n",
      "Epoch [27/100], Step [200/640], Loss: 0.9392, Accuracy: 25.86%\n",
      "Epoch [27/100], Step [300/640], Loss: 0.9194, Accuracy: 25.86%\n",
      "Epoch [27/100], Step [400/640], Loss: 0.9391, Accuracy: 25.57%\n",
      "Epoch [27/100], Step [500/640], Loss: 0.9889, Accuracy: 23.43%\n",
      "Epoch [27/100], Step [600/640], Loss: 1.0971, Accuracy: 21.14%\n",
      "train Loss: 0.9723 Acc: 0.7668\n",
      "Epoch [27/100], Step [100/640], Loss: 0.9689, Accuracy: 24.29%\n",
      "val Loss: 1.0566 Acc: 0.7332\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/640], Loss: 0.9187, Accuracy: 22.43%\n",
      "Epoch [28/100], Step [200/640], Loss: 0.9698, Accuracy: 23.29%\n",
      "Epoch [28/100], Step [300/640], Loss: 1.3005, Accuracy: 19.71%\n",
      "Epoch [28/100], Step [400/640], Loss: 0.8671, Accuracy: 25.86%\n",
      "Epoch [28/100], Step [500/640], Loss: 0.9044, Accuracy: 25.71%\n",
      "Epoch [28/100], Step [600/640], Loss: 1.0137, Accuracy: 24.71%\n",
      "train Loss: 0.9741 Acc: 0.7638\n",
      "Epoch [28/100], Step [100/640], Loss: 1.2172, Accuracy: 23.14%\n",
      "val Loss: 1.0912 Acc: 0.7517\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/640], Loss: 1.0136, Accuracy: 24.57%\n",
      "Epoch [29/100], Step [200/640], Loss: 0.9789, Accuracy: 25.00%\n",
      "Epoch [29/100], Step [300/640], Loss: 0.9720, Accuracy: 24.71%\n",
      "Epoch [29/100], Step [400/640], Loss: 0.8434, Accuracy: 24.57%\n",
      "Epoch [29/100], Step [500/640], Loss: 0.9145, Accuracy: 24.14%\n",
      "Epoch [29/100], Step [600/640], Loss: 0.9273, Accuracy: 25.86%\n",
      "train Loss: 0.9611 Acc: 0.7695\n",
      "Epoch [29/100], Step [100/640], Loss: 1.2340, Accuracy: 22.86%\n",
      "val Loss: 1.0240 Acc: 0.7514\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/640], Loss: 0.7485, Accuracy: 26.29%\n",
      "Epoch [30/100], Step [200/640], Loss: 0.8651, Accuracy: 24.43%\n",
      "Epoch [30/100], Step [300/640], Loss: 1.0682, Accuracy: 22.29%\n",
      "Epoch [30/100], Step [400/640], Loss: 0.9307, Accuracy: 25.00%\n",
      "Epoch [30/100], Step [500/640], Loss: 1.1112, Accuracy: 23.14%\n",
      "Epoch [30/100], Step [600/640], Loss: 0.9892, Accuracy: 23.57%\n",
      "train Loss: 0.9640 Acc: 0.7685\n",
      "Epoch [30/100], Step [100/640], Loss: 1.0948, Accuracy: 24.71%\n",
      "val Loss: 0.9871 Acc: 0.7866\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/640], Loss: 1.0508, Accuracy: 24.14%\n",
      "Epoch [31/100], Step [200/640], Loss: 1.1221, Accuracy: 22.71%\n",
      "Epoch [31/100], Step [300/640], Loss: 0.8895, Accuracy: 24.86%\n",
      "Epoch [31/100], Step [400/640], Loss: 0.9953, Accuracy: 22.57%\n",
      "Epoch [31/100], Step [500/640], Loss: 0.8589, Accuracy: 25.14%\n",
      "Epoch [31/100], Step [600/640], Loss: 0.9494, Accuracy: 24.14%\n",
      "train Loss: 0.9545 Acc: 0.7701\n",
      "Epoch [31/100], Step [100/640], Loss: 1.1893, Accuracy: 23.57%\n",
      "val Loss: 1.0137 Acc: 0.7585\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/640], Loss: 0.9972, Accuracy: 24.14%\n",
      "Epoch [32/100], Step [200/640], Loss: 0.8397, Accuracy: 25.57%\n",
      "Epoch [32/100], Step [300/640], Loss: 0.7949, Accuracy: 26.29%\n",
      "Epoch [32/100], Step [400/640], Loss: 1.0426, Accuracy: 24.71%\n",
      "Epoch [32/100], Step [500/640], Loss: 1.0132, Accuracy: 23.00%\n",
      "Epoch [32/100], Step [600/640], Loss: 0.9914, Accuracy: 24.71%\n",
      "train Loss: 0.9547 Acc: 0.7707\n",
      "Epoch [32/100], Step [100/640], Loss: 0.9763, Accuracy: 23.14%\n",
      "val Loss: 1.0369 Acc: 0.7011\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/640], Loss: 1.0441, Accuracy: 23.57%\n",
      "Epoch [33/100], Step [200/640], Loss: 0.9254, Accuracy: 24.14%\n",
      "Epoch [33/100], Step [300/640], Loss: 0.8645, Accuracy: 25.29%\n",
      "Epoch [33/100], Step [400/640], Loss: 0.8463, Accuracy: 27.14%\n",
      "Epoch [33/100], Step [500/640], Loss: 0.9162, Accuracy: 23.86%\n",
      "Epoch [33/100], Step [600/640], Loss: 1.0500, Accuracy: 23.29%\n",
      "train Loss: 0.9462 Acc: 0.7726\n",
      "Epoch [33/100], Step [100/640], Loss: 1.0728, Accuracy: 25.29%\n",
      "val Loss: 0.9601 Acc: 0.7912\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/640], Loss: 0.8106, Accuracy: 25.00%\n",
      "Epoch [34/100], Step [200/640], Loss: 0.8881, Accuracy: 26.43%\n",
      "Epoch [34/100], Step [300/640], Loss: 1.0152, Accuracy: 24.14%\n",
      "Epoch [34/100], Step [400/640], Loss: 1.1826, Accuracy: 23.29%\n",
      "Epoch [34/100], Step [500/640], Loss: 0.9063, Accuracy: 24.86%\n",
      "Epoch [34/100], Step [600/640], Loss: 0.9777, Accuracy: 25.86%\n",
      "train Loss: 0.9457 Acc: 0.7731\n",
      "Epoch [34/100], Step [100/640], Loss: 1.0933, Accuracy: 24.14%\n",
      "val Loss: 0.9762 Acc: 0.7649\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/640], Loss: 0.7163, Accuracy: 27.14%\n",
      "Epoch [35/100], Step [200/640], Loss: 0.8735, Accuracy: 25.86%\n",
      "Epoch [35/100], Step [300/640], Loss: 0.9188, Accuracy: 25.57%\n",
      "Epoch [35/100], Step [400/640], Loss: 1.0968, Accuracy: 23.29%\n",
      "Epoch [35/100], Step [500/640], Loss: 0.9900, Accuracy: 24.57%\n",
      "Epoch [35/100], Step [600/640], Loss: 1.0261, Accuracy: 24.14%\n",
      "train Loss: 0.9393 Acc: 0.7757\n",
      "Epoch [35/100], Step [100/640], Loss: 1.0050, Accuracy: 24.29%\n",
      "val Loss: 0.9598 Acc: 0.7690\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/640], Loss: 1.0299, Accuracy: 24.43%\n",
      "Epoch [36/100], Step [200/640], Loss: 1.0114, Accuracy: 24.71%\n",
      "Epoch [36/100], Step [300/640], Loss: 0.6979, Accuracy: 27.29%\n",
      "Epoch [36/100], Step [400/640], Loss: 0.8900, Accuracy: 25.00%\n",
      "Epoch [36/100], Step [500/640], Loss: 0.9035, Accuracy: 25.14%\n",
      "Epoch [36/100], Step [600/640], Loss: 0.8582, Accuracy: 25.00%\n",
      "train Loss: 0.9356 Acc: 0.7746\n",
      "Epoch [36/100], Step [100/640], Loss: 0.9811, Accuracy: 25.00%\n",
      "val Loss: 0.9590 Acc: 0.7557\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/640], Loss: 0.9596, Accuracy: 24.43%\n",
      "Epoch [37/100], Step [200/640], Loss: 1.0098, Accuracy: 23.29%\n",
      "Epoch [37/100], Step [300/640], Loss: 0.9653, Accuracy: 24.86%\n",
      "Epoch [37/100], Step [400/640], Loss: 1.0211, Accuracy: 23.14%\n",
      "Epoch [37/100], Step [500/640], Loss: 1.0650, Accuracy: 24.71%\n",
      "Epoch [37/100], Step [600/640], Loss: 0.7308, Accuracy: 25.71%\n",
      "train Loss: 0.9333 Acc: 0.7771\n",
      "Epoch [37/100], Step [100/640], Loss: 0.9996, Accuracy: 25.00%\n",
      "val Loss: 1.0211 Acc: 0.7276\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/640], Loss: 0.8561, Accuracy: 26.00%\n",
      "Epoch [38/100], Step [200/640], Loss: 1.0436, Accuracy: 23.14%\n",
      "Epoch [38/100], Step [300/640], Loss: 0.8947, Accuracy: 25.14%\n",
      "Epoch [38/100], Step [400/640], Loss: 0.8227, Accuracy: 26.29%\n",
      "Epoch [38/100], Step [500/640], Loss: 1.0456, Accuracy: 25.71%\n",
      "Epoch [38/100], Step [600/640], Loss: 0.9638, Accuracy: 24.43%\n",
      "train Loss: 0.9342 Acc: 0.7756\n",
      "Epoch [38/100], Step [100/640], Loss: 0.9408, Accuracy: 24.86%\n",
      "val Loss: 0.9566 Acc: 0.7571\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/640], Loss: 1.0618, Accuracy: 24.57%\n",
      "Epoch [39/100], Step [200/640], Loss: 0.8580, Accuracy: 25.14%\n",
      "Epoch [39/100], Step [300/640], Loss: 0.9574, Accuracy: 24.57%\n",
      "Epoch [39/100], Step [400/640], Loss: 0.9665, Accuracy: 23.86%\n",
      "Epoch [39/100], Step [500/640], Loss: 0.8376, Accuracy: 26.14%\n",
      "Epoch [39/100], Step [600/640], Loss: 1.0193, Accuracy: 23.86%\n",
      "train Loss: 0.9250 Acc: 0.7781\n",
      "Epoch [39/100], Step [100/640], Loss: 1.2779, Accuracy: 23.43%\n",
      "val Loss: 0.9840 Acc: 0.7960\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/640], Loss: 0.8033, Accuracy: 24.86%\n",
      "Epoch [40/100], Step [200/640], Loss: 0.8007, Accuracy: 26.86%\n",
      "Epoch [40/100], Step [300/640], Loss: 0.8821, Accuracy: 25.14%\n",
      "Epoch [40/100], Step [400/640], Loss: 0.8940, Accuracy: 25.29%\n",
      "Epoch [40/100], Step [500/640], Loss: 0.8636, Accuracy: 25.71%\n",
      "Epoch [40/100], Step [600/640], Loss: 1.0517, Accuracy: 25.57%\n",
      "train Loss: 0.9195 Acc: 0.7809\n",
      "Epoch [40/100], Step [100/640], Loss: 0.9802, Accuracy: 24.86%\n",
      "val Loss: 0.9506 Acc: 0.7726\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/640], Loss: 0.9620, Accuracy: 23.14%\n",
      "Epoch [41/100], Step [200/640], Loss: 0.9787, Accuracy: 24.57%\n",
      "Epoch [41/100], Step [300/640], Loss: 0.9085, Accuracy: 24.71%\n",
      "Epoch [41/100], Step [400/640], Loss: 0.9129, Accuracy: 24.71%\n",
      "Epoch [41/100], Step [500/640], Loss: 0.8411, Accuracy: 25.29%\n",
      "Epoch [41/100], Step [600/640], Loss: 0.8150, Accuracy: 25.00%\n",
      "train Loss: 0.9173 Acc: 0.7795\n",
      "Epoch [41/100], Step [100/640], Loss: 1.0943, Accuracy: 24.29%\n",
      "val Loss: 0.9586 Acc: 0.7732\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/640], Loss: 0.9536, Accuracy: 24.57%\n",
      "Epoch [42/100], Step [200/640], Loss: 0.9229, Accuracy: 25.00%\n",
      "Epoch [42/100], Step [300/640], Loss: 0.9489, Accuracy: 26.43%\n",
      "Epoch [42/100], Step [400/640], Loss: 0.9848, Accuracy: 23.86%\n",
      "Epoch [42/100], Step [500/640], Loss: 1.1361, Accuracy: 25.14%\n",
      "Epoch [42/100], Step [600/640], Loss: 0.9336, Accuracy: 26.14%\n",
      "train Loss: 0.9093 Acc: 0.7838\n",
      "Epoch [42/100], Step [100/640], Loss: 1.0097, Accuracy: 25.14%\n",
      "val Loss: 0.9441 Acc: 0.7892\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/640], Loss: 0.7586, Accuracy: 25.43%\n",
      "Epoch [43/100], Step [200/640], Loss: 0.9095, Accuracy: 25.43%\n",
      "Epoch [43/100], Step [300/640], Loss: 0.9513, Accuracy: 24.86%\n",
      "Epoch [43/100], Step [400/640], Loss: 0.9274, Accuracy: 23.57%\n",
      "Epoch [43/100], Step [500/640], Loss: 0.9676, Accuracy: 25.43%\n",
      "Epoch [43/100], Step [600/640], Loss: 0.7921, Accuracy: 26.00%\n",
      "train Loss: 0.9102 Acc: 0.7822\n",
      "Epoch [43/100], Step [100/640], Loss: 1.2063, Accuracy: 22.57%\n",
      "val Loss: 0.9626 Acc: 0.7679\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/640], Loss: 0.8168, Accuracy: 25.00%\n",
      "Epoch [44/100], Step [200/640], Loss: 0.8243, Accuracy: 25.71%\n",
      "Epoch [44/100], Step [300/640], Loss: 0.9408, Accuracy: 24.86%\n",
      "Epoch [44/100], Step [400/640], Loss: 1.0867, Accuracy: 24.00%\n",
      "Epoch [44/100], Step [500/640], Loss: 0.9103, Accuracy: 25.86%\n",
      "Epoch [44/100], Step [600/640], Loss: 0.8343, Accuracy: 26.29%\n",
      "train Loss: 0.9126 Acc: 0.7813\n",
      "Epoch [44/100], Step [100/640], Loss: 0.9612, Accuracy: 25.14%\n",
      "val Loss: 0.9536 Acc: 0.7561\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/640], Loss: 0.8830, Accuracy: 25.14%\n",
      "Epoch [45/100], Step [200/640], Loss: 0.8272, Accuracy: 25.43%\n",
      "Epoch [45/100], Step [300/640], Loss: 0.9978, Accuracy: 26.43%\n",
      "Epoch [45/100], Step [400/640], Loss: 1.0103, Accuracy: 25.71%\n",
      "Epoch [45/100], Step [500/640], Loss: 0.8659, Accuracy: 24.29%\n",
      "Epoch [45/100], Step [600/640], Loss: 0.8992, Accuracy: 25.71%\n",
      "train Loss: 0.8959 Acc: 0.7842\n",
      "Epoch [45/100], Step [100/640], Loss: 1.0075, Accuracy: 24.71%\n",
      "val Loss: 0.9762 Acc: 0.7738\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/640], Loss: 0.7825, Accuracy: 25.00%\n",
      "Epoch [46/100], Step [200/640], Loss: 0.9549, Accuracy: 26.14%\n",
      "Epoch [46/100], Step [300/640], Loss: 0.9517, Accuracy: 25.00%\n",
      "Epoch [46/100], Step [400/640], Loss: 0.9510, Accuracy: 25.71%\n",
      "Epoch [46/100], Step [500/640], Loss: 0.9097, Accuracy: 25.71%\n",
      "Epoch [46/100], Step [600/640], Loss: 0.8166, Accuracy: 24.86%\n",
      "train Loss: 0.8951 Acc: 0.7861\n",
      "Epoch [46/100], Step [100/640], Loss: 1.0157, Accuracy: 24.57%\n",
      "val Loss: 0.9549 Acc: 0.7809\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/640], Loss: 0.8065, Accuracy: 26.14%\n",
      "Epoch [47/100], Step [200/640], Loss: 0.8945, Accuracy: 23.43%\n",
      "Epoch [47/100], Step [300/640], Loss: 1.0065, Accuracy: 24.00%\n",
      "Epoch [47/100], Step [400/640], Loss: 0.8371, Accuracy: 26.43%\n",
      "Epoch [47/100], Step [500/640], Loss: 0.7722, Accuracy: 26.00%\n",
      "Epoch [47/100], Step [600/640], Loss: 0.8910, Accuracy: 25.43%\n",
      "train Loss: 0.8856 Acc: 0.7876\n",
      "Epoch [47/100], Step [100/640], Loss: 1.1746, Accuracy: 24.43%\n",
      "val Loss: 0.9953 Acc: 0.7907\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/640], Loss: 0.8103, Accuracy: 25.71%\n",
      "Epoch [48/100], Step [200/640], Loss: 0.8323, Accuracy: 24.00%\n",
      "Epoch [48/100], Step [300/640], Loss: 1.0681, Accuracy: 25.29%\n",
      "Epoch [48/100], Step [400/640], Loss: 0.8300, Accuracy: 24.57%\n",
      "Epoch [48/100], Step [500/640], Loss: 0.9314, Accuracy: 26.14%\n",
      "Epoch [48/100], Step [600/640], Loss: 0.8520, Accuracy: 23.86%\n",
      "train Loss: 0.8848 Acc: 0.7872\n",
      "Epoch [48/100], Step [100/640], Loss: 1.0632, Accuracy: 23.57%\n",
      "val Loss: 0.9948 Acc: 0.7477\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/640], Loss: 0.8824, Accuracy: 26.14%\n",
      "Epoch [49/100], Step [200/640], Loss: 1.0142, Accuracy: 24.43%\n",
      "Epoch [49/100], Step [300/640], Loss: 0.8543, Accuracy: 24.86%\n",
      "Epoch [49/100], Step [400/640], Loss: 0.7519, Accuracy: 25.86%\n",
      "Epoch [49/100], Step [500/640], Loss: 0.8102, Accuracy: 25.43%\n",
      "Epoch [49/100], Step [600/640], Loss: 0.7572, Accuracy: 25.71%\n",
      "train Loss: 0.8743 Acc: 0.7895\n",
      "Epoch [49/100], Step [100/640], Loss: 0.9500, Accuracy: 23.86%\n",
      "val Loss: 1.0070 Acc: 0.7062\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/640], Loss: 0.8307, Accuracy: 26.86%\n",
      "Epoch [50/100], Step [200/640], Loss: 0.7646, Accuracy: 26.57%\n",
      "Epoch [50/100], Step [300/640], Loss: 1.1214, Accuracy: 24.43%\n",
      "Epoch [50/100], Step [400/640], Loss: 0.9040, Accuracy: 25.14%\n",
      "Epoch [50/100], Step [500/640], Loss: 1.0123, Accuracy: 24.57%\n",
      "Epoch [50/100], Step [600/640], Loss: 0.8533, Accuracy: 25.14%\n",
      "train Loss: 0.8725 Acc: 0.7893\n",
      "Epoch [50/100], Step [100/640], Loss: 0.9828, Accuracy: 25.29%\n",
      "val Loss: 1.0010 Acc: 0.7768\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/640], Loss: 0.9952, Accuracy: 24.43%\n",
      "Epoch [51/100], Step [200/640], Loss: 0.8777, Accuracy: 25.00%\n",
      "Epoch [51/100], Step [300/640], Loss: 0.8237, Accuracy: 24.86%\n",
      "Epoch [51/100], Step [400/640], Loss: 0.8103, Accuracy: 26.71%\n",
      "Epoch [51/100], Step [500/640], Loss: 0.8647, Accuracy: 23.14%\n",
      "Epoch [51/100], Step [600/640], Loss: 0.7998, Accuracy: 24.86%\n",
      "train Loss: 0.8648 Acc: 0.7902\n",
      "Epoch [51/100], Step [100/640], Loss: 1.0372, Accuracy: 23.57%\n",
      "val Loss: 0.9758 Acc: 0.7482\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/640], Loss: 0.9456, Accuracy: 23.14%\n",
      "Epoch [52/100], Step [200/640], Loss: 0.7953, Accuracy: 25.57%\n",
      "Epoch [52/100], Step [300/640], Loss: 0.7992, Accuracy: 24.86%\n",
      "Epoch [52/100], Step [400/640], Loss: 0.9438, Accuracy: 25.43%\n",
      "Epoch [52/100], Step [500/640], Loss: 0.8457, Accuracy: 25.86%\n",
      "Epoch [52/100], Step [600/640], Loss: 0.9924, Accuracy: 24.00%\n",
      "train Loss: 0.8659 Acc: 0.7904\n",
      "Epoch [52/100], Step [100/640], Loss: 1.0475, Accuracy: 23.00%\n",
      "val Loss: 0.9931 Acc: 0.7426\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/640], Loss: 1.0299, Accuracy: 25.00%\n",
      "Epoch [53/100], Step [200/640], Loss: 0.8029, Accuracy: 25.86%\n",
      "Epoch [53/100], Step [300/640], Loss: 0.9484, Accuracy: 23.00%\n",
      "Epoch [53/100], Step [400/640], Loss: 0.7940, Accuracy: 25.43%\n",
      "Epoch [53/100], Step [500/640], Loss: 0.8320, Accuracy: 25.86%\n",
      "Epoch [53/100], Step [600/640], Loss: 0.9559, Accuracy: 25.57%\n",
      "train Loss: 0.8538 Acc: 0.7931\n",
      "Epoch [53/100], Step [100/640], Loss: 1.0140, Accuracy: 24.43%\n",
      "val Loss: 0.9936 Acc: 0.7477\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/640], Loss: 0.8959, Accuracy: 25.29%\n",
      "Epoch [54/100], Step [200/640], Loss: 0.7323, Accuracy: 26.00%\n",
      "Epoch [54/100], Step [300/640], Loss: 0.8534, Accuracy: 24.71%\n",
      "Epoch [54/100], Step [400/640], Loss: 0.8634, Accuracy: 25.29%\n",
      "Epoch [54/100], Step [500/640], Loss: 0.8039, Accuracy: 24.57%\n",
      "Epoch [54/100], Step [600/640], Loss: 0.8128, Accuracy: 26.00%\n",
      "train Loss: 0.8458 Acc: 0.7949\n",
      "Epoch [54/100], Step [100/640], Loss: 1.1066, Accuracy: 23.86%\n",
      "val Loss: 1.0040 Acc: 0.7585\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/640], Loss: 1.0467, Accuracy: 23.86%\n",
      "Epoch [55/100], Step [200/640], Loss: 0.7498, Accuracy: 25.43%\n",
      "Epoch [55/100], Step [300/640], Loss: 0.8150, Accuracy: 25.14%\n",
      "Epoch [55/100], Step [400/640], Loss: 0.8846, Accuracy: 25.00%\n",
      "Epoch [55/100], Step [500/640], Loss: 0.8698, Accuracy: 25.57%\n",
      "Epoch [55/100], Step [600/640], Loss: 0.8949, Accuracy: 25.71%\n",
      "train Loss: 0.8385 Acc: 0.7947\n",
      "Epoch [55/100], Step [100/640], Loss: 1.1197, Accuracy: 24.14%\n",
      "val Loss: 0.9701 Acc: 0.7716\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/640], Loss: 0.8702, Accuracy: 24.57%\n",
      "Epoch [56/100], Step [200/640], Loss: 0.8658, Accuracy: 25.29%\n",
      "Epoch [56/100], Step [300/640], Loss: 0.8086, Accuracy: 25.86%\n",
      "Epoch [56/100], Step [400/640], Loss: 0.8802, Accuracy: 24.00%\n",
      "Epoch [56/100], Step [500/640], Loss: 0.8714, Accuracy: 26.29%\n",
      "Epoch [56/100], Step [600/640], Loss: 0.8632, Accuracy: 25.43%\n",
      "train Loss: 0.8351 Acc: 0.7949\n",
      "Epoch [56/100], Step [100/640], Loss: 1.1034, Accuracy: 22.57%\n",
      "val Loss: 0.9886 Acc: 0.7368\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/640], Loss: 0.7899, Accuracy: 26.43%\n",
      "Epoch [57/100], Step [200/640], Loss: 0.9653, Accuracy: 26.57%\n",
      "Epoch [57/100], Step [300/640], Loss: 0.7624, Accuracy: 25.57%\n",
      "Epoch [57/100], Step [400/640], Loss: 0.6471, Accuracy: 27.57%\n",
      "Epoch [57/100], Step [500/640], Loss: 0.7311, Accuracy: 25.43%\n",
      "Epoch [57/100], Step [600/640], Loss: 0.7700, Accuracy: 25.71%\n",
      "train Loss: 0.8261 Acc: 0.7968\n",
      "Epoch [57/100], Step [100/640], Loss: 1.2686, Accuracy: 23.43%\n",
      "val Loss: 1.0126 Acc: 0.7704\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/640], Loss: 0.9007, Accuracy: 23.71%\n",
      "Epoch [58/100], Step [200/640], Loss: 0.8179, Accuracy: 24.86%\n",
      "Epoch [58/100], Step [300/640], Loss: 0.7336, Accuracy: 26.57%\n",
      "Epoch [58/100], Step [400/640], Loss: 0.6814, Accuracy: 28.00%\n",
      "Epoch [58/100], Step [500/640], Loss: 0.9888, Accuracy: 24.71%\n",
      "Epoch [58/100], Step [600/640], Loss: 0.9642, Accuracy: 24.29%\n",
      "train Loss: 0.8243 Acc: 0.7971\n",
      "Epoch [58/100], Step [100/640], Loss: 1.3839, Accuracy: 22.86%\n",
      "val Loss: 1.0510 Acc: 0.7807\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/640], Loss: 0.7629, Accuracy: 25.00%\n",
      "Epoch [59/100], Step [200/640], Loss: 0.7246, Accuracy: 25.00%\n",
      "Epoch [59/100], Step [300/640], Loss: 0.8287, Accuracy: 25.29%\n",
      "Epoch [59/100], Step [400/640], Loss: 0.7874, Accuracy: 25.86%\n",
      "Epoch [59/100], Step [500/640], Loss: 0.8988, Accuracy: 25.57%\n",
      "Epoch [59/100], Step [600/640], Loss: 0.7577, Accuracy: 26.71%\n",
      "train Loss: 0.8119 Acc: 0.8008\n",
      "Epoch [59/100], Step [100/640], Loss: 1.2919, Accuracy: 22.43%\n",
      "val Loss: 1.0058 Acc: 0.7608\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/640], Loss: 0.9371, Accuracy: 23.71%\n",
      "Epoch [60/100], Step [200/640], Loss: 0.7250, Accuracy: 25.86%\n",
      "Epoch [60/100], Step [300/640], Loss: 0.8662, Accuracy: 24.86%\n",
      "Epoch [60/100], Step [400/640], Loss: 0.8055, Accuracy: 25.57%\n",
      "Epoch [60/100], Step [500/640], Loss: 0.9323, Accuracy: 25.29%\n",
      "Epoch [60/100], Step [600/640], Loss: 0.7174, Accuracy: 26.14%\n",
      "train Loss: 0.8079 Acc: 0.8010\n",
      "Epoch [60/100], Step [100/640], Loss: 1.1481, Accuracy: 25.43%\n",
      "val Loss: 1.0196 Acc: 0.7826\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/640], Loss: 0.6925, Accuracy: 26.57%\n",
      "Epoch [61/100], Step [200/640], Loss: 0.7510, Accuracy: 24.86%\n",
      "Epoch [61/100], Step [300/640], Loss: 0.8969, Accuracy: 23.71%\n",
      "Epoch [61/100], Step [400/640], Loss: 0.9050, Accuracy: 24.57%\n",
      "Epoch [61/100], Step [500/640], Loss: 0.6734, Accuracy: 26.86%\n",
      "Epoch [61/100], Step [600/640], Loss: 0.7529, Accuracy: 26.29%\n",
      "train Loss: 0.7966 Acc: 0.8014\n",
      "Epoch [61/100], Step [100/640], Loss: 1.1143, Accuracy: 25.00%\n",
      "val Loss: 1.0464 Acc: 0.7555\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/640], Loss: 0.6779, Accuracy: 25.57%\n",
      "Epoch [62/100], Step [200/640], Loss: 0.8122, Accuracy: 24.71%\n",
      "Epoch [62/100], Step [300/640], Loss: 0.8723, Accuracy: 25.86%\n",
      "Epoch [62/100], Step [400/640], Loss: 0.7313, Accuracy: 25.57%\n",
      "Epoch [62/100], Step [500/640], Loss: 0.7407, Accuracy: 26.43%\n",
      "Epoch [62/100], Step [600/640], Loss: 0.6541, Accuracy: 27.00%\n",
      "train Loss: 0.7903 Acc: 0.8022\n",
      "Epoch [62/100], Step [100/640], Loss: 1.5013, Accuracy: 23.71%\n",
      "val Loss: 1.0646 Acc: 0.7744\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/640], Loss: 0.7659, Accuracy: 26.29%\n",
      "Epoch [63/100], Step [200/640], Loss: 0.8742, Accuracy: 25.86%\n",
      "Epoch [63/100], Step [300/640], Loss: 0.6532, Accuracy: 27.00%\n",
      "Epoch [63/100], Step [400/640], Loss: 0.8046, Accuracy: 26.14%\n",
      "Epoch [63/100], Step [500/640], Loss: 0.7877, Accuracy: 26.29%\n",
      "Epoch [63/100], Step [600/640], Loss: 0.8146, Accuracy: 24.86%\n",
      "train Loss: 0.7819 Acc: 0.8037\n",
      "Epoch [63/100], Step [100/640], Loss: 1.3068, Accuracy: 24.14%\n",
      "val Loss: 1.1625 Acc: 0.7743\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/640], Loss: 0.6699, Accuracy: 25.86%\n",
      "Epoch [64/100], Step [200/640], Loss: 0.6366, Accuracy: 27.43%\n",
      "Epoch [64/100], Step [300/640], Loss: 0.7522, Accuracy: 25.00%\n",
      "Epoch [64/100], Step [400/640], Loss: 0.7090, Accuracy: 25.71%\n",
      "Epoch [64/100], Step [500/640], Loss: 0.8071, Accuracy: 25.86%\n",
      "Epoch [64/100], Step [600/640], Loss: 0.7904, Accuracy: 26.57%\n",
      "train Loss: 0.7759 Acc: 0.8047\n",
      "Epoch [64/100], Step [100/640], Loss: 1.2100, Accuracy: 24.57%\n",
      "val Loss: 1.0812 Acc: 0.7546\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/640], Loss: 0.7130, Accuracy: 24.86%\n",
      "Epoch [65/100], Step [200/640], Loss: 0.7708, Accuracy: 25.57%\n",
      "Epoch [65/100], Step [300/640], Loss: 0.7691, Accuracy: 24.86%\n",
      "Epoch [65/100], Step [400/640], Loss: 0.9221, Accuracy: 25.00%\n",
      "Epoch [65/100], Step [500/640], Loss: 0.9313, Accuracy: 24.86%\n",
      "Epoch [65/100], Step [600/640], Loss: 0.6596, Accuracy: 27.86%\n",
      "train Loss: 0.7699 Acc: 0.8061\n",
      "Epoch [65/100], Step [100/640], Loss: 1.3296, Accuracy: 24.29%\n",
      "val Loss: 1.0994 Acc: 0.7708\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/640], Loss: 0.8658, Accuracy: 25.71%\n",
      "Epoch [66/100], Step [200/640], Loss: 0.8000, Accuracy: 25.71%\n",
      "Epoch [66/100], Step [300/640], Loss: 0.7095, Accuracy: 27.71%\n",
      "Epoch [66/100], Step [400/640], Loss: 0.8504, Accuracy: 24.71%\n",
      "Epoch [66/100], Step [500/640], Loss: 0.7353, Accuracy: 27.43%\n",
      "Epoch [66/100], Step [600/640], Loss: 0.6007, Accuracy: 26.71%\n",
      "train Loss: 0.7575 Acc: 0.8094\n",
      "Epoch [66/100], Step [100/640], Loss: 1.2588, Accuracy: 24.57%\n",
      "val Loss: 1.0910 Acc: 0.7674\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/640], Loss: 0.8000, Accuracy: 26.86%\n",
      "Epoch [67/100], Step [200/640], Loss: 0.8628, Accuracy: 24.14%\n",
      "Epoch [67/100], Step [300/640], Loss: 0.6781, Accuracy: 26.00%\n",
      "Epoch [67/100], Step [400/640], Loss: 0.8191, Accuracy: 25.71%\n",
      "Epoch [67/100], Step [500/640], Loss: 0.7966, Accuracy: 26.00%\n",
      "Epoch [67/100], Step [600/640], Loss: 0.7324, Accuracy: 25.14%\n",
      "train Loss: 0.7509 Acc: 0.8103\n",
      "Epoch [67/100], Step [100/640], Loss: 1.4430, Accuracy: 24.00%\n",
      "val Loss: 1.1645 Acc: 0.7782\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/640], Loss: 0.6025, Accuracy: 26.14%\n",
      "Epoch [68/100], Step [200/640], Loss: 1.0149, Accuracy: 24.86%\n",
      "Epoch [68/100], Step [300/640], Loss: 0.7602, Accuracy: 25.71%\n",
      "Epoch [68/100], Step [400/640], Loss: 0.9241, Accuracy: 25.86%\n",
      "Epoch [68/100], Step [500/640], Loss: 0.8271, Accuracy: 25.71%\n",
      "Epoch [68/100], Step [600/640], Loss: 0.8415, Accuracy: 26.29%\n",
      "train Loss: 0.7467 Acc: 0.8116\n",
      "Epoch [68/100], Step [100/640], Loss: 1.3808, Accuracy: 24.14%\n",
      "val Loss: 1.1129 Acc: 0.7745\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/640], Loss: 0.8153, Accuracy: 25.57%\n",
      "Epoch [69/100], Step [200/640], Loss: 0.6742, Accuracy: 26.29%\n",
      "Epoch [69/100], Step [300/640], Loss: 0.8857, Accuracy: 24.43%\n",
      "Epoch [69/100], Step [400/640], Loss: 0.7274, Accuracy: 25.86%\n",
      "Epoch [69/100], Step [500/640], Loss: 0.7648, Accuracy: 26.00%\n",
      "Epoch [69/100], Step [600/640], Loss: 0.6660, Accuracy: 27.71%\n",
      "train Loss: 0.7293 Acc: 0.8150\n",
      "Epoch [69/100], Step [100/640], Loss: 1.3506, Accuracy: 23.71%\n",
      "val Loss: 1.1662 Acc: 0.7585\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/640], Loss: 0.7673, Accuracy: 26.29%\n",
      "Epoch [70/100], Step [200/640], Loss: 0.6714, Accuracy: 26.43%\n",
      "Epoch [70/100], Step [300/640], Loss: 0.9102, Accuracy: 25.29%\n",
      "Epoch [70/100], Step [400/640], Loss: 0.7113, Accuracy: 25.86%\n",
      "Epoch [70/100], Step [500/640], Loss: 0.7120, Accuracy: 26.14%\n",
      "Epoch [70/100], Step [600/640], Loss: 0.6436, Accuracy: 27.29%\n",
      "train Loss: 0.7275 Acc: 0.8126\n",
      "Epoch [70/100], Step [100/640], Loss: 1.3573, Accuracy: 23.71%\n",
      "val Loss: 1.1097 Acc: 0.7560\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/640], Loss: 0.7593, Accuracy: 25.86%\n",
      "Epoch [71/100], Step [200/640], Loss: 0.7166, Accuracy: 25.71%\n",
      "Epoch [71/100], Step [300/640], Loss: 0.7237, Accuracy: 27.00%\n",
      "Epoch [71/100], Step [400/640], Loss: 0.6780, Accuracy: 27.43%\n",
      "Epoch [71/100], Step [500/640], Loss: 0.7198, Accuracy: 26.29%\n",
      "Epoch [71/100], Step [600/640], Loss: 0.7108, Accuracy: 26.00%\n",
      "train Loss: 0.7169 Acc: 0.8165\n",
      "Epoch [71/100], Step [100/640], Loss: 1.4805, Accuracy: 24.71%\n",
      "val Loss: 1.2563 Acc: 0.7778\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/640], Loss: 0.6510, Accuracy: 26.57%\n",
      "Epoch [72/100], Step [200/640], Loss: 0.5223, Accuracy: 27.86%\n",
      "Epoch [72/100], Step [300/640], Loss: 0.5997, Accuracy: 26.57%\n",
      "Epoch [72/100], Step [400/640], Loss: 0.7225, Accuracy: 25.29%\n",
      "Epoch [72/100], Step [500/640], Loss: 0.6350, Accuracy: 26.71%\n",
      "Epoch [72/100], Step [600/640], Loss: 0.7296, Accuracy: 25.57%\n",
      "train Loss: 0.7096 Acc: 0.8182\n",
      "Epoch [72/100], Step [100/640], Loss: 1.3639, Accuracy: 24.00%\n",
      "val Loss: 1.2432 Acc: 0.7662\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/640], Loss: 0.8545, Accuracy: 25.71%\n",
      "Epoch [73/100], Step [200/640], Loss: 0.7721, Accuracy: 26.29%\n",
      "Epoch [73/100], Step [300/640], Loss: 0.6186, Accuracy: 26.86%\n",
      "Epoch [73/100], Step [400/640], Loss: 0.7235, Accuracy: 26.29%\n",
      "Epoch [73/100], Step [500/640], Loss: 0.7155, Accuracy: 26.57%\n",
      "Epoch [73/100], Step [600/640], Loss: 0.6600, Accuracy: 26.43%\n",
      "train Loss: 0.7035 Acc: 0.8205\n",
      "Epoch [73/100], Step [100/640], Loss: 1.3109, Accuracy: 24.71%\n",
      "val Loss: 1.2433 Acc: 0.7642\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/640], Loss: 0.7047, Accuracy: 25.57%\n",
      "Epoch [74/100], Step [200/640], Loss: 0.6473, Accuracy: 27.14%\n",
      "Epoch [74/100], Step [300/640], Loss: 0.8094, Accuracy: 26.14%\n",
      "Epoch [74/100], Step [400/640], Loss: 0.6647, Accuracy: 25.71%\n",
      "Epoch [74/100], Step [500/640], Loss: 0.7737, Accuracy: 25.43%\n",
      "Epoch [74/100], Step [600/640], Loss: 0.7300, Accuracy: 26.29%\n",
      "train Loss: 0.6939 Acc: 0.8222\n",
      "Epoch [74/100], Step [100/640], Loss: 1.4121, Accuracy: 24.86%\n",
      "val Loss: 1.2779 Acc: 0.7602\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/640], Loss: 0.6102, Accuracy: 26.14%\n",
      "Epoch [75/100], Step [200/640], Loss: 0.6838, Accuracy: 26.43%\n",
      "Epoch [75/100], Step [300/640], Loss: 0.6833, Accuracy: 26.29%\n",
      "Epoch [75/100], Step [400/640], Loss: 0.7812, Accuracy: 26.00%\n",
      "Epoch [75/100], Step [500/640], Loss: 0.8219, Accuracy: 25.29%\n",
      "Epoch [75/100], Step [600/640], Loss: 0.6161, Accuracy: 26.00%\n",
      "train Loss: 0.6858 Acc: 0.8228\n",
      "Epoch [75/100], Step [100/640], Loss: 1.4101, Accuracy: 23.71%\n",
      "val Loss: 1.2542 Acc: 0.7591\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/640], Loss: 0.5270, Accuracy: 27.71%\n",
      "Epoch [76/100], Step [200/640], Loss: 0.6498, Accuracy: 25.43%\n",
      "Epoch [76/100], Step [300/640], Loss: 0.7367, Accuracy: 26.14%\n",
      "Epoch [76/100], Step [400/640], Loss: 0.6021, Accuracy: 27.00%\n",
      "Epoch [76/100], Step [500/640], Loss: 0.6174, Accuracy: 26.43%\n",
      "Epoch [76/100], Step [600/640], Loss: 0.6983, Accuracy: 25.57%\n",
      "train Loss: 0.6802 Acc: 0.8256\n",
      "Epoch [76/100], Step [100/640], Loss: 1.3299, Accuracy: 24.29%\n",
      "val Loss: 1.2898 Acc: 0.7603\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/640], Loss: 0.6567, Accuracy: 27.14%\n",
      "Epoch [77/100], Step [200/640], Loss: 0.6317, Accuracy: 27.86%\n",
      "Epoch [77/100], Step [300/640], Loss: 0.7492, Accuracy: 25.71%\n",
      "Epoch [77/100], Step [400/640], Loss: 0.7951, Accuracy: 25.14%\n",
      "Epoch [77/100], Step [500/640], Loss: 0.5791, Accuracy: 26.86%\n",
      "Epoch [77/100], Step [600/640], Loss: 0.8577, Accuracy: 25.86%\n",
      "train Loss: 0.6721 Acc: 0.8261\n",
      "Epoch [77/100], Step [100/640], Loss: 1.6036, Accuracy: 23.43%\n",
      "val Loss: 1.3889 Acc: 0.7604\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/640], Loss: 0.5199, Accuracy: 27.71%\n",
      "Epoch [78/100], Step [200/640], Loss: 0.7540, Accuracy: 26.86%\n",
      "Epoch [78/100], Step [300/640], Loss: 0.6992, Accuracy: 25.71%\n",
      "Epoch [78/100], Step [400/640], Loss: 0.7615, Accuracy: 25.43%\n",
      "Epoch [78/100], Step [500/640], Loss: 0.6330, Accuracy: 26.71%\n",
      "Epoch [78/100], Step [600/640], Loss: 0.6881, Accuracy: 25.71%\n",
      "train Loss: 0.6653 Acc: 0.8268\n",
      "Epoch [78/100], Step [100/640], Loss: 1.6739, Accuracy: 23.00%\n",
      "val Loss: 1.3334 Acc: 0.7583\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/640], Loss: 0.6120, Accuracy: 27.00%\n",
      "Epoch [79/100], Step [200/640], Loss: 0.7434, Accuracy: 24.86%\n",
      "Epoch [79/100], Step [300/640], Loss: 0.8363, Accuracy: 26.29%\n",
      "Epoch [79/100], Step [400/640], Loss: 0.7253, Accuracy: 26.86%\n",
      "Epoch [79/100], Step [500/640], Loss: 0.7294, Accuracy: 25.14%\n",
      "Epoch [79/100], Step [600/640], Loss: 0.6310, Accuracy: 27.71%\n",
      "train Loss: 0.6683 Acc: 0.8274\n",
      "Epoch [79/100], Step [100/640], Loss: 1.4196, Accuracy: 24.14%\n",
      "val Loss: 1.3866 Acc: 0.7646\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/640], Loss: 0.5974, Accuracy: 26.71%\n",
      "Epoch [80/100], Step [200/640], Loss: 0.7310, Accuracy: 26.43%\n",
      "Epoch [80/100], Step [300/640], Loss: 0.9728, Accuracy: 25.29%\n",
      "Epoch [80/100], Step [400/640], Loss: 0.7084, Accuracy: 26.57%\n",
      "Epoch [80/100], Step [500/640], Loss: 0.6957, Accuracy: 26.86%\n",
      "Epoch [80/100], Step [600/640], Loss: 0.7451, Accuracy: 24.86%\n",
      "train Loss: 0.6503 Acc: 0.8318\n",
      "Epoch [80/100], Step [100/640], Loss: 1.5962, Accuracy: 23.86%\n",
      "val Loss: 1.4017 Acc: 0.7580\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/640], Loss: 0.6152, Accuracy: 27.14%\n",
      "Epoch [81/100], Step [200/640], Loss: 0.7465, Accuracy: 25.71%\n",
      "Epoch [81/100], Step [300/640], Loss: 0.5969, Accuracy: 26.14%\n",
      "Epoch [81/100], Step [400/640], Loss: 0.7001, Accuracy: 26.71%\n",
      "Epoch [81/100], Step [500/640], Loss: 0.6834, Accuracy: 25.43%\n",
      "Epoch [81/100], Step [600/640], Loss: 0.6058, Accuracy: 27.00%\n",
      "train Loss: 0.6448 Acc: 0.8314\n",
      "Epoch [81/100], Step [100/640], Loss: 1.6234, Accuracy: 23.71%\n",
      "val Loss: 1.3647 Acc: 0.7484\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/640], Loss: 0.7302, Accuracy: 26.29%\n",
      "Epoch [82/100], Step [200/640], Loss: 0.5308, Accuracy: 26.86%\n",
      "Epoch [82/100], Step [300/640], Loss: 0.5542, Accuracy: 26.71%\n",
      "Epoch [82/100], Step [400/640], Loss: 0.6744, Accuracy: 25.71%\n",
      "Epoch [82/100], Step [500/640], Loss: 0.7151, Accuracy: 27.71%\n",
      "Epoch [82/100], Step [600/640], Loss: 0.6387, Accuracy: 25.86%\n",
      "train Loss: 0.6503 Acc: 0.8310\n",
      "Epoch [82/100], Step [100/640], Loss: 1.8260, Accuracy: 23.43%\n",
      "val Loss: 1.4763 Acc: 0.7683\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/640], Loss: 0.6296, Accuracy: 26.86%\n",
      "Epoch [83/100], Step [200/640], Loss: 0.5961, Accuracy: 27.86%\n",
      "Epoch [83/100], Step [300/640], Loss: 0.5130, Accuracy: 28.00%\n",
      "Epoch [83/100], Step [400/640], Loss: 0.6062, Accuracy: 26.86%\n",
      "Epoch [83/100], Step [500/640], Loss: 0.5328, Accuracy: 27.71%\n",
      "Epoch [83/100], Step [600/640], Loss: 0.6546, Accuracy: 25.71%\n",
      "train Loss: 0.6326 Acc: 0.8359\n",
      "Epoch [83/100], Step [100/640], Loss: 1.6254, Accuracy: 24.71%\n",
      "val Loss: 1.5198 Acc: 0.7608\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/640], Loss: 0.4736, Accuracy: 27.71%\n",
      "Epoch [84/100], Step [200/640], Loss: 0.4869, Accuracy: 27.43%\n",
      "Epoch [84/100], Step [300/640], Loss: 0.6300, Accuracy: 28.00%\n",
      "Epoch [84/100], Step [400/640], Loss: 0.5809, Accuracy: 26.14%\n",
      "Epoch [84/100], Step [500/640], Loss: 0.5643, Accuracy: 27.57%\n",
      "Epoch [84/100], Step [600/640], Loss: 0.7784, Accuracy: 25.29%\n",
      "train Loss: 0.6245 Acc: 0.8384\n",
      "Epoch [84/100], Step [100/640], Loss: 2.0028, Accuracy: 24.00%\n",
      "val Loss: 1.5668 Acc: 0.7684\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/640], Loss: 0.6227, Accuracy: 27.43%\n",
      "Epoch [85/100], Step [200/640], Loss: 0.6209, Accuracy: 27.43%\n",
      "Epoch [85/100], Step [300/640], Loss: 0.4636, Accuracy: 28.57%\n",
      "Epoch [85/100], Step [400/640], Loss: 0.7575, Accuracy: 25.57%\n",
      "Epoch [85/100], Step [500/640], Loss: 0.6295, Accuracy: 26.43%\n",
      "Epoch [85/100], Step [600/640], Loss: 0.6859, Accuracy: 27.00%\n",
      "train Loss: 0.6182 Acc: 0.8379\n",
      "Epoch [85/100], Step [100/640], Loss: 1.7662, Accuracy: 24.43%\n",
      "val Loss: 1.5461 Acc: 0.7553\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/640], Loss: 0.6064, Accuracy: 25.29%\n",
      "Epoch [86/100], Step [200/640], Loss: 0.6094, Accuracy: 26.00%\n",
      "Epoch [86/100], Step [300/640], Loss: 0.6247, Accuracy: 26.71%\n",
      "Epoch [86/100], Step [400/640], Loss: 0.6550, Accuracy: 25.86%\n",
      "Epoch [86/100], Step [500/640], Loss: 0.5589, Accuracy: 26.86%\n",
      "Epoch [86/100], Step [600/640], Loss: 0.5940, Accuracy: 26.71%\n",
      "train Loss: 0.6136 Acc: 0.8391\n",
      "Epoch [86/100], Step [100/640], Loss: 1.4972, Accuracy: 23.57%\n",
      "val Loss: 1.4832 Acc: 0.7494\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/640], Loss: 0.4757, Accuracy: 27.57%\n",
      "Epoch [87/100], Step [200/640], Loss: 0.7267, Accuracy: 26.00%\n",
      "Epoch [87/100], Step [300/640], Loss: 0.5259, Accuracy: 28.14%\n",
      "Epoch [87/100], Step [400/640], Loss: 0.5779, Accuracy: 26.57%\n",
      "Epoch [87/100], Step [500/640], Loss: 0.5916, Accuracy: 26.86%\n",
      "Epoch [87/100], Step [600/640], Loss: 0.6177, Accuracy: 25.14%\n",
      "train Loss: 0.6087 Acc: 0.8414\n",
      "Epoch [87/100], Step [100/640], Loss: 1.5948, Accuracy: 24.43%\n",
      "val Loss: 1.5279 Acc: 0.7505\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/640], Loss: 0.6198, Accuracy: 27.43%\n",
      "Epoch [88/100], Step [200/640], Loss: 0.6632, Accuracy: 26.57%\n",
      "Epoch [88/100], Step [300/640], Loss: 0.6325, Accuracy: 27.29%\n",
      "Epoch [88/100], Step [400/640], Loss: 0.6129, Accuracy: 26.86%\n",
      "Epoch [88/100], Step [500/640], Loss: 0.5463, Accuracy: 27.00%\n",
      "Epoch [88/100], Step [600/640], Loss: 0.6042, Accuracy: 26.29%\n",
      "train Loss: 0.5984 Acc: 0.8421\n",
      "Epoch [88/100], Step [100/640], Loss: 1.6828, Accuracy: 24.86%\n",
      "val Loss: 1.5955 Acc: 0.7559\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/640], Loss: 0.6711, Accuracy: 27.43%\n",
      "Epoch [89/100], Step [200/640], Loss: 0.6041, Accuracy: 26.57%\n",
      "Epoch [89/100], Step [300/640], Loss: 0.5685, Accuracy: 27.29%\n",
      "Epoch [89/100], Step [400/640], Loss: 0.4942, Accuracy: 27.71%\n",
      "Epoch [89/100], Step [500/640], Loss: 0.6905, Accuracy: 26.71%\n",
      "Epoch [89/100], Step [600/640], Loss: 0.6652, Accuracy: 27.00%\n",
      "train Loss: 0.5997 Acc: 0.8430\n",
      "Epoch [89/100], Step [100/640], Loss: 1.9198, Accuracy: 24.14%\n",
      "val Loss: 1.6946 Acc: 0.7635\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/640], Loss: 0.4342, Accuracy: 28.86%\n",
      "Epoch [90/100], Step [200/640], Loss: 0.5835, Accuracy: 26.86%\n",
      "Epoch [90/100], Step [300/640], Loss: 0.5448, Accuracy: 27.86%\n",
      "Epoch [90/100], Step [400/640], Loss: 0.5980, Accuracy: 26.43%\n",
      "Epoch [90/100], Step [500/640], Loss: 0.4979, Accuracy: 27.43%\n",
      "Epoch [90/100], Step [600/640], Loss: 0.5378, Accuracy: 27.57%\n",
      "train Loss: 0.5900 Acc: 0.8439\n",
      "Epoch [90/100], Step [100/640], Loss: 2.1163, Accuracy: 24.71%\n",
      "val Loss: 1.7393 Acc: 0.7750\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/640], Loss: 0.4973, Accuracy: 27.29%\n",
      "Epoch [91/100], Step [200/640], Loss: 0.5642, Accuracy: 26.00%\n",
      "Epoch [91/100], Step [300/640], Loss: 0.6148, Accuracy: 26.71%\n",
      "Epoch [91/100], Step [400/640], Loss: 0.6972, Accuracy: 26.00%\n",
      "Epoch [91/100], Step [500/640], Loss: 0.6397, Accuracy: 26.43%\n",
      "Epoch [91/100], Step [600/640], Loss: 0.4877, Accuracy: 28.00%\n",
      "train Loss: 0.5898 Acc: 0.8461\n",
      "Epoch [91/100], Step [100/640], Loss: 2.1585, Accuracy: 23.86%\n",
      "val Loss: 1.6622 Acc: 0.7620\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/640], Loss: 0.6399, Accuracy: 26.57%\n",
      "Epoch [92/100], Step [200/640], Loss: 0.5082, Accuracy: 27.14%\n",
      "Epoch [92/100], Step [300/640], Loss: 0.6508, Accuracy: 27.43%\n",
      "Epoch [92/100], Step [400/640], Loss: 0.7675, Accuracy: 26.14%\n",
      "Epoch [92/100], Step [500/640], Loss: 0.5357, Accuracy: 26.86%\n",
      "Epoch [92/100], Step [600/640], Loss: 0.5525, Accuracy: 27.71%\n",
      "train Loss: 0.5783 Acc: 0.8473\n",
      "Epoch [92/100], Step [100/640], Loss: 1.9634, Accuracy: 24.43%\n",
      "val Loss: 1.8079 Acc: 0.7607\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/640], Loss: 0.5952, Accuracy: 26.86%\n",
      "Epoch [93/100], Step [200/640], Loss: 0.4826, Accuracy: 27.00%\n",
      "Epoch [93/100], Step [300/640], Loss: 0.5207, Accuracy: 27.86%\n",
      "Epoch [93/100], Step [400/640], Loss: 0.6302, Accuracy: 26.00%\n",
      "Epoch [93/100], Step [500/640], Loss: 0.7093, Accuracy: 25.14%\n",
      "Epoch [93/100], Step [600/640], Loss: 0.5446, Accuracy: 27.43%\n",
      "train Loss: 0.5786 Acc: 0.8483\n",
      "Epoch [93/100], Step [100/640], Loss: 2.0576, Accuracy: 24.00%\n",
      "val Loss: 1.7853 Acc: 0.7626\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/640], Loss: 0.6934, Accuracy: 26.86%\n",
      "Epoch [94/100], Step [200/640], Loss: 0.4540, Accuracy: 28.14%\n",
      "Epoch [94/100], Step [300/640], Loss: 0.6808, Accuracy: 26.71%\n",
      "Epoch [94/100], Step [400/640], Loss: 0.6002, Accuracy: 26.71%\n",
      "Epoch [94/100], Step [500/640], Loss: 0.6369, Accuracy: 25.71%\n",
      "Epoch [94/100], Step [600/640], Loss: 0.5343, Accuracy: 27.14%\n",
      "train Loss: 0.5719 Acc: 0.8497\n",
      "Epoch [94/100], Step [100/640], Loss: 2.0178, Accuracy: 24.43%\n",
      "val Loss: 1.8360 Acc: 0.7565\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/640], Loss: 0.6393, Accuracy: 26.86%\n",
      "Epoch [95/100], Step [200/640], Loss: 0.5881, Accuracy: 27.57%\n",
      "Epoch [95/100], Step [300/640], Loss: 0.5526, Accuracy: 27.14%\n",
      "Epoch [95/100], Step [400/640], Loss: 0.5971, Accuracy: 27.71%\n",
      "Epoch [95/100], Step [500/640], Loss: 0.5263, Accuracy: 26.71%\n",
      "Epoch [95/100], Step [600/640], Loss: 0.7136, Accuracy: 24.71%\n",
      "train Loss: 0.5672 Acc: 0.8499\n",
      "Epoch [95/100], Step [100/640], Loss: 2.3409, Accuracy: 24.43%\n",
      "val Loss: 1.8671 Acc: 0.7622\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/640], Loss: 0.5570, Accuracy: 26.86%\n",
      "Epoch [96/100], Step [200/640], Loss: 0.5810, Accuracy: 26.71%\n",
      "Epoch [96/100], Step [300/640], Loss: 0.4544, Accuracy: 27.43%\n",
      "Epoch [96/100], Step [400/640], Loss: 0.5163, Accuracy: 28.00%\n",
      "Epoch [96/100], Step [500/640], Loss: 0.3979, Accuracy: 28.29%\n",
      "Epoch [96/100], Step [600/640], Loss: 0.4941, Accuracy: 27.57%\n",
      "train Loss: 0.5611 Acc: 0.8518\n",
      "Epoch [96/100], Step [100/640], Loss: 2.3591, Accuracy: 24.14%\n",
      "val Loss: 1.8591 Acc: 0.7648\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/640], Loss: 0.4768, Accuracy: 27.00%\n",
      "Epoch [97/100], Step [200/640], Loss: 0.4354, Accuracy: 29.43%\n",
      "Epoch [97/100], Step [300/640], Loss: 0.4452, Accuracy: 28.29%\n",
      "Epoch [97/100], Step [400/640], Loss: 0.6974, Accuracy: 25.43%\n",
      "Epoch [97/100], Step [500/640], Loss: 0.4104, Accuracy: 28.43%\n",
      "Epoch [97/100], Step [600/640], Loss: 0.5694, Accuracy: 27.00%\n",
      "train Loss: 0.5604 Acc: 0.8519\n",
      "Epoch [97/100], Step [100/640], Loss: 2.3024, Accuracy: 25.00%\n",
      "val Loss: 1.9075 Acc: 0.7644\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/640], Loss: 0.5057, Accuracy: 27.86%\n",
      "Epoch [98/100], Step [200/640], Loss: 0.6893, Accuracy: 27.29%\n",
      "Epoch [98/100], Step [300/640], Loss: 0.5214, Accuracy: 27.43%\n",
      "Epoch [98/100], Step [400/640], Loss: 0.6860, Accuracy: 25.57%\n",
      "Epoch [98/100], Step [500/640], Loss: 0.5019, Accuracy: 28.14%\n",
      "Epoch [98/100], Step [600/640], Loss: 0.5022, Accuracy: 28.43%\n",
      "train Loss: 0.5565 Acc: 0.8531\n",
      "Epoch [98/100], Step [100/640], Loss: 2.3118, Accuracy: 24.29%\n",
      "val Loss: 1.8698 Acc: 0.7633\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/640], Loss: 0.6315, Accuracy: 27.00%\n",
      "Epoch [99/100], Step [200/640], Loss: 0.6073, Accuracy: 27.57%\n",
      "Epoch [99/100], Step [300/640], Loss: 0.5215, Accuracy: 28.14%\n",
      "Epoch [99/100], Step [400/640], Loss: 0.5444, Accuracy: 27.43%\n",
      "Epoch [99/100], Step [500/640], Loss: 0.7100, Accuracy: 26.43%\n",
      "Epoch [99/100], Step [600/640], Loss: 0.6809, Accuracy: 25.86%\n",
      "train Loss: 0.5540 Acc: 0.8537\n",
      "Epoch [99/100], Step [100/640], Loss: 2.3078, Accuracy: 24.29%\n",
      "val Loss: 2.0236 Acc: 0.7638\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/640], Loss: 0.4837, Accuracy: 28.57%\n",
      "Epoch [100/100], Step [200/640], Loss: 0.4970, Accuracy: 28.43%\n",
      "Epoch [100/100], Step [300/640], Loss: 0.6090, Accuracy: 27.00%\n",
      "Epoch [100/100], Step [400/640], Loss: 0.6501, Accuracy: 27.43%\n",
      "Epoch [100/100], Step [500/640], Loss: 0.4301, Accuracy: 28.14%\n",
      "Epoch [100/100], Step [600/640], Loss: 0.4741, Accuracy: 28.71%\n",
      "train Loss: 0.5517 Acc: 0.8548\n",
      "Epoch [100/100], Step [100/640], Loss: 2.6689, Accuracy: 24.43%\n",
      "val Loss: 2.0425 Acc: 0.7650\n",
      "\n",
      "Training complete in 121m 15s\n",
      "Best val Acc: 0.789221\n",
      "Best loss: 0.944057\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'chest_xray_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7835638192284787\n",
      "f1: 0.4067081829195027\n",
      "cm: [[[2832  441]\n",
      "  [ 515  530]]\n",
      "\n",
      " [[2589  684]\n",
      "  [ 307  738]]\n",
      "\n",
      " [[3319  440]\n",
      "  [ 362  197]]\n",
      "\n",
      " [[3213  450]\n",
      "  [ 491  164]]\n",
      "\n",
      " [[2630  641]\n",
      "  [ 567  480]]\n",
      "\n",
      " [[3413  460]\n",
      "  [ 263  182]]\n",
      "\n",
      " [[3141  711]\n",
      "  [ 210  256]]]\n",
      "outputs: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "targets: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
